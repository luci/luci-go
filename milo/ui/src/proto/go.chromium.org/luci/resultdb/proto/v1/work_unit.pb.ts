// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.7.5
//   protoc               v6.32.1
// source: go.chromium.org/luci/resultdb/proto/v1/work_unit.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import { Struct } from "../../../../../google/protobuf/struct.pb";
import { Timestamp } from "../../../../../google/protobuf/timestamp.pb";
import {
  ModuleIdentifier,
  ProducerResource,
  StringPair,
  WorkUnitView,
  workUnitViewFromJSON,
  workUnitViewToJSON,
} from "./common.pb";
import { Instructions } from "./instruction.pb";
import { WorkUnitPredicate } from "./predicate.pb";

export const protobufPackage = "luci.resultdb.v1";

/**
 * A process step that contributes results to a root invocation.
 * Work units contain test results, artifacts and exonerations. Work units may
 * also contain other work units and (legacy) invocations.
 * Next ID: 27.
 */
export interface WorkUnit {
  /**
   * The resource name of this work unit.
   * Format: `rootInvocations/{ROOT_INVOCATION_ID}/workUnits/{WORK_UNIT_ID}`
   * See also https://aip.dev/122.
   *
   * Output only.
   */
  readonly name: string;
  /**
   * The work unit identifier. This identifier is unique within
   * an enclosing root invocation, but not necessarily globally unique.
   *
   * Output only.
   */
  readonly workUnitId: string;
  /**
   * The type of work unit. This captures the process the work unit is
   * performing and the infrastructure that is creating it.
   *
   * Each infrastructure layer should reserve its own prefix (e.g. TF_, TFC_...)
   * and document it below to avoid generating conflicts. Reach out to ResultDB
   * owners if you'd like help updating this comment.
   *
   * Known values:
   * - Android Test Production: ATP_INVOCATION
   * - Tradefed: TF_MODULE, TF_TEST_RUN
   * - Tradefed Cluster: TFC_COMMAND, TFC_COMMAND_TASK
   * - Bazel: G3_BLAZE_INVOCATION, G3_TEST_TARGET, G3_ACTION, G3_MODULE
   * - Buildbucket: BUILDBUCKET_BUILD
   * - ResultSink: RDB_STREAM
   *
   * Regex: ^[A-Z0-9]+(_[A-Z0-9]+)+$. Limited to 50 characters in length.
   * Required.
   */
  readonly kind: string;
  /**
   * The overall state of the work unit, including any child work units.
   * See also: https://google.aip.dev/216.
   *
   * An accompanying human-readable description should be uploaded for FAILED,
   * CANCELLED and SKIPPED states to `summary_markdown`.
   */
  readonly state: WorkUnit_State;
  /**
   * A summary of the final state of the work unit, to be displayed on the UI.
   * MUST be escaped prior to rendering on the UI.
   *
   * E.g. if the work unit failed, the reason/stack trace describing why
   * it failed.
   *
   * Can be elided if the work unit succeeded.
   *
   * The size of the summary must be equal to or smaller than 4096 bytes in
   * UTF-8.
   */
  readonly summaryMarkdown: string;
  /**
   * Current finalization state of the work unit.
   *
   * Output only.
   */
  readonly finalizationState: WorkUnit_FinalizationState;
  /**
   * The realm of the work unit. This controls the ACLs that apply to the
   * work unit and its contents.
   *
   * For example, 'chromium:try'.
   *
   * See go/luci-authorization for more information.
   */
  readonly realm: string;
  /**
   * When the work unit was created.
   * Output only.
   */
  readonly createTime:
    | string
    | undefined;
  /**
   * LUCI identity (e.g. "user:<email>") who created the work unit.
   * Typically, a LUCI service account (e.g.
   * "user:cr-buildbucket@appspot.gserviceaccount.com"), but can also be a user
   * (e.g. "user:johndoe@example.com").
   *
   * Output only.
   */
  readonly creator: string;
  /**
   * When the work unit was last updated.
   * Output only.
   */
  readonly lastUpdated:
    | string
    | undefined;
  /**
   * When the work unit started to finalize, i.e. transitioned to a finalization
   * state of FINALIZING. This means the work unit is immutable but directly or
   * indirectly included work units may not be.
   *
   * Output only.
   */
  readonly finalizeStartTime:
    | string
    | undefined;
  /**
   * When the work unit was finalized, i.e. transitioned to a finalization
   * state of FINALIZED.
   * If this field is set, implies that the work units is finalized. This
   * means the work unit, and all directly and indirectly included work units,
   * are immutable.
   *
   * Output only.
   */
  readonly finalizeTime:
    | string
    | undefined;
  /**
   * Timestamp when the work unit will be forcefully finalized.
   * Can be extended with UpdateWorkUnit until finalized.
   */
  readonly deadline:
    | string
    | undefined;
  /**
   * The parent resource of this work unit. This is typically
   * another work unit, except for the root work unit, for which
   * it is the root invocation.
   */
  readonly parent: string;
  /**
   * Resource names of child work units.
   *
   * This field only covers children; to find grandchildren, great
   * grandchildren, etc. traverse recursively.
   *
   * To create a new child work unit, use Recorder.CreateWorkUnit
   * and specify this work unit as the parent.
   *
   * Output only (append via (Batch)CreateWorkUnit(s)).
   */
  readonly childWorkUnits: readonly string[];
  /**
   * Resource names of child (legacy) invocations.
   *
   * This field only covers children; to find grandchildren, great
   * grandchildren, etc. traverse recursively.
   *
   * Output only (append via UpdateIncludedInvocations).
   */
  readonly childInvocations: readonly string[];
  /**
   * The module this work unit is reporting results for.
   *
   * The value set here will inherit to (and cannot be overridden by) all descendent
   * work units created under this work unit.
   *
   * This field must be set if this work unit will (directly) contain any test
   * results or test result artifacts, as test results and test result
   * artifacts uploaded to this work unit will need to match this module.
   *
   * This field does not need to be set to upload work unit-level artifacts
   * (artifacts not associated with a test result).
   *
   * If results from multiple modules need to be reported, leave module_id blank
   * on the work unit and create a child work unit for each module.
   * This field may be left unset if this work unit is not associated with a module,
   * only has child work units, and will not be uploading test results itself.
   *
   * This field is immutable, it can only be set at work unit creation time.
   */
  readonly moduleId:
    | ModuleIdentifier
    | undefined;
  /**
   * The identifier of the module-shard this work unit is running.
   *
   * This is used when computing module aggregations. Module aggregations
   * consider only top-level module work units; a top-level module work unit is
   * any work unit that sets module_id AND has no ancestor (parent, grandparent
   * etc.) that sets a module_id.
   *
   * A module is considered to succeed if only if there is at least one SUCCEEDED
   * or SKIPPED top-level module work unit for each shard key seen.
   * (Or, if no sharding key is reported, there is at least one SUCCEEDED or SKIPPED
   * top-level module work unit for the module.)
   *
   * If sharding is not used, leave blank. Shard keys must be coordinated within
   * a root invocation-module so that the same shard key refers to the same shard,
   * wherever it is used in the root invocation.
   *
   * This field may only be set when module_id is also set. It will inherit to
   * all descendent work units created under this work unit. It can only be set
   * at work unit creation time.
   *
   * Regex: ^[a-z0-9_\-]+$. Limited to 50 characters in length.
   */
  readonly moduleShardKey: string;
  /** The resource that produced results in this work unit. */
  readonly producerResource:
    | ProducerResource
    | undefined;
  /**
   * Work unit-level string key-value pairs.
   * A key can be repeated.
   *
   * These tags may be re-exported alongside each test result.
   *
   * Total size (as measured by proto.Size()) must be <= 16 KB.
   */
  readonly tags: readonly StringPair[];
  /**
   * Arbitrary JSON object that contains structured, domain-specific properties
   * of the work unit.
   *
   * The value must contain a field "@type" which is a URL/resource name that
   * uniquely identifies the type of the source protocol buffer message that
   * defines the schema of these properties. This string must contain at least
   * one "/" character. The last segment of the URL's path must represent the
   * fully qualified name of the type (e.g. foo.com/x/some.package.MyMessage).
   * See google.protobuf.Any for more information.
   *
   * N.B. We do not use google.protobuf.Any here to remove a requirement for
   * ResultDB to know the schema of customer-defined protos. We do however use
   * a format equivalent to google.protobuf.Any's JSON representation.
   *
   * The serialized size must be <= 16 KB.
   */
  readonly properties:
    | { readonly [key: string]: any }
    | undefined;
  /**
   * Additional JSON object(s) that contain additional structured data about the
   * work unit. Unlike `properties` this field is not included (denormalized)
   * in the test results export, it is only available in the finalized
   * work units BigQuery export.
   *
   * All google.protobuf.Struct values must contain a field '@type' which is
   * a URL/resource name that uniquely identifies the type of the source
   * protocol buffer message. This string must contain at least
   * one "/" character. The last segment of the URL's path must represent the
   * fully qualified name of the type (e.g. foo.com/x/some.package.MyMessage)
   *
   * ResultDB will not validate the contents with respect to this schema, but
   * downstream systems may depend on the '@type' field to inform how the
   * contents are interpreted.
   *
   * Each key is limited to 63 characters matching
   * ^[a-z]([a-z0-9_]{0,61}[a-z0-9])?$.
   * The size of each value is limited to <= 512 KB.
   * The total size of the map (as measured by proto.Size())
   * is limited to <= 2 MB.
   *
   * The following paths can be used for field masks:
   * * "extended_properties" to target the whole extended_properties,
   * * "extended_properties.some_key" to target one key of extended_properties.
   */
  readonly extendedProperties: { [key: string]: { readonly [key: string]: any } | undefined };
  /**
   * Reproduction instructions for steps and test results represented by
   * this work unit. It may also contain instructions for test results in
   * included work units.
   */
  readonly instructions:
    | Instructions
    | undefined;
  /**
   * Whether the work unit has been masked so that it includes only metadata.
   * The metadata fields for a WorkUnit are:
   * * name
   * * work_unit_id
   * * kind
   * * finalization_state
   * * state
   * * summary_markdown (truncated to the first 140 bytes)
   * * realm
   * * create_time
   * * creator
   * * last_updated
   * * finalize_start_time
   * * finalize_time
   * * deadline
   * * parent
   * * child_work_units
   * * child_invocations
   * * module_id (all fields except `module_variant`)
   * * module_shard_key
   * * producer_resource
   *
   * Output only.
   */
  readonly isMasked: boolean;
  /**
   * This checksum is computed by the server based on the value of other
   * fields, and may be sent on update requests to ensure the client
   * has an up-to-date value before proceeding.
   * See also https://google.aip.dev/154.
   */
  readonly etag: string;
}

/** The execution state of the work unit. */
export enum WorkUnit_State {
  /** STATE_UNSPECIFIED - The default value. This value is unused. */
  STATE_UNSPECIFIED = 0,
  /** PENDING - The work unit has not yet started running. */
  PENDING = 1,
  /** RUNNING - The work unit is currently running. */
  RUNNING = 2,
  /** FINAL_STATE_MASK - Can be used as a bitmask to identify final states. */
  FINAL_STATE_MASK = 4,
  /**
   * SUCCEEDED - The work unit, including its child work units, completed
   * successfully. If any child work units failed, they were
   * retried, and those retries succeeded.
   *
   * This status means results are complete and correct, i.e.:
   * - all tests to be run (or skipped) were identified.
   * - test results were successfully uploaded to ResultDB
   *   for each such test.
   *
   * This status generally does not say anything about the test content;
   * tests could have FAILED, some could have even failed to
   * produce a result (EXECUTION_ERRORED).
   *
   * If any test results were reported with a status of PRECLUDED (i.e.
   * had their execution blocked by a higher-level error), do not use
   * this status. Instead report the status ERRORED, and indicate what
   * higher-level error precluded the execution of those tests (e.g.
   * loss of system under test).
   */
  SUCCEEDED = 12,
  /**
   * SKIPPED - The work unit determined no tests need to be run.
   * For example, the build dependency graph indicates the CL did
   * not modify the module to be tested.
   * This status usually indicates no test results were uploaded.
   */
  SKIPPED = 20,
  /**
   * FAILED - The work unit, or one of its child work units, encountered an error.
   * Moreover, that error was not resolved by retry within the work unit.
   *
   * This status means the results may be incomplete, e.g. because of an
   * issue:
   * - identifying the tests to be run (and skipped), or
   * - running those tests, or
   * - uploading the work unit, or any of its test results or artifacts,
   *   to ResultDB.
   *
   * Common causes are timeout, crash of the device under test and tool failure.
   * It can also indicate the bot running the work unit was shut down
   * unexpectedly.
   *
   * If you report any test results with a status of `PRECLUDED`, you
   * MUST use this status and indicate what higher-level error
   * precluded their execution (e.g. timeout or loss of system
   * under test) in the summary_markdown field.
   *
   * If this work unit is forcefully finalized because the `deadline`
   * expired, it will be automatically transitioned to this state as
   * there is an implied failure to upload results to ResultDB.
   */
  FAILED = 36,
  /**
   * CANCELLED - The work unit never started or may be incomplete, because
   * an external factor requested its cancellation (e.g. presubmit
   * run was no longer needed).
   */
  CANCELLED = 68,
}

export function workUnit_StateFromJSON(object: any): WorkUnit_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return WorkUnit_State.STATE_UNSPECIFIED;
    case 1:
    case "PENDING":
      return WorkUnit_State.PENDING;
    case 2:
    case "RUNNING":
      return WorkUnit_State.RUNNING;
    case 4:
    case "FINAL_STATE_MASK":
      return WorkUnit_State.FINAL_STATE_MASK;
    case 12:
    case "SUCCEEDED":
      return WorkUnit_State.SUCCEEDED;
    case 20:
    case "SKIPPED":
      return WorkUnit_State.SKIPPED;
    case 36:
    case "FAILED":
      return WorkUnit_State.FAILED;
    case 68:
    case "CANCELLED":
      return WorkUnit_State.CANCELLED;
    default:
      throw new globalThis.Error("Unrecognized enum value " + object + " for enum WorkUnit_State");
  }
}

export function workUnit_StateToJSON(object: WorkUnit_State): string {
  switch (object) {
    case WorkUnit_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case WorkUnit_State.PENDING:
      return "PENDING";
    case WorkUnit_State.RUNNING:
      return "RUNNING";
    case WorkUnit_State.FINAL_STATE_MASK:
      return "FINAL_STATE_MASK";
    case WorkUnit_State.SUCCEEDED:
      return "SUCCEEDED";
    case WorkUnit_State.SKIPPED:
      return "SKIPPED";
    case WorkUnit_State.FAILED:
      return "FAILED";
    case WorkUnit_State.CANCELLED:
      return "CANCELLED";
    default:
      throw new globalThis.Error("Unrecognized enum value " + object + " for enum WorkUnit_State");
  }
}

/** Indicates whether the work unit, and its children, are immutable. */
export enum WorkUnit_FinalizationState {
  /** FINALIZATION_STATE_UNSPECIFIED - The default value. This value is unused. */
  FINALIZATION_STATE_UNSPECIFIED = 0,
  /**
   * ACTIVE - The work unit is mutable.
   * The work unit will be int his state when `state` is in a non-final
   * state.
   */
  ACTIVE = 1,
  /**
   * FINALIZING - The work unit is in the process of moving to the FINALIZED state.
   *
   * In this state, the work unit itself is immutable, but its
   * contained work units may still be mutable. When the work unit
   * is immutable, the work unit record may not be updated, and
   * no test results, exonerations or artifacts be created
   * inside it.
   *
   * The work unit automatically enters this state when the work unit
   * `state` transitions to a final state (SUCCEEDED, SKIPPED, FAILED,
   * CANCELLED).
   */
  FINALIZING = 2,
  /**
   * FINALIZED - The work unit is immutable and no longer accepts new results
   * directly or indirectly.
   *
   * This work unit automatically enters this state shortly after it is
   * FINALIZING and all included work units become FINALIZED.
   */
  FINALIZED = 3,
}

export function workUnit_FinalizationStateFromJSON(object: any): WorkUnit_FinalizationState {
  switch (object) {
    case 0:
    case "FINALIZATION_STATE_UNSPECIFIED":
      return WorkUnit_FinalizationState.FINALIZATION_STATE_UNSPECIFIED;
    case 1:
    case "ACTIVE":
      return WorkUnit_FinalizationState.ACTIVE;
    case 2:
    case "FINALIZING":
      return WorkUnit_FinalizationState.FINALIZING;
    case 3:
    case "FINALIZED":
      return WorkUnit_FinalizationState.FINALIZED;
    default:
      throw new globalThis.Error("Unrecognized enum value " + object + " for enum WorkUnit_FinalizationState");
  }
}

export function workUnit_FinalizationStateToJSON(object: WorkUnit_FinalizationState): string {
  switch (object) {
    case WorkUnit_FinalizationState.FINALIZATION_STATE_UNSPECIFIED:
      return "FINALIZATION_STATE_UNSPECIFIED";
    case WorkUnit_FinalizationState.ACTIVE:
      return "ACTIVE";
    case WorkUnit_FinalizationState.FINALIZING:
      return "FINALIZING";
    case WorkUnit_FinalizationState.FINALIZED:
      return "FINALIZED";
    default:
      throw new globalThis.Error("Unrecognized enum value " + object + " for enum WorkUnit_FinalizationState");
  }
}

export interface WorkUnit_ExtendedPropertiesEntry {
  readonly key: string;
  readonly value: { readonly [key: string]: any } | undefined;
}

/** A request message for the GetWorkUnit RPC. */
export interface GetWorkUnitRequest {
  /** The name of the work unit to read, see WorkUnit.name. */
  readonly name: string;
  /** The view to apply to the returned work unit. Defaults to BASIC. */
  readonly view: WorkUnitView;
}

/**
 * A request message for the BatchGetWorkUnits RPC.
 *
 * As per google.aip.dev/231, this request will be handled atomically:
 * either it will succeed in reading all nominated work units or it will fail.
 */
export interface BatchGetWorkUnitsRequest {
  /**
   * The parent root invocation shared by all work units being retrieved.
   * Format: rootInvocations/{root_invocation_id}
   * The parent of all work units specified in `names` must match this
   * field.
   * Required.
   */
  readonly parent: string;
  /**
   * The names of the work units to retrieve.
   * A maximum of 500 work units can be retrieved in a batch.
   * Format: rootInvocations/{root_invocation_id}/workUnits/{work_unit_id}
   */
  readonly names: readonly string[];
  /**
   * The view to apply to returned work units. Using the view BASIC is
   * strongly recommended as response size limits could be easily exceeded
   * if FULL is used (as each work unit's extended properties may be up to
   * ~2MB). Defaults to BASIC.
   */
  readonly view: WorkUnitView;
}

/** A response message for the BatchGetWorkUnits RPC. */
export interface BatchGetWorkUnitsResponse {
  /**
   * The work units requested. These will appear in the same order as
   * names in the request, i.e. work_units[i] corresponds to names[i].
   */
  readonly workUnits: readonly WorkUnit[];
}

/** A request message for the QueryWorkUnits RPC. */
export interface QueryWorkUnitsRequest {
  /**
   * Resource name of the root invocation to query.
   * Format: rootInvocations/{ROOT_INVOCATION_ID}
   */
  readonly parent: string;
  /** The predicate to filter the workunits to be returned. */
  readonly predicate:
    | WorkUnitPredicate
    | undefined;
  /**
   * The view to apply to returned work units. Using the view BASIC is
   * strongly recommended as response size limits could be easily exceeded
   * if FULL is used (as each work unit's extended properties may be up to
   * ~2MB). Defaults to BASIC.
   */
  readonly view: WorkUnitView;
}

/** A response message for the QueryWorkUnits RPC. */
export interface QueryWorkUnitsResponse {
  /** The workunits matching the query. */
  readonly workUnits: readonly WorkUnit[];
}

function createBaseWorkUnit(): WorkUnit {
  return {
    name: "",
    workUnitId: "",
    kind: "",
    state: 0,
    summaryMarkdown: "",
    finalizationState: 0,
    realm: "",
    createTime: undefined,
    creator: "",
    lastUpdated: undefined,
    finalizeStartTime: undefined,
    finalizeTime: undefined,
    deadline: undefined,
    parent: "",
    childWorkUnits: [],
    childInvocations: [],
    moduleId: undefined,
    moduleShardKey: "",
    producerResource: undefined,
    tags: [],
    properties: undefined,
    extendedProperties: {},
    instructions: undefined,
    isMasked: false,
    etag: "",
  };
}

export const WorkUnit: MessageFns<WorkUnit> = {
  encode(message: WorkUnit, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.workUnitId !== "") {
      writer.uint32(18).string(message.workUnitId);
    }
    if (message.kind !== "") {
      writer.uint32(202).string(message.kind);
    }
    if (message.state !== 0) {
      writer.uint32(176).int32(message.state);
    }
    if (message.summaryMarkdown !== "") {
      writer.uint32(186).string(message.summaryMarkdown);
    }
    if (message.finalizationState !== 0) {
      writer.uint32(24).int32(message.finalizationState);
    }
    if (message.realm !== "") {
      writer.uint32(34).string(message.realm);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(42).fork()).join();
    }
    if (message.creator !== "") {
      writer.uint32(50).string(message.creator);
    }
    if (message.lastUpdated !== undefined) {
      Timestamp.encode(toTimestamp(message.lastUpdated), writer.uint32(162).fork()).join();
    }
    if (message.finalizeStartTime !== undefined) {
      Timestamp.encode(toTimestamp(message.finalizeStartTime), writer.uint32(58).fork()).join();
    }
    if (message.finalizeTime !== undefined) {
      Timestamp.encode(toTimestamp(message.finalizeTime), writer.uint32(66).fork()).join();
    }
    if (message.deadline !== undefined) {
      Timestamp.encode(toTimestamp(message.deadline), writer.uint32(74).fork()).join();
    }
    if (message.parent !== "") {
      writer.uint32(82).string(message.parent);
    }
    for (const v of message.childWorkUnits) {
      writer.uint32(90).string(v!);
    }
    for (const v of message.childInvocations) {
      writer.uint32(98).string(v!);
    }
    if (message.moduleId !== undefined) {
      ModuleIdentifier.encode(message.moduleId, writer.uint32(154).fork()).join();
    }
    if (message.moduleShardKey !== "") {
      writer.uint32(194).string(message.moduleShardKey);
    }
    if (message.producerResource !== undefined) {
      ProducerResource.encode(message.producerResource, writer.uint32(210).fork()).join();
    }
    for (const v of message.tags) {
      StringPair.encode(v!, writer.uint32(114).fork()).join();
    }
    if (message.properties !== undefined) {
      Struct.encode(Struct.wrap(message.properties), writer.uint32(122).fork()).join();
    }
    Object.entries(message.extendedProperties).forEach(([key, value]) => {
      if (value !== undefined) {
        WorkUnit_ExtendedPropertiesEntry.encode({ key: key as any, value }, writer.uint32(130).fork()).join();
      }
    });
    if (message.instructions !== undefined) {
      Instructions.encode(message.instructions, writer.uint32(138).fork()).join();
    }
    if (message.isMasked !== false) {
      writer.uint32(144).bool(message.isMasked);
    }
    if (message.etag !== "") {
      writer.uint32(170).string(message.etag);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WorkUnit {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkUnit() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.workUnitId = reader.string();
          continue;
        }
        case 25: {
          if (tag !== 202) {
            break;
          }

          message.kind = reader.string();
          continue;
        }
        case 22: {
          if (tag !== 176) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 23: {
          if (tag !== 186) {
            break;
          }

          message.summaryMarkdown = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.finalizationState = reader.int32() as any;
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.realm = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.creator = reader.string();
          continue;
        }
        case 20: {
          if (tag !== 162) {
            break;
          }

          message.lastUpdated = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.finalizeStartTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.finalizeTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.deadline = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.parent = reader.string();
          continue;
        }
        case 11: {
          if (tag !== 90) {
            break;
          }

          message.childWorkUnits.push(reader.string());
          continue;
        }
        case 12: {
          if (tag !== 98) {
            break;
          }

          message.childInvocations.push(reader.string());
          continue;
        }
        case 19: {
          if (tag !== 154) {
            break;
          }

          message.moduleId = ModuleIdentifier.decode(reader, reader.uint32());
          continue;
        }
        case 24: {
          if (tag !== 194) {
            break;
          }

          message.moduleShardKey = reader.string();
          continue;
        }
        case 26: {
          if (tag !== 210) {
            break;
          }

          message.producerResource = ProducerResource.decode(reader, reader.uint32());
          continue;
        }
        case 14: {
          if (tag !== 114) {
            break;
          }

          message.tags.push(StringPair.decode(reader, reader.uint32()));
          continue;
        }
        case 15: {
          if (tag !== 122) {
            break;
          }

          message.properties = Struct.unwrap(Struct.decode(reader, reader.uint32()));
          continue;
        }
        case 16: {
          if (tag !== 130) {
            break;
          }

          const entry16 = WorkUnit_ExtendedPropertiesEntry.decode(reader, reader.uint32());
          if (entry16.value !== undefined) {
            message.extendedProperties[entry16.key] = entry16.value;
          }
          continue;
        }
        case 17: {
          if (tag !== 138) {
            break;
          }

          message.instructions = Instructions.decode(reader, reader.uint32());
          continue;
        }
        case 18: {
          if (tag !== 144) {
            break;
          }

          message.isMasked = reader.bool();
          continue;
        }
        case 21: {
          if (tag !== 170) {
            break;
          }

          message.etag = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WorkUnit {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      workUnitId: isSet(object.workUnitId) ? globalThis.String(object.workUnitId) : "",
      kind: isSet(object.kind) ? globalThis.String(object.kind) : "",
      state: isSet(object.state) ? workUnit_StateFromJSON(object.state) : 0,
      summaryMarkdown: isSet(object.summaryMarkdown) ? globalThis.String(object.summaryMarkdown) : "",
      finalizationState: isSet(object.finalizationState)
        ? workUnit_FinalizationStateFromJSON(object.finalizationState)
        : 0,
      realm: isSet(object.realm) ? globalThis.String(object.realm) : "",
      createTime: isSet(object.createTime) ? globalThis.String(object.createTime) : undefined,
      creator: isSet(object.creator) ? globalThis.String(object.creator) : "",
      lastUpdated: isSet(object.lastUpdated) ? globalThis.String(object.lastUpdated) : undefined,
      finalizeStartTime: isSet(object.finalizeStartTime) ? globalThis.String(object.finalizeStartTime) : undefined,
      finalizeTime: isSet(object.finalizeTime) ? globalThis.String(object.finalizeTime) : undefined,
      deadline: isSet(object.deadline) ? globalThis.String(object.deadline) : undefined,
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      childWorkUnits: globalThis.Array.isArray(object?.childWorkUnits)
        ? object.childWorkUnits.map((e: any) => globalThis.String(e))
        : [],
      childInvocations: globalThis.Array.isArray(object?.childInvocations)
        ? object.childInvocations.map((e: any) => globalThis.String(e))
        : [],
      moduleId: isSet(object.moduleId) ? ModuleIdentifier.fromJSON(object.moduleId) : undefined,
      moduleShardKey: isSet(object.moduleShardKey) ? globalThis.String(object.moduleShardKey) : "",
      producerResource: isSet(object.producerResource) ? ProducerResource.fromJSON(object.producerResource) : undefined,
      tags: globalThis.Array.isArray(object?.tags) ? object.tags.map((e: any) => StringPair.fromJSON(e)) : [],
      properties: isObject(object.properties) ? object.properties : undefined,
      extendedProperties: isObject(object.extendedProperties)
        ? Object.entries(object.extendedProperties).reduce<
          { [key: string]: { readonly [key: string]: any } | undefined }
        >((acc, [key, value]) => {
          acc[key] = value as { readonly [key: string]: any } | undefined;
          return acc;
        }, {})
        : {},
      instructions: isSet(object.instructions) ? Instructions.fromJSON(object.instructions) : undefined,
      isMasked: isSet(object.isMasked) ? globalThis.Boolean(object.isMasked) : false,
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
    };
  },

  toJSON(message: WorkUnit): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.workUnitId !== "") {
      obj.workUnitId = message.workUnitId;
    }
    if (message.kind !== "") {
      obj.kind = message.kind;
    }
    if (message.state !== 0) {
      obj.state = workUnit_StateToJSON(message.state);
    }
    if (message.summaryMarkdown !== "") {
      obj.summaryMarkdown = message.summaryMarkdown;
    }
    if (message.finalizationState !== 0) {
      obj.finalizationState = workUnit_FinalizationStateToJSON(message.finalizationState);
    }
    if (message.realm !== "") {
      obj.realm = message.realm;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime;
    }
    if (message.creator !== "") {
      obj.creator = message.creator;
    }
    if (message.lastUpdated !== undefined) {
      obj.lastUpdated = message.lastUpdated;
    }
    if (message.finalizeStartTime !== undefined) {
      obj.finalizeStartTime = message.finalizeStartTime;
    }
    if (message.finalizeTime !== undefined) {
      obj.finalizeTime = message.finalizeTime;
    }
    if (message.deadline !== undefined) {
      obj.deadline = message.deadline;
    }
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.childWorkUnits?.length) {
      obj.childWorkUnits = message.childWorkUnits;
    }
    if (message.childInvocations?.length) {
      obj.childInvocations = message.childInvocations;
    }
    if (message.moduleId !== undefined) {
      obj.moduleId = ModuleIdentifier.toJSON(message.moduleId);
    }
    if (message.moduleShardKey !== "") {
      obj.moduleShardKey = message.moduleShardKey;
    }
    if (message.producerResource !== undefined) {
      obj.producerResource = ProducerResource.toJSON(message.producerResource);
    }
    if (message.tags?.length) {
      obj.tags = message.tags.map((e) => StringPair.toJSON(e));
    }
    if (message.properties !== undefined) {
      obj.properties = message.properties;
    }
    if (message.extendedProperties) {
      const entries = Object.entries(message.extendedProperties);
      if (entries.length > 0) {
        obj.extendedProperties = {};
        entries.forEach(([k, v]) => {
          obj.extendedProperties[k] = v;
        });
      }
    }
    if (message.instructions !== undefined) {
      obj.instructions = Instructions.toJSON(message.instructions);
    }
    if (message.isMasked !== false) {
      obj.isMasked = message.isMasked;
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    return obj;
  },

  create(base?: DeepPartial<WorkUnit>): WorkUnit {
    return WorkUnit.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkUnit>): WorkUnit {
    const message = createBaseWorkUnit() as any;
    message.name = object.name ?? "";
    message.workUnitId = object.workUnitId ?? "";
    message.kind = object.kind ?? "";
    message.state = object.state ?? 0;
    message.summaryMarkdown = object.summaryMarkdown ?? "";
    message.finalizationState = object.finalizationState ?? 0;
    message.realm = object.realm ?? "";
    message.createTime = object.createTime ?? undefined;
    message.creator = object.creator ?? "";
    message.lastUpdated = object.lastUpdated ?? undefined;
    message.finalizeStartTime = object.finalizeStartTime ?? undefined;
    message.finalizeTime = object.finalizeTime ?? undefined;
    message.deadline = object.deadline ?? undefined;
    message.parent = object.parent ?? "";
    message.childWorkUnits = object.childWorkUnits?.map((e) => e) || [];
    message.childInvocations = object.childInvocations?.map((e) => e) || [];
    message.moduleId = (object.moduleId !== undefined && object.moduleId !== null)
      ? ModuleIdentifier.fromPartial(object.moduleId)
      : undefined;
    message.moduleShardKey = object.moduleShardKey ?? "";
    message.producerResource = (object.producerResource !== undefined && object.producerResource !== null)
      ? ProducerResource.fromPartial(object.producerResource)
      : undefined;
    message.tags = object.tags?.map((e) => StringPair.fromPartial(e)) || [];
    message.properties = object.properties ?? undefined;
    message.extendedProperties = Object.entries(object.extendedProperties ?? {}).reduce<
      { [key: string]: { readonly [key: string]: any } | undefined }
    >((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = value;
      }
      return acc;
    }, {});
    message.instructions = (object.instructions !== undefined && object.instructions !== null)
      ? Instructions.fromPartial(object.instructions)
      : undefined;
    message.isMasked = object.isMasked ?? false;
    message.etag = object.etag ?? "";
    return message;
  },
};

function createBaseWorkUnit_ExtendedPropertiesEntry(): WorkUnit_ExtendedPropertiesEntry {
  return { key: "", value: undefined };
}

export const WorkUnit_ExtendedPropertiesEntry: MessageFns<WorkUnit_ExtendedPropertiesEntry> = {
  encode(message: WorkUnit_ExtendedPropertiesEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== undefined) {
      Struct.encode(Struct.wrap(message.value), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WorkUnit_ExtendedPropertiesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWorkUnit_ExtendedPropertiesEntry() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = Struct.unwrap(Struct.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WorkUnit_ExtendedPropertiesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isObject(object.value) ? object.value : undefined,
    };
  },

  toJSON(message: WorkUnit_ExtendedPropertiesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== undefined) {
      obj.value = message.value;
    }
    return obj;
  },

  create(base?: DeepPartial<WorkUnit_ExtendedPropertiesEntry>): WorkUnit_ExtendedPropertiesEntry {
    return WorkUnit_ExtendedPropertiesEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WorkUnit_ExtendedPropertiesEntry>): WorkUnit_ExtendedPropertiesEntry {
    const message = createBaseWorkUnit_ExtendedPropertiesEntry() as any;
    message.key = object.key ?? "";
    message.value = object.value ?? undefined;
    return message;
  },
};

function createBaseGetWorkUnitRequest(): GetWorkUnitRequest {
  return { name: "", view: 0 };
}

export const GetWorkUnitRequest: MessageFns<GetWorkUnitRequest> = {
  encode(message: GetWorkUnitRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.view !== 0) {
      writer.uint32(16).int32(message.view);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetWorkUnitRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetWorkUnitRequest() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.view = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetWorkUnitRequest {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      view: isSet(object.view) ? workUnitViewFromJSON(object.view) : 0,
    };
  },

  toJSON(message: GetWorkUnitRequest): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.view !== 0) {
      obj.view = workUnitViewToJSON(message.view);
    }
    return obj;
  },

  create(base?: DeepPartial<GetWorkUnitRequest>): GetWorkUnitRequest {
    return GetWorkUnitRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetWorkUnitRequest>): GetWorkUnitRequest {
    const message = createBaseGetWorkUnitRequest() as any;
    message.name = object.name ?? "";
    message.view = object.view ?? 0;
    return message;
  },
};

function createBaseBatchGetWorkUnitsRequest(): BatchGetWorkUnitsRequest {
  return { parent: "", names: [], view: 0 };
}

export const BatchGetWorkUnitsRequest: MessageFns<BatchGetWorkUnitsRequest> = {
  encode(message: BatchGetWorkUnitsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    for (const v of message.names) {
      writer.uint32(18).string(v!);
    }
    if (message.view !== 0) {
      writer.uint32(24).int32(message.view);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchGetWorkUnitsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchGetWorkUnitsRequest() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.names.push(reader.string());
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.view = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchGetWorkUnitsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      names: globalThis.Array.isArray(object?.names) ? object.names.map((e: any) => globalThis.String(e)) : [],
      view: isSet(object.view) ? workUnitViewFromJSON(object.view) : 0,
    };
  },

  toJSON(message: BatchGetWorkUnitsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.names?.length) {
      obj.names = message.names;
    }
    if (message.view !== 0) {
      obj.view = workUnitViewToJSON(message.view);
    }
    return obj;
  },

  create(base?: DeepPartial<BatchGetWorkUnitsRequest>): BatchGetWorkUnitsRequest {
    return BatchGetWorkUnitsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchGetWorkUnitsRequest>): BatchGetWorkUnitsRequest {
    const message = createBaseBatchGetWorkUnitsRequest() as any;
    message.parent = object.parent ?? "";
    message.names = object.names?.map((e) => e) || [];
    message.view = object.view ?? 0;
    return message;
  },
};

function createBaseBatchGetWorkUnitsResponse(): BatchGetWorkUnitsResponse {
  return { workUnits: [] };
}

export const BatchGetWorkUnitsResponse: MessageFns<BatchGetWorkUnitsResponse> = {
  encode(message: BatchGetWorkUnitsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.workUnits) {
      WorkUnit.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchGetWorkUnitsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchGetWorkUnitsResponse() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.workUnits.push(WorkUnit.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchGetWorkUnitsResponse {
    return {
      workUnits: globalThis.Array.isArray(object?.workUnits)
        ? object.workUnits.map((e: any) => WorkUnit.fromJSON(e))
        : [],
    };
  },

  toJSON(message: BatchGetWorkUnitsResponse): unknown {
    const obj: any = {};
    if (message.workUnits?.length) {
      obj.workUnits = message.workUnits.map((e) => WorkUnit.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<BatchGetWorkUnitsResponse>): BatchGetWorkUnitsResponse {
    return BatchGetWorkUnitsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchGetWorkUnitsResponse>): BatchGetWorkUnitsResponse {
    const message = createBaseBatchGetWorkUnitsResponse() as any;
    message.workUnits = object.workUnits?.map((e) => WorkUnit.fromPartial(e)) || [];
    return message;
  },
};

function createBaseQueryWorkUnitsRequest(): QueryWorkUnitsRequest {
  return { parent: "", predicate: undefined, view: 0 };
}

export const QueryWorkUnitsRequest: MessageFns<QueryWorkUnitsRequest> = {
  encode(message: QueryWorkUnitsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.parent !== "") {
      writer.uint32(10).string(message.parent);
    }
    if (message.predicate !== undefined) {
      WorkUnitPredicate.encode(message.predicate, writer.uint32(18).fork()).join();
    }
    if (message.view !== 0) {
      writer.uint32(24).int32(message.view);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryWorkUnitsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryWorkUnitsRequest() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.parent = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.predicate = WorkUnitPredicate.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.view = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryWorkUnitsRequest {
    return {
      parent: isSet(object.parent) ? globalThis.String(object.parent) : "",
      predicate: isSet(object.predicate) ? WorkUnitPredicate.fromJSON(object.predicate) : undefined,
      view: isSet(object.view) ? workUnitViewFromJSON(object.view) : 0,
    };
  },

  toJSON(message: QueryWorkUnitsRequest): unknown {
    const obj: any = {};
    if (message.parent !== "") {
      obj.parent = message.parent;
    }
    if (message.predicate !== undefined) {
      obj.predicate = WorkUnitPredicate.toJSON(message.predicate);
    }
    if (message.view !== 0) {
      obj.view = workUnitViewToJSON(message.view);
    }
    return obj;
  },

  create(base?: DeepPartial<QueryWorkUnitsRequest>): QueryWorkUnitsRequest {
    return QueryWorkUnitsRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryWorkUnitsRequest>): QueryWorkUnitsRequest {
    const message = createBaseQueryWorkUnitsRequest() as any;
    message.parent = object.parent ?? "";
    message.predicate = (object.predicate !== undefined && object.predicate !== null)
      ? WorkUnitPredicate.fromPartial(object.predicate)
      : undefined;
    message.view = object.view ?? 0;
    return message;
  },
};

function createBaseQueryWorkUnitsResponse(): QueryWorkUnitsResponse {
  return { workUnits: [] };
}

export const QueryWorkUnitsResponse: MessageFns<QueryWorkUnitsResponse> = {
  encode(message: QueryWorkUnitsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.workUnits) {
      WorkUnit.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): QueryWorkUnitsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQueryWorkUnitsResponse() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.workUnits.push(WorkUnit.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): QueryWorkUnitsResponse {
    return {
      workUnits: globalThis.Array.isArray(object?.workUnits)
        ? object.workUnits.map((e: any) => WorkUnit.fromJSON(e))
        : [],
    };
  },

  toJSON(message: QueryWorkUnitsResponse): unknown {
    const obj: any = {};
    if (message.workUnits?.length) {
      obj.workUnits = message.workUnits.map((e) => WorkUnit.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<QueryWorkUnitsResponse>): QueryWorkUnitsResponse {
    return QueryWorkUnitsResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<QueryWorkUnitsResponse>): QueryWorkUnitsResponse {
    const message = createBaseQueryWorkUnitsResponse() as any;
    message.workUnits = object.workUnits?.map((e) => WorkUnit.fromPartial(e)) || [];
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(dateStr: string): Timestamp {
  const date = new globalThis.Date(dateStr);
  const seconds = Math.trunc(date.getTime() / 1_000).toString();
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): string {
  let millis = (globalThis.Number(t.seconds) || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis).toISOString();
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
