// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.7.5
//   protoc               v6.32.1
// source: turboci/graph/orchestrator/v1/execution_policy.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import { Duration } from "../../../../google/protobuf/duration.pb";

export const protobufPackage = "turboci.graph.orchestrator.v1";

/**
 * ExecutionPolicy describes constraints on how a Stage may be executed by the
 * Orchestrator.
 */
export interface ExecutionPolicy {
  /** The heartbeat policies for Attempts of this Stage. */
  readonly attemptHeartbeat?:
    | ExecutionPolicy_Heartbeat
    | undefined;
  /** The timeout policies for Attempts of this Stage. */
  readonly attemptTimeout?:
    | ExecutionPolicy_AttemptTimeout
    | undefined;
  /**
   * Policy for retrying this Stage across multiple Attempts.
   *
   * If omitted, the Stage will be attempted at most once.
   */
  readonly retry?:
    | ExecutionPolicy_Retry
    | undefined;
  /**
   * The maximum amount of time the Stage itself can stay in a non-FINAL state.
   *
   * This timeout starts from the time the Stage is *created*.
   *
   * This supersedes all per-Attempt restrictions and is intended to be able
   * to set a cap on the maximum overall amount of time that a stage can take.
   *
   * This MUST be greater than the cumulative timeouts in `attempt_timeout` - it
   * should also account for some amount of time for this Stage to enter the
   * ATTEMPTING state in the first place.
   *
   * Interaction with retries: See `stage_timeout_mode`.
   */
  readonly stageTimeout?:
    | Duration
    | undefined;
  /**
   * Describes how stage_timeout interacts with the Stage state machine.
   *
   * In particular, we want to avoid the situation where the Orchestrator
   * creates 'doomed' Stage Attempts.
   *
   * Consider the case where a Build Stage is allotted a total of 6 hours to be
   * scheduled, execute and complete. If there are only 4 hours left on
   * `stage_timeout`, it likely doesn't make sense to trigger the Build with the
   * intent on killing it off 2 hours before it will likely complete (which
   * would just be a waste of resources).
   *
   * In this scenario, the two modes available today would let you:
   *   * potentially overshoot stage_timeout by 2 hours
   *   * fail the stage with 4 hours of stage_timeout left
   *   * fail the stage with 4 hours of stage_timeout left (unless the stage has
   *     zero attempts, in which case it will overshoot by 2 hours)
   *
   * TBD: it's possible to imagine another mode which runs a final Attempt with
   * a modified `attempt_timeout` - this is likely more complicated (which
   * timeout do you prune? probably pending_throttled?). Leaving this out for
   * now to see how far these other modes get us.
   *
   * If unset, defaults to STAGE_TIMEOUT_MODE_FINISH_CURRENT_ATTEMPT.
   */
  readonly stageTimeoutMode?: ExecutionPolicy_StageTimeoutMode | undefined;
}

/** The description of what happens when `stage_timeout` is reached. */
export enum ExecutionPolicy_StageTimeoutMode {
  /** STAGE_TIMEOUT_MODE_UNKNOWN - UNKNOWN is the invalid mode. */
  STAGE_TIMEOUT_MODE_UNKNOWN = 0,
  /**
   * STAGE_TIMEOUT_MODE_FINISH_CURRENT_ATTEMPT - FINISH_CURRENT_ATTEMPT means that when `stage_timeout` occurs, the
   * Orchestrator will allow the current Attempt to finish within it's
   * configured expiration.
   */
  STAGE_TIMEOUT_MODE_FINISH_CURRENT_ATTEMPT = 1,
  /**
   * STAGE_TIMEOUT_MODE_BLOCK_MAX_EXECUTION_RETRY - BLOCK_MAX_EXECUTION_RETRY means that BEFORE `stage_timeout` occurs, the
   * Orchestrator will calculate if the next Attempt, assuming it runs to the
   * maximum duration of all timeouts in `attempt_timeout`, plus the computed
   * backoff delay, would complete before `stage_timeout`.
   *
   * If it would, then the retry Attempt will be created. Otherwise the
   * Orchestrator will not create a retry.
   *
   * Note that this mode also means that if it took a VERY long time to
   * unblock this Stage, and the Stage Attempt's maximum execution time is
   * also long, it's possible for the Stage to move to FINAL without executing
   * any Attempt at all. See HYBRID for a compromise.
   */
  STAGE_TIMEOUT_MODE_BLOCK_MAX_EXECUTION_RETRY = 2,
  /**
   * STAGE_TIMEOUT_MODE_HYBRID - This is the same as BLOCK_MAX_EXECUTION_RETRY, except that the Stage will
   * always have at least one Attempt (so, it behaves like
   * FINISH_CURRENT_ATTEMPT if the Stage has zero or one Attempts, otherwise
   * like BLOCK_MAX_EXECUTION_RETRY).
   */
  STAGE_TIMEOUT_MODE_HYBRID = 3,
}

export function executionPolicy_StageTimeoutModeFromJSON(object: any): ExecutionPolicy_StageTimeoutMode {
  switch (object) {
    case 0:
    case "STAGE_TIMEOUT_MODE_UNKNOWN":
      return ExecutionPolicy_StageTimeoutMode.STAGE_TIMEOUT_MODE_UNKNOWN;
    case 1:
    case "STAGE_TIMEOUT_MODE_FINISH_CURRENT_ATTEMPT":
      return ExecutionPolicy_StageTimeoutMode.STAGE_TIMEOUT_MODE_FINISH_CURRENT_ATTEMPT;
    case 2:
    case "STAGE_TIMEOUT_MODE_BLOCK_MAX_EXECUTION_RETRY":
      return ExecutionPolicy_StageTimeoutMode.STAGE_TIMEOUT_MODE_BLOCK_MAX_EXECUTION_RETRY;
    case 3:
    case "STAGE_TIMEOUT_MODE_HYBRID":
      return ExecutionPolicy_StageTimeoutMode.STAGE_TIMEOUT_MODE_HYBRID;
    default:
      throw new globalThis.Error("Unrecognized enum value " + object + " for enum ExecutionPolicy_StageTimeoutMode");
  }
}

export function executionPolicy_StageTimeoutModeToJSON(object: ExecutionPolicy_StageTimeoutMode): string {
  switch (object) {
    case ExecutionPolicy_StageTimeoutMode.STAGE_TIMEOUT_MODE_UNKNOWN:
      return "STAGE_TIMEOUT_MODE_UNKNOWN";
    case ExecutionPolicy_StageTimeoutMode.STAGE_TIMEOUT_MODE_FINISH_CURRENT_ATTEMPT:
      return "STAGE_TIMEOUT_MODE_FINISH_CURRENT_ATTEMPT";
    case ExecutionPolicy_StageTimeoutMode.STAGE_TIMEOUT_MODE_BLOCK_MAX_EXECUTION_RETRY:
      return "STAGE_TIMEOUT_MODE_BLOCK_MAX_EXECUTION_RETRY";
    case ExecutionPolicy_StageTimeoutMode.STAGE_TIMEOUT_MODE_HYBRID:
      return "STAGE_TIMEOUT_MODE_HYBRID";
    default:
      throw new globalThis.Error("Unrecognized enum value " + object + " for enum ExecutionPolicy_StageTimeoutMode");
  }
}

/**
 * Heartbeat indicates the minimum heartbeat interval for Stage Attempts in
 * a given state.
 *
 * Heartbeats allow the Orchestrator to detect missing stages sooner than
 * the execution timeout, by declaring non-receipt of a heartbeat message for
 * a certain amount of time to mean that the stage is gone and should be
 * treated accordingly.
 *
 * If, say, `pending` is 30s, it means that the executor must send a Heartbeat
 * RPC to the Orchestrator at least once every 30s while the Stage Attempt is
 * in the PENDING state. It's allowed to heartbeat faster than this interval,
 * but shouldn't be necessary.
 *
 * In addition, we want to ensure that a single lost heartbeat doesn't time
 * out an expensive stage that might be close to completion, so the
 * Orchestrator will allow 1 missed heartbeat before declaring the next
 * non-received heartbeat to mean the stage is gone and should be marked
 * INCOMPLETE. However, missing/late heartbeats will be monitored and alerted
 * on, as they are likely pre-indicators of something about to go wrong.
 *
 * In other words, if the Orchestrator doesn't get an RPC from the Stage
 * Attempt before missing 2 heartbeats the Orchestrator will mark the Stage
 * Attempt as INCOMPLETE.
 *
 * It is expected that clients writing heartbeats will write them at an
 * interval faster than the minimum required here to account for network
 * latency and delays (including contention on a busy client machine).
 * A suggested rule of thumb is to heartbeat at an interval which is 90% of
 * the interval here. So if there is a 30s interval for RUNNING, the client
 * would target doing the RPC to heartbeat every 27 seconds. Ultimately,
 * though, it's up to the Executor how to ensure that a heartbeat gets to the
 * Orchestrator under this deadline.
 *
 * The fields here correspond to StageAttemptState values where a heartbeat
 * is applicable.
 *
 * It is TYPICAL to only define a heartbeat for `running`.
 *
 * Heartbeat intervals, if set, currently cannot exceed 30 minutes.
 */
export interface ExecutionPolicy_Heartbeat {
  /**
   * The expected duration that a Stage Attempt can be in the SCHEDULED
   * state without sending a heartbeat.
   *
   * If unset, then there is no required heartbeat cadence, though the stage
   * is still subject to timeouts for the phase.
   */
  readonly scheduled?:
    | Duration
    | undefined;
  /**
   * The expected duration that a Stage Attempt can be in the RUNNING state
   * without sending a heartbeat.
   *
   * If unset, then there is no required heartbeat cadence, though the stage
   * is still subject to timeouts for the phase.
   *
   * NOTE: This heartbeat still applies during the CANCELLING state - it's
   * expected that CANCELLING only applies to Stage Attempts which are
   * RUNNING, but before the Stage Attempt actually knows this.
   */
  readonly running?:
    | Duration
    | undefined;
  /**
   * The expected duration that a Stage Attempt can be in the TEARING_DOWN
   * state without sending a heartbeat.
   *
   * If unset, then there is no required heartbeat cadence, though the stage
   * is still subject to timeouts for the phase.
   */
  readonly tearingDown?: Duration | undefined;
}

/**
 * AttemptTimeout describes the maximum amount of time a Stage Attempt can be in a
 * given state (in addition to restrictions imposed by Heartbeat).
 *
 * The Orchestrator will automatically transition a Stage Attempt to
 * INCOMPLETE after the timeout has passed if the Stage Attempt has not yet
 * transitioned to the next state.
 */
export interface ExecutionPolicy_AttemptTimeout {
  /**
   * The maximum amount of time a Stage Attempt can be in the
   * PENDING/THROTTLED state.
   *
   * It is calculated from the time the Attempt first enters `PENDING` to the
   * time that it leaves `PENDING` for a non-THROTTLED state.
   *
   * If unset, then there is a large default limit on how long a Stage Attempt
   * can be in the PENDING/THROTTLED state.
   */
  readonly pendingThrottled?:
    | Duration
    | undefined;
  /**
   * The maximum amount of time a Stage Attempt can be in the SCHEDULED
   * state.
   *
   * If unset, then there is a large default limit on how long a Stage Attempt
   * can be in the SCHEDULED state.
   */
  readonly scheduled?:
    | Duration
    | undefined;
  /**
   * The maximum amount of time a Stage Attempt can be in the RUNNING state.
   *
   * If unset, then there is a large default limit on how long a Stage Attempt
   * can be in the RUNNING state.
   *
   * NOTE: This timeout still applies during the CANCELLING state - it's
   * expected that CANCELLING only applies to Stage Attempts which are
   * RUNNING, but before the Stage Attempt actually knows this.
   */
  readonly running?:
    | Duration
    | undefined;
  /**
   * The maximum amount of time a Stage Attempt can be in the
   * TEARING_DOWN state.
   *
   * If unset, then there is a large default limit on how long a Stage Attempt can be in
   * the TEARING_DOWN state.
   */
  readonly tearingDown?: Duration | undefined;
}

/** Retry describes the policy for retrying a Stage across multiple Attempts. */
export interface ExecutionPolicy_Retry {
  /**
   * The maximum number of retries (apart from the first attempt) that will be
   * made for this Stage.
   */
  readonly maxRetries?: number | undefined;
}

function createBaseExecutionPolicy(): ExecutionPolicy {
  return {
    attemptHeartbeat: undefined,
    attemptTimeout: undefined,
    retry: undefined,
    stageTimeout: undefined,
    stageTimeoutMode: undefined,
  };
}

export const ExecutionPolicy: MessageFns<ExecutionPolicy> = {
  encode(message: ExecutionPolicy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.attemptHeartbeat !== undefined) {
      ExecutionPolicy_Heartbeat.encode(message.attemptHeartbeat, writer.uint32(18).fork()).join();
    }
    if (message.attemptTimeout !== undefined) {
      ExecutionPolicy_AttemptTimeout.encode(message.attemptTimeout, writer.uint32(26).fork()).join();
    }
    if (message.retry !== undefined) {
      ExecutionPolicy_Retry.encode(message.retry, writer.uint32(34).fork()).join();
    }
    if (message.stageTimeout !== undefined) {
      Duration.encode(message.stageTimeout, writer.uint32(42).fork()).join();
    }
    if (message.stageTimeoutMode !== undefined) {
      writer.uint32(48).int32(message.stageTimeoutMode);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExecutionPolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExecutionPolicy() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.attemptHeartbeat = ExecutionPolicy_Heartbeat.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.attemptTimeout = ExecutionPolicy_AttemptTimeout.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.retry = ExecutionPolicy_Retry.decode(reader, reader.uint32());
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.stageTimeout = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 6: {
          if (tag !== 48) {
            break;
          }

          message.stageTimeoutMode = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExecutionPolicy {
    return {
      attemptHeartbeat: isSet(object.attemptHeartbeat)
        ? ExecutionPolicy_Heartbeat.fromJSON(object.attemptHeartbeat)
        : undefined,
      attemptTimeout: isSet(object.attemptTimeout)
        ? ExecutionPolicy_AttemptTimeout.fromJSON(object.attemptTimeout)
        : undefined,
      retry: isSet(object.retry) ? ExecutionPolicy_Retry.fromJSON(object.retry) : undefined,
      stageTimeout: isSet(object.stageTimeout) ? Duration.fromJSON(object.stageTimeout) : undefined,
      stageTimeoutMode: isSet(object.stageTimeoutMode)
        ? executionPolicy_StageTimeoutModeFromJSON(object.stageTimeoutMode)
        : undefined,
    };
  },

  toJSON(message: ExecutionPolicy): unknown {
    const obj: any = {};
    if (message.attemptHeartbeat !== undefined) {
      obj.attemptHeartbeat = ExecutionPolicy_Heartbeat.toJSON(message.attemptHeartbeat);
    }
    if (message.attemptTimeout !== undefined) {
      obj.attemptTimeout = ExecutionPolicy_AttemptTimeout.toJSON(message.attemptTimeout);
    }
    if (message.retry !== undefined) {
      obj.retry = ExecutionPolicy_Retry.toJSON(message.retry);
    }
    if (message.stageTimeout !== undefined) {
      obj.stageTimeout = Duration.toJSON(message.stageTimeout);
    }
    if (message.stageTimeoutMode !== undefined) {
      obj.stageTimeoutMode = executionPolicy_StageTimeoutModeToJSON(message.stageTimeoutMode);
    }
    return obj;
  },

  create(base?: DeepPartial<ExecutionPolicy>): ExecutionPolicy {
    return ExecutionPolicy.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExecutionPolicy>): ExecutionPolicy {
    const message = createBaseExecutionPolicy() as any;
    message.attemptHeartbeat = (object.attemptHeartbeat !== undefined && object.attemptHeartbeat !== null)
      ? ExecutionPolicy_Heartbeat.fromPartial(object.attemptHeartbeat)
      : undefined;
    message.attemptTimeout = (object.attemptTimeout !== undefined && object.attemptTimeout !== null)
      ? ExecutionPolicy_AttemptTimeout.fromPartial(object.attemptTimeout)
      : undefined;
    message.retry = (object.retry !== undefined && object.retry !== null)
      ? ExecutionPolicy_Retry.fromPartial(object.retry)
      : undefined;
    message.stageTimeout = (object.stageTimeout !== undefined && object.stageTimeout !== null)
      ? Duration.fromPartial(object.stageTimeout)
      : undefined;
    message.stageTimeoutMode = object.stageTimeoutMode ?? undefined;
    return message;
  },
};

function createBaseExecutionPolicy_Heartbeat(): ExecutionPolicy_Heartbeat {
  return { scheduled: undefined, running: undefined, tearingDown: undefined };
}

export const ExecutionPolicy_Heartbeat: MessageFns<ExecutionPolicy_Heartbeat> = {
  encode(message: ExecutionPolicy_Heartbeat, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.scheduled !== undefined) {
      Duration.encode(message.scheduled, writer.uint32(10).fork()).join();
    }
    if (message.running !== undefined) {
      Duration.encode(message.running, writer.uint32(18).fork()).join();
    }
    if (message.tearingDown !== undefined) {
      Duration.encode(message.tearingDown, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExecutionPolicy_Heartbeat {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExecutionPolicy_Heartbeat() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.scheduled = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.running = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.tearingDown = Duration.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExecutionPolicy_Heartbeat {
    return {
      scheduled: isSet(object.scheduled) ? Duration.fromJSON(object.scheduled) : undefined,
      running: isSet(object.running) ? Duration.fromJSON(object.running) : undefined,
      tearingDown: isSet(object.tearingDown) ? Duration.fromJSON(object.tearingDown) : undefined,
    };
  },

  toJSON(message: ExecutionPolicy_Heartbeat): unknown {
    const obj: any = {};
    if (message.scheduled !== undefined) {
      obj.scheduled = Duration.toJSON(message.scheduled);
    }
    if (message.running !== undefined) {
      obj.running = Duration.toJSON(message.running);
    }
    if (message.tearingDown !== undefined) {
      obj.tearingDown = Duration.toJSON(message.tearingDown);
    }
    return obj;
  },

  create(base?: DeepPartial<ExecutionPolicy_Heartbeat>): ExecutionPolicy_Heartbeat {
    return ExecutionPolicy_Heartbeat.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExecutionPolicy_Heartbeat>): ExecutionPolicy_Heartbeat {
    const message = createBaseExecutionPolicy_Heartbeat() as any;
    message.scheduled = (object.scheduled !== undefined && object.scheduled !== null)
      ? Duration.fromPartial(object.scheduled)
      : undefined;
    message.running = (object.running !== undefined && object.running !== null)
      ? Duration.fromPartial(object.running)
      : undefined;
    message.tearingDown = (object.tearingDown !== undefined && object.tearingDown !== null)
      ? Duration.fromPartial(object.tearingDown)
      : undefined;
    return message;
  },
};

function createBaseExecutionPolicy_AttemptTimeout(): ExecutionPolicy_AttemptTimeout {
  return { pendingThrottled: undefined, scheduled: undefined, running: undefined, tearingDown: undefined };
}

export const ExecutionPolicy_AttemptTimeout: MessageFns<ExecutionPolicy_AttemptTimeout> = {
  encode(message: ExecutionPolicy_AttemptTimeout, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.pendingThrottled !== undefined) {
      Duration.encode(message.pendingThrottled, writer.uint32(10).fork()).join();
    }
    if (message.scheduled !== undefined) {
      Duration.encode(message.scheduled, writer.uint32(18).fork()).join();
    }
    if (message.running !== undefined) {
      Duration.encode(message.running, writer.uint32(26).fork()).join();
    }
    if (message.tearingDown !== undefined) {
      Duration.encode(message.tearingDown, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExecutionPolicy_AttemptTimeout {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExecutionPolicy_AttemptTimeout() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.pendingThrottled = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.scheduled = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.running = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.tearingDown = Duration.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExecutionPolicy_AttemptTimeout {
    return {
      pendingThrottled: isSet(object.pendingThrottled) ? Duration.fromJSON(object.pendingThrottled) : undefined,
      scheduled: isSet(object.scheduled) ? Duration.fromJSON(object.scheduled) : undefined,
      running: isSet(object.running) ? Duration.fromJSON(object.running) : undefined,
      tearingDown: isSet(object.tearingDown) ? Duration.fromJSON(object.tearingDown) : undefined,
    };
  },

  toJSON(message: ExecutionPolicy_AttemptTimeout): unknown {
    const obj: any = {};
    if (message.pendingThrottled !== undefined) {
      obj.pendingThrottled = Duration.toJSON(message.pendingThrottled);
    }
    if (message.scheduled !== undefined) {
      obj.scheduled = Duration.toJSON(message.scheduled);
    }
    if (message.running !== undefined) {
      obj.running = Duration.toJSON(message.running);
    }
    if (message.tearingDown !== undefined) {
      obj.tearingDown = Duration.toJSON(message.tearingDown);
    }
    return obj;
  },

  create(base?: DeepPartial<ExecutionPolicy_AttemptTimeout>): ExecutionPolicy_AttemptTimeout {
    return ExecutionPolicy_AttemptTimeout.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExecutionPolicy_AttemptTimeout>): ExecutionPolicy_AttemptTimeout {
    const message = createBaseExecutionPolicy_AttemptTimeout() as any;
    message.pendingThrottled = (object.pendingThrottled !== undefined && object.pendingThrottled !== null)
      ? Duration.fromPartial(object.pendingThrottled)
      : undefined;
    message.scheduled = (object.scheduled !== undefined && object.scheduled !== null)
      ? Duration.fromPartial(object.scheduled)
      : undefined;
    message.running = (object.running !== undefined && object.running !== null)
      ? Duration.fromPartial(object.running)
      : undefined;
    message.tearingDown = (object.tearingDown !== undefined && object.tearingDown !== null)
      ? Duration.fromPartial(object.tearingDown)
      : undefined;
    return message;
  },
};

function createBaseExecutionPolicy_Retry(): ExecutionPolicy_Retry {
  return { maxRetries: undefined };
}

export const ExecutionPolicy_Retry: MessageFns<ExecutionPolicy_Retry> = {
  encode(message: ExecutionPolicy_Retry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.maxRetries !== undefined) {
      writer.uint32(8).int32(message.maxRetries);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExecutionPolicy_Retry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExecutionPolicy_Retry() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.maxRetries = reader.int32();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExecutionPolicy_Retry {
    return { maxRetries: isSet(object.maxRetries) ? globalThis.Number(object.maxRetries) : undefined };
  },

  toJSON(message: ExecutionPolicy_Retry): unknown {
    const obj: any = {};
    if (message.maxRetries !== undefined) {
      obj.maxRetries = Math.round(message.maxRetries);
    }
    return obj;
  },

  create(base?: DeepPartial<ExecutionPolicy_Retry>): ExecutionPolicy_Retry {
    return ExecutionPolicy_Retry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<ExecutionPolicy_Retry>): ExecutionPolicy_Retry {
    const message = createBaseExecutionPolicy_Retry() as any;
    message.maxRetries = object.maxRetries ?? undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
