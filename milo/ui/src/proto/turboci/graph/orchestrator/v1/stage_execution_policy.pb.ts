// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.7.5
//   protoc               v6.32.1
// source: turboci/graph/orchestrator/v1/stage_execution_policy.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import { Duration } from "../../../../google/protobuf/duration.pb";
import { StageAttemptExecutionPolicy } from "./stage_attempt_execution_policy.pb";

export const protobufPackage = "turboci.graph.orchestrator.v1";

/**
 * StageExecutionPolicy describes constraints on how a Stage may be executed by the
 * Orchestrator.
 */
export interface StageExecutionPolicy {
  /**
   * Policy for retrying this Stage across multiple Attempts.
   *
   * If omitted, the Stage will be attempted at most once.
   */
  readonly retry?:
    | StageExecutionPolicy_Retry
    | undefined;
  /**
   * The maximum amount of time the Stage itself can stay in a non-FINAL state.
   *
   * This timeout starts from the time the Stage is *created*.
   *
   * This supersedes all per-Attempt restrictions and is intended to be able
   * to set a cap on the maximum overall amount of time that a stage can take.
   *
   * This MUST be greater than the cumulative timeouts in `attempt_timeout` - it
   * should also account for some amount of time for this Stage to enter the
   * ATTEMPTING state in the first place.
   *
   * Interaction with retries: See `stage_timeout_mode`.
   */
  readonly stageTimeout?:
    | Duration
    | undefined;
  /**
   * Describes how stage_timeout interacts with the Stage state machine.
   *
   * In particular, we want to avoid the situation where the Orchestrator
   * creates 'doomed' Stage Attempts.
   *
   * Consider the case where a Build Stage is allotted a total of 6 hours to be
   * scheduled, execute and complete. If there are only 4 hours left on
   * `stage_timeout`, it likely doesn't make sense to trigger the Build with the
   * intent on killing it off 2 hours before it will likely complete (which
   * would just be a waste of resources).
   *
   * In this scenario, the two modes available today would let you:
   *   * potentially overshoot stage_timeout by 2 hours
   *   * fail the stage with 4 hours of stage_timeout left
   *   * fail the stage with 4 hours of stage_timeout left (unless the stage has
   *     zero attempts, in which case it will overshoot by 2 hours)
   *
   * TBD: it's possible to imagine another mode which runs a final Attempt with
   * a modified `attempt_timeout` - this is likely more complicated (which
   * timeout do you prune? probably pending_throttled?). Leaving this out for
   * now to see how far these other modes get us.
   *
   * If unset, defaults to STAGE_TIMEOUT_MODE_FINISH_CURRENT_ATTEMPT.
   */
  readonly stageTimeoutMode?:
    | StageExecutionPolicy_StageTimeoutMode
    | undefined;
  /**
   * Template for attempt level execution policy.
   *
   * Each attempt will be created with this policy as requested. But the
   * executor may augment the policy by merging the requested policy and what
   * is in the configs.
   */
  readonly attemptExecutionPolicyTemplate?: StageAttemptExecutionPolicy | undefined;
}

/** The description of what happens when `stage_timeout` is reached. */
export enum StageExecutionPolicy_StageTimeoutMode {
  /** STAGE_TIMEOUT_MODE_UNKNOWN - UNKNOWN is the invalid mode. */
  STAGE_TIMEOUT_MODE_UNKNOWN = 0,
  /**
   * STAGE_TIMEOUT_MODE_FINISH_CURRENT_ATTEMPT - FINISH_CURRENT_ATTEMPT means that when `stage_timeout` occurs, the
   * Orchestrator will allow the current Attempt to finish within it's
   * configured expiration.
   */
  STAGE_TIMEOUT_MODE_FINISH_CURRENT_ATTEMPT = 1,
  /**
   * STAGE_TIMEOUT_MODE_BLOCK_MAX_EXECUTION_RETRY - BLOCK_MAX_EXECUTION_RETRY means that BEFORE `stage_timeout` occurs, the
   * Orchestrator will calculate if the next Attempt, assuming it runs to the
   * maximum duration of all timeouts in `attempt_timeout`, plus the computed
   * backoff delay, would complete before `stage_timeout`.
   *
   * If it would, then the retry Attempt will be created. Otherwise the
   * Orchestrator will not create a retry.
   *
   * Note that this mode also means that if it took a VERY long time to
   * unblock this Stage, and the Stage Attempt's maximum execution time is
   * also long, it's possible for the Stage to move to FINAL without executing
   * any Attempt at all. See HYBRID for a compromise.
   */
  STAGE_TIMEOUT_MODE_BLOCK_MAX_EXECUTION_RETRY = 2,
  /**
   * STAGE_TIMEOUT_MODE_HYBRID - This is the same as BLOCK_MAX_EXECUTION_RETRY, except that the Stage will
   * always have at least one Attempt (so, it behaves like
   * FINISH_CURRENT_ATTEMPT if the Stage has zero or one Attempts, otherwise
   * like BLOCK_MAX_EXECUTION_RETRY).
   */
  STAGE_TIMEOUT_MODE_HYBRID = 3,
}

export function stageExecutionPolicy_StageTimeoutModeFromJSON(object: any): StageExecutionPolicy_StageTimeoutMode {
  switch (object) {
    case 0:
    case "STAGE_TIMEOUT_MODE_UNKNOWN":
      return StageExecutionPolicy_StageTimeoutMode.STAGE_TIMEOUT_MODE_UNKNOWN;
    case 1:
    case "STAGE_TIMEOUT_MODE_FINISH_CURRENT_ATTEMPT":
      return StageExecutionPolicy_StageTimeoutMode.STAGE_TIMEOUT_MODE_FINISH_CURRENT_ATTEMPT;
    case 2:
    case "STAGE_TIMEOUT_MODE_BLOCK_MAX_EXECUTION_RETRY":
      return StageExecutionPolicy_StageTimeoutMode.STAGE_TIMEOUT_MODE_BLOCK_MAX_EXECUTION_RETRY;
    case 3:
    case "STAGE_TIMEOUT_MODE_HYBRID":
      return StageExecutionPolicy_StageTimeoutMode.STAGE_TIMEOUT_MODE_HYBRID;
    default:
      throw new globalThis.Error(
        "Unrecognized enum value " + object + " for enum StageExecutionPolicy_StageTimeoutMode",
      );
  }
}

export function stageExecutionPolicy_StageTimeoutModeToJSON(object: StageExecutionPolicy_StageTimeoutMode): string {
  switch (object) {
    case StageExecutionPolicy_StageTimeoutMode.STAGE_TIMEOUT_MODE_UNKNOWN:
      return "STAGE_TIMEOUT_MODE_UNKNOWN";
    case StageExecutionPolicy_StageTimeoutMode.STAGE_TIMEOUT_MODE_FINISH_CURRENT_ATTEMPT:
      return "STAGE_TIMEOUT_MODE_FINISH_CURRENT_ATTEMPT";
    case StageExecutionPolicy_StageTimeoutMode.STAGE_TIMEOUT_MODE_BLOCK_MAX_EXECUTION_RETRY:
      return "STAGE_TIMEOUT_MODE_BLOCK_MAX_EXECUTION_RETRY";
    case StageExecutionPolicy_StageTimeoutMode.STAGE_TIMEOUT_MODE_HYBRID:
      return "STAGE_TIMEOUT_MODE_HYBRID";
    default:
      throw new globalThis.Error(
        "Unrecognized enum value " + object + " for enum StageExecutionPolicy_StageTimeoutMode",
      );
  }
}

/** Retry describes the policy for retrying a Stage across multiple Attempts. */
export interface StageExecutionPolicy_Retry {
  /**
   * The maximum number of retries (apart from the first attempt) that will be
   * made for this Stage.
   */
  readonly maxRetries?: number | undefined;
}

function createBaseStageExecutionPolicy(): StageExecutionPolicy {
  return {
    retry: undefined,
    stageTimeout: undefined,
    stageTimeoutMode: undefined,
    attemptExecutionPolicyTemplate: undefined,
  };
}

export const StageExecutionPolicy: MessageFns<StageExecutionPolicy> = {
  encode(message: StageExecutionPolicy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.retry !== undefined) {
      StageExecutionPolicy_Retry.encode(message.retry, writer.uint32(10).fork()).join();
    }
    if (message.stageTimeout !== undefined) {
      Duration.encode(message.stageTimeout, writer.uint32(18).fork()).join();
    }
    if (message.stageTimeoutMode !== undefined) {
      writer.uint32(24).int32(message.stageTimeoutMode);
    }
    if (message.attemptExecutionPolicyTemplate !== undefined) {
      StageAttemptExecutionPolicy.encode(message.attemptExecutionPolicyTemplate, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StageExecutionPolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStageExecutionPolicy() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.retry = StageExecutionPolicy_Retry.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.stageTimeout = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.stageTimeoutMode = reader.int32() as any;
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.attemptExecutionPolicyTemplate = StageAttemptExecutionPolicy.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StageExecutionPolicy {
    return {
      retry: isSet(object.retry) ? StageExecutionPolicy_Retry.fromJSON(object.retry) : undefined,
      stageTimeout: isSet(object.stageTimeout) ? Duration.fromJSON(object.stageTimeout) : undefined,
      stageTimeoutMode: isSet(object.stageTimeoutMode)
        ? stageExecutionPolicy_StageTimeoutModeFromJSON(object.stageTimeoutMode)
        : undefined,
      attemptExecutionPolicyTemplate: isSet(object.attemptExecutionPolicyTemplate)
        ? StageAttemptExecutionPolicy.fromJSON(object.attemptExecutionPolicyTemplate)
        : undefined,
    };
  },

  toJSON(message: StageExecutionPolicy): unknown {
    const obj: any = {};
    if (message.retry !== undefined) {
      obj.retry = StageExecutionPolicy_Retry.toJSON(message.retry);
    }
    if (message.stageTimeout !== undefined) {
      obj.stageTimeout = Duration.toJSON(message.stageTimeout);
    }
    if (message.stageTimeoutMode !== undefined) {
      obj.stageTimeoutMode = stageExecutionPolicy_StageTimeoutModeToJSON(message.stageTimeoutMode);
    }
    if (message.attemptExecutionPolicyTemplate !== undefined) {
      obj.attemptExecutionPolicyTemplate = StageAttemptExecutionPolicy.toJSON(message.attemptExecutionPolicyTemplate);
    }
    return obj;
  },

  create(base?: DeepPartial<StageExecutionPolicy>): StageExecutionPolicy {
    return StageExecutionPolicy.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StageExecutionPolicy>): StageExecutionPolicy {
    const message = createBaseStageExecutionPolicy() as any;
    message.retry = (object.retry !== undefined && object.retry !== null)
      ? StageExecutionPolicy_Retry.fromPartial(object.retry)
      : undefined;
    message.stageTimeout = (object.stageTimeout !== undefined && object.stageTimeout !== null)
      ? Duration.fromPartial(object.stageTimeout)
      : undefined;
    message.stageTimeoutMode = object.stageTimeoutMode ?? undefined;
    message.attemptExecutionPolicyTemplate =
      (object.attemptExecutionPolicyTemplate !== undefined && object.attemptExecutionPolicyTemplate !== null)
        ? StageAttemptExecutionPolicy.fromPartial(object.attemptExecutionPolicyTemplate)
        : undefined;
    return message;
  },
};

function createBaseStageExecutionPolicy_Retry(): StageExecutionPolicy_Retry {
  return { maxRetries: undefined };
}

export const StageExecutionPolicy_Retry: MessageFns<StageExecutionPolicy_Retry> = {
  encode(message: StageExecutionPolicy_Retry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.maxRetries !== undefined) {
      writer.uint32(8).int32(message.maxRetries);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StageExecutionPolicy_Retry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStageExecutionPolicy_Retry() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.maxRetries = reader.int32();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StageExecutionPolicy_Retry {
    return { maxRetries: isSet(object.maxRetries) ? globalThis.Number(object.maxRetries) : undefined };
  },

  toJSON(message: StageExecutionPolicy_Retry): unknown {
    const obj: any = {};
    if (message.maxRetries !== undefined) {
      obj.maxRetries = Math.round(message.maxRetries);
    }
    return obj;
  },

  create(base?: DeepPartial<StageExecutionPolicy_Retry>): StageExecutionPolicy_Retry {
    return StageExecutionPolicy_Retry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StageExecutionPolicy_Retry>): StageExecutionPolicy_Retry {
    const message = createBaseStageExecutionPolicy_Retry() as any;
    message.maxRetries = object.maxRetries ?? undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
