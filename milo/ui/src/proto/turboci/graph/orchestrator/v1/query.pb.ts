// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.8.1
//   protoc               v6.32.0
// source: turboci/graph/orchestrator/v1/query.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import { Identifier, WorkPlan } from "../../ids/v1/identifier.pb";
import { CheckKind, checkKindFromJSON, checkKindToJSON } from "./check_kind.pb";
import { CheckState, checkStateFromJSON, checkStateToJSON } from "./check_state.pb";
import { RevisionRange } from "./revision_range.pb";
import { StageState, stageStateFromJSON, stageStateToJSON } from "./stage_state.pb";
import { TypeSet } from "./type_set.pb";

export const protobufPackage = "turboci.graph.orchestrator.v1";

/**
 * When expanding a query selection set with Query.ExpandDependencies or
 * Query.ExpandDependents, how should we actually expand that set?
 */
export enum QueryExpandDepsMode {
  /**
   * QUERY_EXPAND_DEPS_MODE_UNKNOWN - Unknown query expansion mode.
   *
   * Equivalent to QUERY_EXPAND_DEPS_MODE_EDGES.
   */
  QUERY_EXPAND_DEPS_MODE_UNKNOWN = 0,
  /** QUERY_EXPAND_DEPS_MODE_EDGES - Expand to deps which are listed in dependencies.edges. */
  QUERY_EXPAND_DEPS_MODE_EDGES = 1,
  /**
   * QUERY_EXPAND_DEPS_MODE_SATISFIED - Expand to edges which were the ones that caused dependencies.resolved to be
   * RESOLUTION_SATISFIED.
   *
   * Note that this will be the empty set for nodes which are not already past
   * the PLANNED state, and for nodes which have RESOLUTION_UNSATISFIED
   * dependencies.
   */
  QUERY_EXPAND_DEPS_MODE_SATISFIED = 2,
}

export function queryExpandDepsModeFromJSON(object: any): QueryExpandDepsMode {
  switch (object) {
    case 0:
    case "QUERY_EXPAND_DEPS_MODE_UNKNOWN":
      return QueryExpandDepsMode.QUERY_EXPAND_DEPS_MODE_UNKNOWN;
    case 1:
    case "QUERY_EXPAND_DEPS_MODE_EDGES":
      return QueryExpandDepsMode.QUERY_EXPAND_DEPS_MODE_EDGES;
    case 2:
    case "QUERY_EXPAND_DEPS_MODE_SATISFIED":
      return QueryExpandDepsMode.QUERY_EXPAND_DEPS_MODE_SATISFIED;
    default:
      throw new globalThis.Error("Unrecognized enum value " + object + " for enum QueryExpandDepsMode");
  }
}

export function queryExpandDepsModeToJSON(object: QueryExpandDepsMode): string {
  switch (object) {
    case QueryExpandDepsMode.QUERY_EXPAND_DEPS_MODE_UNKNOWN:
      return "QUERY_EXPAND_DEPS_MODE_UNKNOWN";
    case QueryExpandDepsMode.QUERY_EXPAND_DEPS_MODE_EDGES:
      return "QUERY_EXPAND_DEPS_MODE_EDGES";
    case QueryExpandDepsMode.QUERY_EXPAND_DEPS_MODE_SATISFIED:
      return "QUERY_EXPAND_DEPS_MODE_SATISFIED";
    default:
      throw new globalThis.Error("Unrecognized enum value " + object + " for enum QueryExpandDepsMode");
  }
}

/** Defines what subset of Stage Attempts to include when returning a Stage. */
export enum CollectStageAttempts {
  /**
   * COLLECT_STAGE_ATTEMPTS_UNKNOWN - UNKNOWN is the default value.
   *
   * Equivalent to COLLECT_STAGE_ATTEMPTS_NONE.
   */
  COLLECT_STAGE_ATTEMPTS_UNKNOWN = 0,
  /** COLLECT_STAGE_ATTEMPTS_NONE - No stage attempts will be returned, this is default. */
  COLLECT_STAGE_ATTEMPTS_NONE = 1,
  /** COLLECT_STAGE_ATTEMPTS_ALL - All stage attempts will be returned. */
  COLLECT_STAGE_ATTEMPTS_ALL = 2,
  /**
   * COLLECT_STAGE_ATTEMPTS_LATEST - Only the latest stage attempt will be returned.
   *
   * All non-latest attempts will be represented by shallow entries just
   * containing their ID (to preserve the invariant that Stage.attempt[x] has
   * ID with Idx `x+1`).
   */
  COLLECT_STAGE_ATTEMPTS_LATEST = 3,
}

export function collectStageAttemptsFromJSON(object: any): CollectStageAttempts {
  switch (object) {
    case 0:
    case "COLLECT_STAGE_ATTEMPTS_UNKNOWN":
      return CollectStageAttempts.COLLECT_STAGE_ATTEMPTS_UNKNOWN;
    case 1:
    case "COLLECT_STAGE_ATTEMPTS_NONE":
      return CollectStageAttempts.COLLECT_STAGE_ATTEMPTS_NONE;
    case 2:
    case "COLLECT_STAGE_ATTEMPTS_ALL":
      return CollectStageAttempts.COLLECT_STAGE_ATTEMPTS_ALL;
    case 3:
    case "COLLECT_STAGE_ATTEMPTS_LATEST":
      return CollectStageAttempts.COLLECT_STAGE_ATTEMPTS_LATEST;
    default:
      throw new globalThis.Error("Unrecognized enum value " + object + " for enum CollectStageAttempts");
  }
}

export function collectStageAttemptsToJSON(object: CollectStageAttempts): string {
  switch (object) {
    case CollectStageAttempts.COLLECT_STAGE_ATTEMPTS_UNKNOWN:
      return "COLLECT_STAGE_ATTEMPTS_UNKNOWN";
    case CollectStageAttempts.COLLECT_STAGE_ATTEMPTS_NONE:
      return "COLLECT_STAGE_ATTEMPTS_NONE";
    case CollectStageAttempts.COLLECT_STAGE_ATTEMPTS_ALL:
      return "COLLECT_STAGE_ATTEMPTS_ALL";
    case CollectStageAttempts.COLLECT_STAGE_ATTEMPTS_LATEST:
      return "COLLECT_STAGE_ATTEMPTS_LATEST";
    default:
      throw new globalThis.Error("Unrecognized enum value " + object + " for enum CollectStageAttempts");
  }
}

/**
 * Query describes a single graph query.
 *
 * This is composed of 3 phases: selection with filtering, expansion and
 * collection.
 *
 * The selection phase (represented by fields `node_set`, `select_stages` and
 * `select_checks`) either just picks the given set of nodes or selects
 * all nodes within a matching set of work plans (most commonly just some
 * single plan). Selected nodes then are optionally filtered based on their
 * type and properties.
 *
 * After the filtering phase, the expansion phase (represented by fields
 * `expand_dependencies` and `expand_dependents`) allows traversal along the
 * edges of the selected nodes. Currently only 'dependency' edge traversal is
 * supported, but other types of relationships could be possible in the future
 * (e.g. 'created_by', 'written_by', etc.).
 *
 * Finally, after the set of nodes has been fully expanded, we collect all the
 * requested data from those Nodes. This phase is represented by fields
 * `collect_checks` and `collect_stages`.
 *
 *                  ┌──────────┐
 *           ┌──────┤ node_set ├─────┐
 *           │      └──────────┘     │
 *           ▼                       ▼
 *    ┌─────────────┐         ┌─────────────┐
 *    │select_checks│         │select_stages│      Select + Filter
 *    └──────┬──────┘         └──────┬──────┘
 *           │                       │
 *           │       ┌───────┐       │
 *           └──────►│       │◄──────┘
 *                   │<union>│
 *           ┌───────┤       ├───────┐
 *           │       └───────┘       │
 *           ▼            │          ▼
 *  ┌───────────────────┐ │ ┌─────────────────┐
 *  │expand_dependencies│ │ │expand_dependents│    Expand
 *  └────────┬──────────┘ │ └────────┬────────┘
 *           │            ▼          │
 *           │       ┌───────┐       │
 *           └──────►│       │◄──────┘
 *                   │<union>│
 *           ┌───────┤       ├───────┐
 *           │       └───────┘       │
 *           │                       │
 *           ▼                       ▼
 *    ┌──────────────┐       ┌──────────────┐
 *    │collect_checks│       │collect_stages│      Collect
 *    └──────┬───────┘       └───────┬──────┘
 *           │                       │
 *           │      ┌─────────┐      │
 *           └─────►│GraphView│◄─────┘
 *                  └─────────┘
 *
 * See QueryNodesRequest.version for how this Query interacts with transactions.
 *
 * Queries that are guaranteed to produce no results (like a query with
 * only `select_stages`, no expansion, and no `collect_stages`) are rejected
 * as invalid, resulting in INVALID_ARGUMENT error from QueryNodes.
 */
export interface Query {
  /** Select all nodes in the given work plan. */
  readonly nodesInWorkplan?:
    | WorkPlan
    | undefined;
  /** Select all nodes in all work plans matching some criteria. */
  readonly nodesAcrossWorkplans?:
    | Query_NodesAcrossWorkPlans
    | undefined;
  /** Select the explicitly given set of nodes. */
  readonly nodesById?:
    | Query_NodesByID
    | undefined;
  /**
   * If present, indicates the query wants to examine Checks.
   *
   * At least one of `select_checks` or `select_stages` must be set.
   */
  readonly selectChecks?:
    | Query_SelectChecks
    | undefined;
  /**
   * If present, indicates the query wants to examine Stages.
   *
   * At least one of `select_checks` or `select_stages` must be set.
   */
  readonly selectStages?:
    | Query_SelectStages
    | undefined;
  /**
   * For each selected Check or Stage, include its immediate dependencies.
   *
   * So given:
   *   A -> {B, C}
   *
   * (B, C) are dependencies of A.
   */
  readonly expandDependencies?:
    | Query_ExpandDependencies
    | undefined;
  /**
   * For each selected Check or Stage, include any Checks/Stages which depend
   * on it.
   *
   * So given:
   *   A -> {B, C}
   *
   * A is a dependent of B.
   */
  readonly expandDependents?:
    | Query_ExpandDependents
    | undefined;
  /**
   * If present, indicates the caller is interested in Checks processed by
   * the query (including the originally selected checks, if any, and all checks
   * discovered during the Expand phase).
   *
   * If absent, the result will have no checks at all.
   *
   * At least one of `collect_checks` or `collect_stages` must be set.
   */
  readonly collectChecks?:
    | Query_CollectChecks
    | undefined;
  /**
   * If present, indicates the caller is interested in Stages processed by
   * the query (including the originally selected stages, if any, and all stages
   * discovered during the Expand phase).
   *
   * If absent, the result will have no stages at all.
   *
   * At least one of `collect_checks` or `collect_stages` must be set.
   */
  readonly collectStages?: Query_CollectStages | undefined;
}

/** Indicates to work with all nodes in the matching set of work plans. */
export interface Query_NodesAcrossWorkPlans {
}

/** Indicates to work only with the given list of nodes. */
export interface Query_NodesByID {
  /**
   * The identifiers of specific nodes to select.
   *
   * This should be used if you already know the identifiers of the nodes you
   * care about.
   *
   * These nodes will be subjected to `select_checks` and `select_stages`
   * predicates. This allowed to e.g. examine if any of the already known
   * nodes are in a particular expected state already.
   *
   * Nodes that don't exist at all will be skipped and their IDs will be
   * returned in QueryNodesResponse.absent.
   */
  readonly nodes: readonly Identifier[];
}

/**
 * If present, indicates the query wants to examine Checks, optionally
 * passing them through the given filtering predicate before proceeding.
 *
 * The outcome of this phase is joined with the outcome of a similar
 * SelectStages phase before being passed to Expand and Collect phases.
 *
 * If not set, the query will not be selecting any Check nodes at the
 * selection phase (note you still may see Checks in the overall result
 * if `collect_checks` is present and some Checks were discovered during
 * the Expand phase).
 */
export interface Query_SelectChecks {
  /**
   * Pick Checks matching any of these predicates (they are ORed together).
   *
   * If empty, all Checks will be selected.
   */
  readonly predicates: readonly Query_SelectChecks_Predicate[];
}

/**
 * Only pick Checks which match this predicate.
 *
 * Individual clauses are ANDed together. An unset field means the
 * corresponding clause is not checked. At least one field must be set.
 */
export interface Query_SelectChecks_Predicate {
  /** Pick Checks of this kind. */
  readonly kind?:
    | CheckKind
    | undefined;
  /** Pick Checks in this state. */
  readonly state?:
    | CheckState
    | undefined;
  /**
   * Pick Checks that have a Check Option that matches the type filter.
   *
   * Note that you still must set QueryNodesRequest.type_info.wanted and
   * collect_checks.options to actually get the Check Option data in
   * the result set.
   */
  readonly withOptionType?:
    | TypeSet
    | undefined;
  /**
   * Pick Checks that have a Check Result that matches the type filter.
   *
   * Note that you still must set QueryNodesRequest.type_info.wanted and
   * collect_checks.result_data to actually get the Check Result data in
   * the result set.
   */
  readonly withResultDataType?: TypeSet | undefined;
}

/**
 * If present, indicates the query wants to examine Stages, optionally
 * passing them through the given filtering predicate before proceeding.
 *
 * The outcome of this phase is joined with the outcome of a similar
 * SelectChecks phase before being passed to Expand and Collect phases.
 *
 * If not set, the query will not be selecting any Stage nodes at the
 * selection phase (note you still may see Stages in the overall result
 * if `collect_stages` is present and some Stages were discovered during
 * the Expand phase).
 */
export interface Query_SelectStages {
  /**
   * Pick Stages matching any of these predicates (they are ORed together).
   *
   * If empty, all Stages will be selected.
   */
  readonly predicates: readonly Query_SelectStages_Predicate[];
}

/**
 * Only pick Stages which match this predicate.
 *
 * Individual clauses are ANDed together. An unset field means the
 * corresponding clause is not checked. At least one field must be set.
 */
export interface Query_SelectStages_Predicate {
  /** Pick Stages in this state. */
  readonly state?:
    | StageState
    | undefined;
  /** Pick Stages with Args matching the type filter. */
  readonly withArgsType?: TypeSet | undefined;
}

/** How to expand the dependencies for a Check or Stage. */
export interface Query_ExpandDependencies {
  /**
   * How to expand dependencies.
   *
   * Defaults to QUERY_EXPAND_DEPS_MODE_EDGES.
   */
  readonly mode?: QueryExpandDepsMode | undefined;
}

/** How to expand the dependents for a Check or Stage. */
export interface Query_ExpandDependents {
  /**
   * How to expand dependents.
   *
   * Defaults to QUERY_EXPAND_DEPS_MODE_EDGES.
   */
  readonly mode?: QueryExpandDepsMode | undefined;
}

/**
 * Describes what data the caller wants to see for discovered Checks (in
 * addition to core Check properties).
 */
export interface Query_CollectChecks {
  /**
   * Include CheckOptions for any discovered Checks.
   *
   * Only options matching QueryNodesRequest.type_info.wanted TypeSet will
   * be returned (for initially selected Checks, this type filter is applied
   * on top of filtering done by SelectChecks.predicates).
   */
  readonly options?:
    | boolean
    | undefined;
  /**
   * Include Result data for any selected Checks.
   *
   * Only options matching QueryNodesRequest.type_info.wanted TypeSet will
   * be returned (for initially selected Checks, this type filter is applied
   * on top of filtering done by SelectChecks.predicates).
   */
  readonly resultData?:
    | boolean
    | undefined;
  /**
   * Include edits only within this range of Revisions.
   *
   * An empty RevisionRange (e.g. {0, 0}) means `all edits`. If this field
   * is absent, no edits will be included.
   */
  readonly edits?: RevisionRange | undefined;
}

/**
 * Describes what data the caller wants to see for discovered Stages (in
 * addition to core Stage properties).
 *
 * Value-typed fields inside Stage Attempts (e.g. progress details) and Stage
 * Edits are subject to filtering by QueryNodesRequest.type_info.wanted.
 */
export interface Query_CollectStages {
  /**
   * What subset of Stage Attempts to include.
   *
   * By default attempts are not included.
   */
  readonly attempts?:
    | CollectStageAttempts
    | undefined;
  /**
   * Include edits only within this range of Revisions.
   *
   * An empty RevisionRange (e.g. {0, 0}) means `all edits`. If this field
   * is absent, no edits will be included.
   */
  readonly edits?: RevisionRange | undefined;
}

function createBaseQuery(): Query {
  return {
    nodesInWorkplan: undefined,
    nodesAcrossWorkplans: undefined,
    nodesById: undefined,
    selectChecks: undefined,
    selectStages: undefined,
    expandDependencies: undefined,
    expandDependents: undefined,
    collectChecks: undefined,
    collectStages: undefined,
  };
}

export const Query: MessageFns<Query> = {
  encode(message: Query, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.nodesInWorkplan !== undefined) {
      WorkPlan.encode(message.nodesInWorkplan, writer.uint32(10).fork()).join();
    }
    if (message.nodesAcrossWorkplans !== undefined) {
      Query_NodesAcrossWorkPlans.encode(message.nodesAcrossWorkplans, writer.uint32(18).fork()).join();
    }
    if (message.nodesById !== undefined) {
      Query_NodesByID.encode(message.nodesById, writer.uint32(26).fork()).join();
    }
    if (message.selectChecks !== undefined) {
      Query_SelectChecks.encode(message.selectChecks, writer.uint32(34).fork()).join();
    }
    if (message.selectStages !== undefined) {
      Query_SelectStages.encode(message.selectStages, writer.uint32(42).fork()).join();
    }
    if (message.expandDependencies !== undefined) {
      Query_ExpandDependencies.encode(message.expandDependencies, writer.uint32(50).fork()).join();
    }
    if (message.expandDependents !== undefined) {
      Query_ExpandDependents.encode(message.expandDependents, writer.uint32(58).fork()).join();
    }
    if (message.collectChecks !== undefined) {
      Query_CollectChecks.encode(message.collectChecks, writer.uint32(66).fork()).join();
    }
    if (message.collectStages !== undefined) {
      Query_CollectStages.encode(message.collectStages, writer.uint32(74).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Query {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuery() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.nodesInWorkplan = WorkPlan.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.nodesAcrossWorkplans = Query_NodesAcrossWorkPlans.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.nodesById = Query_NodesByID.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.selectChecks = Query_SelectChecks.decode(reader, reader.uint32());
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.selectStages = Query_SelectStages.decode(reader, reader.uint32());
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.expandDependencies = Query_ExpandDependencies.decode(reader, reader.uint32());
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.expandDependents = Query_ExpandDependents.decode(reader, reader.uint32());
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.collectChecks = Query_CollectChecks.decode(reader, reader.uint32());
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.collectStages = Query_CollectStages.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Query {
    return {
      nodesInWorkplan: isSet(object.nodesInWorkplan) ? WorkPlan.fromJSON(object.nodesInWorkplan) : undefined,
      nodesAcrossWorkplans: isSet(object.nodesAcrossWorkplans)
        ? Query_NodesAcrossWorkPlans.fromJSON(object.nodesAcrossWorkplans)
        : undefined,
      nodesById: isSet(object.nodesById) ? Query_NodesByID.fromJSON(object.nodesById) : undefined,
      selectChecks: isSet(object.selectChecks) ? Query_SelectChecks.fromJSON(object.selectChecks) : undefined,
      selectStages: isSet(object.selectStages) ? Query_SelectStages.fromJSON(object.selectStages) : undefined,
      expandDependencies: isSet(object.expandDependencies)
        ? Query_ExpandDependencies.fromJSON(object.expandDependencies)
        : undefined,
      expandDependents: isSet(object.expandDependents)
        ? Query_ExpandDependents.fromJSON(object.expandDependents)
        : undefined,
      collectChecks: isSet(object.collectChecks) ? Query_CollectChecks.fromJSON(object.collectChecks) : undefined,
      collectStages: isSet(object.collectStages) ? Query_CollectStages.fromJSON(object.collectStages) : undefined,
    };
  },

  toJSON(message: Query): unknown {
    const obj: any = {};
    if (message.nodesInWorkplan !== undefined) {
      obj.nodesInWorkplan = WorkPlan.toJSON(message.nodesInWorkplan);
    }
    if (message.nodesAcrossWorkplans !== undefined) {
      obj.nodesAcrossWorkplans = Query_NodesAcrossWorkPlans.toJSON(message.nodesAcrossWorkplans);
    }
    if (message.nodesById !== undefined) {
      obj.nodesById = Query_NodesByID.toJSON(message.nodesById);
    }
    if (message.selectChecks !== undefined) {
      obj.selectChecks = Query_SelectChecks.toJSON(message.selectChecks);
    }
    if (message.selectStages !== undefined) {
      obj.selectStages = Query_SelectStages.toJSON(message.selectStages);
    }
    if (message.expandDependencies !== undefined) {
      obj.expandDependencies = Query_ExpandDependencies.toJSON(message.expandDependencies);
    }
    if (message.expandDependents !== undefined) {
      obj.expandDependents = Query_ExpandDependents.toJSON(message.expandDependents);
    }
    if (message.collectChecks !== undefined) {
      obj.collectChecks = Query_CollectChecks.toJSON(message.collectChecks);
    }
    if (message.collectStages !== undefined) {
      obj.collectStages = Query_CollectStages.toJSON(message.collectStages);
    }
    return obj;
  },

  create(base?: DeepPartial<Query>): Query {
    return Query.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Query>): Query {
    const message = createBaseQuery() as any;
    message.nodesInWorkplan = (object.nodesInWorkplan !== undefined && object.nodesInWorkplan !== null)
      ? WorkPlan.fromPartial(object.nodesInWorkplan)
      : undefined;
    message.nodesAcrossWorkplans = (object.nodesAcrossWorkplans !== undefined && object.nodesAcrossWorkplans !== null)
      ? Query_NodesAcrossWorkPlans.fromPartial(object.nodesAcrossWorkplans)
      : undefined;
    message.nodesById = (object.nodesById !== undefined && object.nodesById !== null)
      ? Query_NodesByID.fromPartial(object.nodesById)
      : undefined;
    message.selectChecks = (object.selectChecks !== undefined && object.selectChecks !== null)
      ? Query_SelectChecks.fromPartial(object.selectChecks)
      : undefined;
    message.selectStages = (object.selectStages !== undefined && object.selectStages !== null)
      ? Query_SelectStages.fromPartial(object.selectStages)
      : undefined;
    message.expandDependencies = (object.expandDependencies !== undefined && object.expandDependencies !== null)
      ? Query_ExpandDependencies.fromPartial(object.expandDependencies)
      : undefined;
    message.expandDependents = (object.expandDependents !== undefined && object.expandDependents !== null)
      ? Query_ExpandDependents.fromPartial(object.expandDependents)
      : undefined;
    message.collectChecks = (object.collectChecks !== undefined && object.collectChecks !== null)
      ? Query_CollectChecks.fromPartial(object.collectChecks)
      : undefined;
    message.collectStages = (object.collectStages !== undefined && object.collectStages !== null)
      ? Query_CollectStages.fromPartial(object.collectStages)
      : undefined;
    return message;
  },
};

function createBaseQuery_NodesAcrossWorkPlans(): Query_NodesAcrossWorkPlans {
  return {};
}

export const Query_NodesAcrossWorkPlans: MessageFns<Query_NodesAcrossWorkPlans> = {
  encode(_: Query_NodesAcrossWorkPlans, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Query_NodesAcrossWorkPlans {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuery_NodesAcrossWorkPlans() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): Query_NodesAcrossWorkPlans {
    return {};
  },

  toJSON(_: Query_NodesAcrossWorkPlans): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<Query_NodesAcrossWorkPlans>): Query_NodesAcrossWorkPlans {
    return Query_NodesAcrossWorkPlans.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<Query_NodesAcrossWorkPlans>): Query_NodesAcrossWorkPlans {
    const message = createBaseQuery_NodesAcrossWorkPlans() as any;
    return message;
  },
};

function createBaseQuery_NodesByID(): Query_NodesByID {
  return { nodes: [] };
}

export const Query_NodesByID: MessageFns<Query_NodesByID> = {
  encode(message: Query_NodesByID, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.nodes) {
      Identifier.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Query_NodesByID {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuery_NodesByID() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.nodes.push(Identifier.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Query_NodesByID {
    return {
      nodes: globalThis.Array.isArray(object?.nodes) ? object.nodes.map((e: any) => Identifier.fromJSON(e)) : [],
    };
  },

  toJSON(message: Query_NodesByID): unknown {
    const obj: any = {};
    if (message.nodes?.length) {
      obj.nodes = message.nodes.map((e) => Identifier.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<Query_NodesByID>): Query_NodesByID {
    return Query_NodesByID.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Query_NodesByID>): Query_NodesByID {
    const message = createBaseQuery_NodesByID() as any;
    message.nodes = object.nodes?.map((e) => Identifier.fromPartial(e)) || [];
    return message;
  },
};

function createBaseQuery_SelectChecks(): Query_SelectChecks {
  return { predicates: [] };
}

export const Query_SelectChecks: MessageFns<Query_SelectChecks> = {
  encode(message: Query_SelectChecks, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.predicates) {
      Query_SelectChecks_Predicate.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Query_SelectChecks {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuery_SelectChecks() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.predicates.push(Query_SelectChecks_Predicate.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Query_SelectChecks {
    return {
      predicates: globalThis.Array.isArray(object?.predicates)
        ? object.predicates.map((e: any) => Query_SelectChecks_Predicate.fromJSON(e))
        : [],
    };
  },

  toJSON(message: Query_SelectChecks): unknown {
    const obj: any = {};
    if (message.predicates?.length) {
      obj.predicates = message.predicates.map((e) => Query_SelectChecks_Predicate.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<Query_SelectChecks>): Query_SelectChecks {
    return Query_SelectChecks.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Query_SelectChecks>): Query_SelectChecks {
    const message = createBaseQuery_SelectChecks() as any;
    message.predicates = object.predicates?.map((e) => Query_SelectChecks_Predicate.fromPartial(e)) || [];
    return message;
  },
};

function createBaseQuery_SelectChecks_Predicate(): Query_SelectChecks_Predicate {
  return { kind: undefined, state: undefined, withOptionType: undefined, withResultDataType: undefined };
}

export const Query_SelectChecks_Predicate: MessageFns<Query_SelectChecks_Predicate> = {
  encode(message: Query_SelectChecks_Predicate, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kind !== undefined) {
      writer.uint32(8).int32(message.kind);
    }
    if (message.state !== undefined) {
      writer.uint32(16).int32(message.state);
    }
    if (message.withOptionType !== undefined) {
      TypeSet.encode(message.withOptionType, writer.uint32(26).fork()).join();
    }
    if (message.withResultDataType !== undefined) {
      TypeSet.encode(message.withResultDataType, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Query_SelectChecks_Predicate {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuery_SelectChecks_Predicate() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.kind = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.withOptionType = TypeSet.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.withResultDataType = TypeSet.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Query_SelectChecks_Predicate {
    return {
      kind: isSet(object.kind) ? checkKindFromJSON(object.kind) : undefined,
      state: isSet(object.state) ? checkStateFromJSON(object.state) : undefined,
      withOptionType: isSet(object.withOptionType) ? TypeSet.fromJSON(object.withOptionType) : undefined,
      withResultDataType: isSet(object.withResultDataType) ? TypeSet.fromJSON(object.withResultDataType) : undefined,
    };
  },

  toJSON(message: Query_SelectChecks_Predicate): unknown {
    const obj: any = {};
    if (message.kind !== undefined) {
      obj.kind = checkKindToJSON(message.kind);
    }
    if (message.state !== undefined) {
      obj.state = checkStateToJSON(message.state);
    }
    if (message.withOptionType !== undefined) {
      obj.withOptionType = TypeSet.toJSON(message.withOptionType);
    }
    if (message.withResultDataType !== undefined) {
      obj.withResultDataType = TypeSet.toJSON(message.withResultDataType);
    }
    return obj;
  },

  create(base?: DeepPartial<Query_SelectChecks_Predicate>): Query_SelectChecks_Predicate {
    return Query_SelectChecks_Predicate.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Query_SelectChecks_Predicate>): Query_SelectChecks_Predicate {
    const message = createBaseQuery_SelectChecks_Predicate() as any;
    message.kind = object.kind ?? undefined;
    message.state = object.state ?? undefined;
    message.withOptionType = (object.withOptionType !== undefined && object.withOptionType !== null)
      ? TypeSet.fromPartial(object.withOptionType)
      : undefined;
    message.withResultDataType = (object.withResultDataType !== undefined && object.withResultDataType !== null)
      ? TypeSet.fromPartial(object.withResultDataType)
      : undefined;
    return message;
  },
};

function createBaseQuery_SelectStages(): Query_SelectStages {
  return { predicates: [] };
}

export const Query_SelectStages: MessageFns<Query_SelectStages> = {
  encode(message: Query_SelectStages, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.predicates) {
      Query_SelectStages_Predicate.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Query_SelectStages {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuery_SelectStages() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.predicates.push(Query_SelectStages_Predicate.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Query_SelectStages {
    return {
      predicates: globalThis.Array.isArray(object?.predicates)
        ? object.predicates.map((e: any) => Query_SelectStages_Predicate.fromJSON(e))
        : [],
    };
  },

  toJSON(message: Query_SelectStages): unknown {
    const obj: any = {};
    if (message.predicates?.length) {
      obj.predicates = message.predicates.map((e) => Query_SelectStages_Predicate.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<Query_SelectStages>): Query_SelectStages {
    return Query_SelectStages.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Query_SelectStages>): Query_SelectStages {
    const message = createBaseQuery_SelectStages() as any;
    message.predicates = object.predicates?.map((e) => Query_SelectStages_Predicate.fromPartial(e)) || [];
    return message;
  },
};

function createBaseQuery_SelectStages_Predicate(): Query_SelectStages_Predicate {
  return { state: undefined, withArgsType: undefined };
}

export const Query_SelectStages_Predicate: MessageFns<Query_SelectStages_Predicate> = {
  encode(message: Query_SelectStages_Predicate, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.state !== undefined) {
      writer.uint32(8).int32(message.state);
    }
    if (message.withArgsType !== undefined) {
      TypeSet.encode(message.withArgsType, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Query_SelectStages_Predicate {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuery_SelectStages_Predicate() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.withArgsType = TypeSet.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Query_SelectStages_Predicate {
    return {
      state: isSet(object.state) ? stageStateFromJSON(object.state) : undefined,
      withArgsType: isSet(object.withArgsType) ? TypeSet.fromJSON(object.withArgsType) : undefined,
    };
  },

  toJSON(message: Query_SelectStages_Predicate): unknown {
    const obj: any = {};
    if (message.state !== undefined) {
      obj.state = stageStateToJSON(message.state);
    }
    if (message.withArgsType !== undefined) {
      obj.withArgsType = TypeSet.toJSON(message.withArgsType);
    }
    return obj;
  },

  create(base?: DeepPartial<Query_SelectStages_Predicate>): Query_SelectStages_Predicate {
    return Query_SelectStages_Predicate.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Query_SelectStages_Predicate>): Query_SelectStages_Predicate {
    const message = createBaseQuery_SelectStages_Predicate() as any;
    message.state = object.state ?? undefined;
    message.withArgsType = (object.withArgsType !== undefined && object.withArgsType !== null)
      ? TypeSet.fromPartial(object.withArgsType)
      : undefined;
    return message;
  },
};

function createBaseQuery_ExpandDependencies(): Query_ExpandDependencies {
  return { mode: undefined };
}

export const Query_ExpandDependencies: MessageFns<Query_ExpandDependencies> = {
  encode(message: Query_ExpandDependencies, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.mode !== undefined) {
      writer.uint32(8).int32(message.mode);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Query_ExpandDependencies {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuery_ExpandDependencies() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.mode = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Query_ExpandDependencies {
    return { mode: isSet(object.mode) ? queryExpandDepsModeFromJSON(object.mode) : undefined };
  },

  toJSON(message: Query_ExpandDependencies): unknown {
    const obj: any = {};
    if (message.mode !== undefined) {
      obj.mode = queryExpandDepsModeToJSON(message.mode);
    }
    return obj;
  },

  create(base?: DeepPartial<Query_ExpandDependencies>): Query_ExpandDependencies {
    return Query_ExpandDependencies.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Query_ExpandDependencies>): Query_ExpandDependencies {
    const message = createBaseQuery_ExpandDependencies() as any;
    message.mode = object.mode ?? undefined;
    return message;
  },
};

function createBaseQuery_ExpandDependents(): Query_ExpandDependents {
  return { mode: undefined };
}

export const Query_ExpandDependents: MessageFns<Query_ExpandDependents> = {
  encode(message: Query_ExpandDependents, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.mode !== undefined) {
      writer.uint32(8).int32(message.mode);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Query_ExpandDependents {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuery_ExpandDependents() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.mode = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Query_ExpandDependents {
    return { mode: isSet(object.mode) ? queryExpandDepsModeFromJSON(object.mode) : undefined };
  },

  toJSON(message: Query_ExpandDependents): unknown {
    const obj: any = {};
    if (message.mode !== undefined) {
      obj.mode = queryExpandDepsModeToJSON(message.mode);
    }
    return obj;
  },

  create(base?: DeepPartial<Query_ExpandDependents>): Query_ExpandDependents {
    return Query_ExpandDependents.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Query_ExpandDependents>): Query_ExpandDependents {
    const message = createBaseQuery_ExpandDependents() as any;
    message.mode = object.mode ?? undefined;
    return message;
  },
};

function createBaseQuery_CollectChecks(): Query_CollectChecks {
  return { options: undefined, resultData: undefined, edits: undefined };
}

export const Query_CollectChecks: MessageFns<Query_CollectChecks> = {
  encode(message: Query_CollectChecks, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.options !== undefined) {
      writer.uint32(8).bool(message.options);
    }
    if (message.resultData !== undefined) {
      writer.uint32(16).bool(message.resultData);
    }
    if (message.edits !== undefined) {
      RevisionRange.encode(message.edits, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Query_CollectChecks {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuery_CollectChecks() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.options = reader.bool();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.resultData = reader.bool();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.edits = RevisionRange.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Query_CollectChecks {
    return {
      options: isSet(object.options) ? globalThis.Boolean(object.options) : undefined,
      resultData: isSet(object.resultData) ? globalThis.Boolean(object.resultData) : undefined,
      edits: isSet(object.edits) ? RevisionRange.fromJSON(object.edits) : undefined,
    };
  },

  toJSON(message: Query_CollectChecks): unknown {
    const obj: any = {};
    if (message.options !== undefined) {
      obj.options = message.options;
    }
    if (message.resultData !== undefined) {
      obj.resultData = message.resultData;
    }
    if (message.edits !== undefined) {
      obj.edits = RevisionRange.toJSON(message.edits);
    }
    return obj;
  },

  create(base?: DeepPartial<Query_CollectChecks>): Query_CollectChecks {
    return Query_CollectChecks.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Query_CollectChecks>): Query_CollectChecks {
    const message = createBaseQuery_CollectChecks() as any;
    message.options = object.options ?? undefined;
    message.resultData = object.resultData ?? undefined;
    message.edits = (object.edits !== undefined && object.edits !== null)
      ? RevisionRange.fromPartial(object.edits)
      : undefined;
    return message;
  },
};

function createBaseQuery_CollectStages(): Query_CollectStages {
  return { attempts: undefined, edits: undefined };
}

export const Query_CollectStages: MessageFns<Query_CollectStages> = {
  encode(message: Query_CollectStages, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.attempts !== undefined) {
      writer.uint32(8).int32(message.attempts);
    }
    if (message.edits !== undefined) {
      RevisionRange.encode(message.edits, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Query_CollectStages {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuery_CollectStages() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.attempts = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.edits = RevisionRange.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Query_CollectStages {
    return {
      attempts: isSet(object.attempts) ? collectStageAttemptsFromJSON(object.attempts) : undefined,
      edits: isSet(object.edits) ? RevisionRange.fromJSON(object.edits) : undefined,
    };
  },

  toJSON(message: Query_CollectStages): unknown {
    const obj: any = {};
    if (message.attempts !== undefined) {
      obj.attempts = collectStageAttemptsToJSON(message.attempts);
    }
    if (message.edits !== undefined) {
      obj.edits = RevisionRange.toJSON(message.edits);
    }
    return obj;
  },

  create(base?: DeepPartial<Query_CollectStages>): Query_CollectStages {
    return Query_CollectStages.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Query_CollectStages>): Query_CollectStages {
    const message = createBaseQuery_CollectStages() as any;
    message.attempts = object.attempts ?? undefined;
    message.edits = (object.edits !== undefined && object.edits !== null)
      ? RevisionRange.fromPartial(object.edits)
      : undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
