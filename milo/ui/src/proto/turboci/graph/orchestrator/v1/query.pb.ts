// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.7.5
//   protoc               v6.32.1
// source: turboci/graph/orchestrator/v1/query.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import { Identifier, WorkPlan } from "../../ids/v1/identifier.pb";
import { CheckKind, checkKindFromJSON, checkKindToJSON } from "./check_kind.pb";
import { CheckState, checkStateFromJSON, checkStateToJSON } from "./check_state.pb";
import { RevisionRange } from "./revision_range.pb";

export const protobufPackage = "turboci.graph.orchestrator.v1";

/**
 * When expanding a query selection set with Query.Expand.Dependencies or
 * Query.Expand.Dependants, how should we actually expand that set?
 */
export enum QueryExpandDepsMode {
  /**
   * QUERY_EXPAND_DEPS_MODE_UNKNOWN - Unknown query expansion mode.
   *
   * Defaults to 'REQUESTED'.
   */
  QUERY_EXPAND_DEPS_MODE_UNKNOWN = 0,
  /** QUERY_EXPAND_DEPS_MODE_EDGES - Expand to deps which are listed in dependencies.edges. */
  QUERY_EXPAND_DEPS_MODE_EDGES = 1,
  /**
   * QUERY_EXPAND_DEPS_MODE_SATISFIED - Expand to edges which were the ones that caused dependencies.resolved to be
   * RESOLUTION_SATISFIED.
   *
   * Note that this will be the empty set for nodes which are not already past
   * the PLANNED state, and for nodes which have RESOLUTION_UNSATISFIED
   * dependencies.
   */
  QUERY_EXPAND_DEPS_MODE_SATISFIED = 2,
}

export function queryExpandDepsModeFromJSON(object: any): QueryExpandDepsMode {
  switch (object) {
    case 0:
    case "QUERY_EXPAND_DEPS_MODE_UNKNOWN":
      return QueryExpandDepsMode.QUERY_EXPAND_DEPS_MODE_UNKNOWN;
    case 1:
    case "QUERY_EXPAND_DEPS_MODE_EDGES":
      return QueryExpandDepsMode.QUERY_EXPAND_DEPS_MODE_EDGES;
    case 2:
    case "QUERY_EXPAND_DEPS_MODE_SATISFIED":
      return QueryExpandDepsMode.QUERY_EXPAND_DEPS_MODE_SATISFIED;
    default:
      throw new globalThis.Error("Unrecognized enum value " + object + " for enum QueryExpandDepsMode");
  }
}

export function queryExpandDepsModeToJSON(object: QueryExpandDepsMode): string {
  switch (object) {
    case QueryExpandDepsMode.QUERY_EXPAND_DEPS_MODE_UNKNOWN:
      return "QUERY_EXPAND_DEPS_MODE_UNKNOWN";
    case QueryExpandDepsMode.QUERY_EXPAND_DEPS_MODE_EDGES:
      return "QUERY_EXPAND_DEPS_MODE_EDGES";
    case QueryExpandDepsMode.QUERY_EXPAND_DEPS_MODE_SATISFIED:
      return "QUERY_EXPAND_DEPS_MODE_SATISFIED";
    default:
      throw new globalThis.Error("Unrecognized enum value " + object + " for enum QueryExpandDepsMode");
  }
}

/**
 * Query describes a simple graph query.
 *
 * This is composed of three phases: selection, expansion and collection.
 *
 * The selection phase queries for a set of nodes within a WorkPlan
 * - effectively a regular SELECT type query on a traditional database.
 *
 * After the selection phase, the expansion phase allows traversal along the
 * edges of the selected nodes. Currently only 'dependency' edge traversal is
 * supported, but other types of relationships could be possible in the future
 * (e.g. 'created_by', 'written_by', etc.).
 *
 * Finally, after the set of nodes has been fully expanded, we collect all the
 * requested data from those Nodes.
 *
 * See QueryNodesRequest.version for how this Query interacts with transactions.
 */
export interface Query {
  /**
   * Type URLs (for Check Option Datum, Check Result Datum, Stage args,
   * CheckEdit Option Datum and CheckEdit Result) that the caller wants to see
   * in the response.  Any child Node whose type URL is not specified here
   * will be omitted in the response.
   *
   * TBD: The special value "*" means that the caller wants to see all type
   * URLs, but this requires an extra permission. Extra permission is needed
   * to encourage clients to be explicit about what they want to reduce
   * bandwidth, coupling and increase auditability.
   *
   * TBD: Allow limited wildcards to include everything under some package
   * namespace.
   */
  readonly typeUrls: readonly string[];
  /** Select an arbitrary set of nodes. */
  readonly select?:
    | Query_Select
    | undefined;
  /** Expand that set of nodes by following their edges. */
  readonly expand?:
    | Query_Expand
    | undefined;
  /** The data to collect from the expanded node set. */
  readonly collect?: Query_Collect | undefined;
}

/** Select picks some set of nodes out of the graph. */
export interface Query_Select {
  /** Which WorkPlans to search across. */
  readonly workplan?:
    | Query_Select_WorkPlanConstraint
    | undefined;
  /**
   * The identifiers of specific nodes to select.
   *
   * This should be used if you already know the identifiers of the nodes you
   * care about.
   */
  readonly nodes: readonly Identifier[];
  /** Select Checks matching these patterns. */
  readonly checkPatterns: readonly Query_Select_CheckPattern[];
  /** Select Stages matching these patterns. */
  readonly stagePatterns: readonly Query_Select_StagePattern[];
}

/**
 * How this selection of nodes should be constrained to one or more
 * WorkPlans.
 */
export interface Query_Select_WorkPlanConstraint {
  /** Constrain this Select to the given WorkPlan(s). */
  readonly inWorkplans: readonly WorkPlan[];
}

/** Select one or more Checks which match this pattern. */
export interface Query_Select_CheckPattern {
  /** Find Checks of this kind (unset means all kinds). */
  readonly kind?:
    | CheckKind
    | undefined;
  /** Find Checks whose `Identifier.Check.id` matches this re2 regex. */
  readonly idRegex?:
    | string
    | undefined;
  /**
   * Find Checks with *any* of these options. Note that you still must set
   * type_urls and collect.data.check.options to actually get the
   * Check Option data in the result set.
   */
  readonly withOptionTypes: readonly string[];
  /** Find Checks in this state. */
  readonly state?:
    | CheckState
    | undefined;
  /**
   * Find Checks with *any* of these result data types. Note that you still
   * must set type_urls and collect.data.check.result_data to actually get the
   * Check Result data in the result set.
   */
  readonly withResultDataTypes: readonly string[];
}

/** Select one or more Stages which match this pattern. */
export interface Query_Select_StagePattern {
}

/**
 * Expand takes the selected node set and 'expands' it by following edges in
 * the graph from those nodes.
 */
export interface Query_Expand {
  /**
   * For each selected Check or Stage, include its immediate dependencies.
   *
   * So given:
   *   A -> {B, C}
   *
   * (B, C) are dependencies of A.
   */
  readonly dependencies?:
    | Query_Expand_Dependencies
    | undefined;
  /**
   * For each selected Check or Stage, include any Checks/Stages which depend
   * on it.
   *
   * So given:
   *   A -> {B, C}
   *
   * A is a dependent of B.
   */
  readonly dependents?: Query_Expand_Dependents | undefined;
}

/** How to expand the dependencies for a Check or Stage. */
export interface Query_Expand_Dependencies {
  /**
   * How to expand dependencies.
   *
   * Defaults to QUERY_EXPAND_DEPS_MODE_EDGES.
   */
  readonly mode?: QueryExpandDepsMode | undefined;
}

/** How to expand the dependents for a Check or Stage. */
export interface Query_Expand_Dependents {
  /**
   * How to expand dependents.
   *
   * Defaults to QUERY_EXPAND_DEPS_MODE_EDGES.
   */
  readonly mode?: QueryExpandDepsMode | undefined;
}

/** Collect retrieves data from the expanded node set. */
export interface Query_Collect {
  /** Describes what data the caller wants to see for Checks. */
  readonly check?:
    | Query_Collect_Check
    | undefined;
  /** Describes what data the caller wants to see for Stages. */
  readonly stage?: Query_Collect_Stage | undefined;
}

/** Describes what data the caller wants to see for Checks. */
export interface Query_Collect_Check {
  /** Include CheckOptions filtered by `type_urls` for any selected Checks. */
  readonly options?:
    | boolean
    | undefined;
  /** Include Result data filtered by `type_urls` for any selected Checks. */
  readonly resultData?:
    | boolean
    | undefined;
  /**
   * Include edits only within this range of Revisions.
   *
   * An empty RevisionRange (e.g. {0, 0}) means `all edits`.
   */
  readonly edits?: RevisionRange | undefined;
}

/** Describes what data the caller wants to see for Stages. */
export interface Query_Collect_Stage {
  /**
   * Include edits only within this range of Revisions.
   *
   * An empty RevisionRange (e.g. {0, 0}) means `all edits`.
   */
  readonly edits?: RevisionRange | undefined;
}

function createBaseQuery(): Query {
  return { typeUrls: [], select: undefined, expand: undefined, collect: undefined };
}

export const Query: MessageFns<Query> = {
  encode(message: Query, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.typeUrls) {
      writer.uint32(10).string(v!);
    }
    if (message.select !== undefined) {
      Query_Select.encode(message.select, writer.uint32(18).fork()).join();
    }
    if (message.expand !== undefined) {
      Query_Expand.encode(message.expand, writer.uint32(26).fork()).join();
    }
    if (message.collect !== undefined) {
      Query_Collect.encode(message.collect, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Query {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuery() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.typeUrls.push(reader.string());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.select = Query_Select.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.expand = Query_Expand.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.collect = Query_Collect.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Query {
    return {
      typeUrls: globalThis.Array.isArray(object?.typeUrls) ? object.typeUrls.map((e: any) => globalThis.String(e)) : [],
      select: isSet(object.select) ? Query_Select.fromJSON(object.select) : undefined,
      expand: isSet(object.expand) ? Query_Expand.fromJSON(object.expand) : undefined,
      collect: isSet(object.collect) ? Query_Collect.fromJSON(object.collect) : undefined,
    };
  },

  toJSON(message: Query): unknown {
    const obj: any = {};
    if (message.typeUrls?.length) {
      obj.typeUrls = message.typeUrls;
    }
    if (message.select !== undefined) {
      obj.select = Query_Select.toJSON(message.select);
    }
    if (message.expand !== undefined) {
      obj.expand = Query_Expand.toJSON(message.expand);
    }
    if (message.collect !== undefined) {
      obj.collect = Query_Collect.toJSON(message.collect);
    }
    return obj;
  },

  create(base?: DeepPartial<Query>): Query {
    return Query.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Query>): Query {
    const message = createBaseQuery() as any;
    message.typeUrls = object.typeUrls?.map((e) => e) || [];
    message.select = (object.select !== undefined && object.select !== null)
      ? Query_Select.fromPartial(object.select)
      : undefined;
    message.expand = (object.expand !== undefined && object.expand !== null)
      ? Query_Expand.fromPartial(object.expand)
      : undefined;
    message.collect = (object.collect !== undefined && object.collect !== null)
      ? Query_Collect.fromPartial(object.collect)
      : undefined;
    return message;
  },
};

function createBaseQuery_Select(): Query_Select {
  return { workplan: undefined, nodes: [], checkPatterns: [], stagePatterns: [] };
}

export const Query_Select: MessageFns<Query_Select> = {
  encode(message: Query_Select, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.workplan !== undefined) {
      Query_Select_WorkPlanConstraint.encode(message.workplan, writer.uint32(10).fork()).join();
    }
    for (const v of message.nodes) {
      Identifier.encode(v!, writer.uint32(18).fork()).join();
    }
    for (const v of message.checkPatterns) {
      Query_Select_CheckPattern.encode(v!, writer.uint32(26).fork()).join();
    }
    for (const v of message.stagePatterns) {
      Query_Select_StagePattern.encode(v!, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Query_Select {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuery_Select() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.workplan = Query_Select_WorkPlanConstraint.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.nodes.push(Identifier.decode(reader, reader.uint32()));
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.checkPatterns.push(Query_Select_CheckPattern.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.stagePatterns.push(Query_Select_StagePattern.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Query_Select {
    return {
      workplan: isSet(object.workplan) ? Query_Select_WorkPlanConstraint.fromJSON(object.workplan) : undefined,
      nodes: globalThis.Array.isArray(object?.nodes) ? object.nodes.map((e: any) => Identifier.fromJSON(e)) : [],
      checkPatterns: globalThis.Array.isArray(object?.checkPatterns)
        ? object.checkPatterns.map((e: any) => Query_Select_CheckPattern.fromJSON(e))
        : [],
      stagePatterns: globalThis.Array.isArray(object?.stagePatterns)
        ? object.stagePatterns.map((e: any) => Query_Select_StagePattern.fromJSON(e))
        : [],
    };
  },

  toJSON(message: Query_Select): unknown {
    const obj: any = {};
    if (message.workplan !== undefined) {
      obj.workplan = Query_Select_WorkPlanConstraint.toJSON(message.workplan);
    }
    if (message.nodes?.length) {
      obj.nodes = message.nodes.map((e) => Identifier.toJSON(e));
    }
    if (message.checkPatterns?.length) {
      obj.checkPatterns = message.checkPatterns.map((e) => Query_Select_CheckPattern.toJSON(e));
    }
    if (message.stagePatterns?.length) {
      obj.stagePatterns = message.stagePatterns.map((e) => Query_Select_StagePattern.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<Query_Select>): Query_Select {
    return Query_Select.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Query_Select>): Query_Select {
    const message = createBaseQuery_Select() as any;
    message.workplan = (object.workplan !== undefined && object.workplan !== null)
      ? Query_Select_WorkPlanConstraint.fromPartial(object.workplan)
      : undefined;
    message.nodes = object.nodes?.map((e) => Identifier.fromPartial(e)) || [];
    message.checkPatterns = object.checkPatterns?.map((e) => Query_Select_CheckPattern.fromPartial(e)) || [];
    message.stagePatterns = object.stagePatterns?.map((e) => Query_Select_StagePattern.fromPartial(e)) || [];
    return message;
  },
};

function createBaseQuery_Select_WorkPlanConstraint(): Query_Select_WorkPlanConstraint {
  return { inWorkplans: [] };
}

export const Query_Select_WorkPlanConstraint: MessageFns<Query_Select_WorkPlanConstraint> = {
  encode(message: Query_Select_WorkPlanConstraint, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.inWorkplans) {
      WorkPlan.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Query_Select_WorkPlanConstraint {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuery_Select_WorkPlanConstraint() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.inWorkplans.push(WorkPlan.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Query_Select_WorkPlanConstraint {
    return {
      inWorkplans: globalThis.Array.isArray(object?.inWorkplans)
        ? object.inWorkplans.map((e: any) => WorkPlan.fromJSON(e))
        : [],
    };
  },

  toJSON(message: Query_Select_WorkPlanConstraint): unknown {
    const obj: any = {};
    if (message.inWorkplans?.length) {
      obj.inWorkplans = message.inWorkplans.map((e) => WorkPlan.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<Query_Select_WorkPlanConstraint>): Query_Select_WorkPlanConstraint {
    return Query_Select_WorkPlanConstraint.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Query_Select_WorkPlanConstraint>): Query_Select_WorkPlanConstraint {
    const message = createBaseQuery_Select_WorkPlanConstraint() as any;
    message.inWorkplans = object.inWorkplans?.map((e) => WorkPlan.fromPartial(e)) || [];
    return message;
  },
};

function createBaseQuery_Select_CheckPattern(): Query_Select_CheckPattern {
  return { kind: undefined, idRegex: undefined, withOptionTypes: [], state: undefined, withResultDataTypes: [] };
}

export const Query_Select_CheckPattern: MessageFns<Query_Select_CheckPattern> = {
  encode(message: Query_Select_CheckPattern, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kind !== undefined) {
      writer.uint32(8).int32(message.kind);
    }
    if (message.idRegex !== undefined) {
      writer.uint32(18).string(message.idRegex);
    }
    for (const v of message.withOptionTypes) {
      writer.uint32(26).string(v!);
    }
    if (message.state !== undefined) {
      writer.uint32(32).int32(message.state);
    }
    for (const v of message.withResultDataTypes) {
      writer.uint32(42).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Query_Select_CheckPattern {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuery_Select_CheckPattern() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.kind = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.idRegex = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.withOptionTypes.push(reader.string());
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.withResultDataTypes.push(reader.string());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Query_Select_CheckPattern {
    return {
      kind: isSet(object.kind) ? checkKindFromJSON(object.kind) : undefined,
      idRegex: isSet(object.idRegex) ? globalThis.String(object.idRegex) : undefined,
      withOptionTypes: globalThis.Array.isArray(object?.withOptionTypes)
        ? object.withOptionTypes.map((e: any) => globalThis.String(e))
        : [],
      state: isSet(object.state) ? checkStateFromJSON(object.state) : undefined,
      withResultDataTypes: globalThis.Array.isArray(object?.withResultDataTypes)
        ? object.withResultDataTypes.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: Query_Select_CheckPattern): unknown {
    const obj: any = {};
    if (message.kind !== undefined) {
      obj.kind = checkKindToJSON(message.kind);
    }
    if (message.idRegex !== undefined) {
      obj.idRegex = message.idRegex;
    }
    if (message.withOptionTypes?.length) {
      obj.withOptionTypes = message.withOptionTypes;
    }
    if (message.state !== undefined) {
      obj.state = checkStateToJSON(message.state);
    }
    if (message.withResultDataTypes?.length) {
      obj.withResultDataTypes = message.withResultDataTypes;
    }
    return obj;
  },

  create(base?: DeepPartial<Query_Select_CheckPattern>): Query_Select_CheckPattern {
    return Query_Select_CheckPattern.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Query_Select_CheckPattern>): Query_Select_CheckPattern {
    const message = createBaseQuery_Select_CheckPattern() as any;
    message.kind = object.kind ?? undefined;
    message.idRegex = object.idRegex ?? undefined;
    message.withOptionTypes = object.withOptionTypes?.map((e) => e) || [];
    message.state = object.state ?? undefined;
    message.withResultDataTypes = object.withResultDataTypes?.map((e) => e) || [];
    return message;
  },
};

function createBaseQuery_Select_StagePattern(): Query_Select_StagePattern {
  return {};
}

export const Query_Select_StagePattern: MessageFns<Query_Select_StagePattern> = {
  encode(_: Query_Select_StagePattern, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Query_Select_StagePattern {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuery_Select_StagePattern() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): Query_Select_StagePattern {
    return {};
  },

  toJSON(_: Query_Select_StagePattern): unknown {
    const obj: any = {};
    return obj;
  },

  create(base?: DeepPartial<Query_Select_StagePattern>): Query_Select_StagePattern {
    return Query_Select_StagePattern.fromPartial(base ?? {});
  },
  fromPartial(_: DeepPartial<Query_Select_StagePattern>): Query_Select_StagePattern {
    const message = createBaseQuery_Select_StagePattern() as any;
    return message;
  },
};

function createBaseQuery_Expand(): Query_Expand {
  return { dependencies: undefined, dependents: undefined };
}

export const Query_Expand: MessageFns<Query_Expand> = {
  encode(message: Query_Expand, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.dependencies !== undefined) {
      Query_Expand_Dependencies.encode(message.dependencies, writer.uint32(10).fork()).join();
    }
    if (message.dependents !== undefined) {
      Query_Expand_Dependents.encode(message.dependents, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Query_Expand {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuery_Expand() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.dependencies = Query_Expand_Dependencies.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.dependents = Query_Expand_Dependents.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Query_Expand {
    return {
      dependencies: isSet(object.dependencies) ? Query_Expand_Dependencies.fromJSON(object.dependencies) : undefined,
      dependents: isSet(object.dependents) ? Query_Expand_Dependents.fromJSON(object.dependents) : undefined,
    };
  },

  toJSON(message: Query_Expand): unknown {
    const obj: any = {};
    if (message.dependencies !== undefined) {
      obj.dependencies = Query_Expand_Dependencies.toJSON(message.dependencies);
    }
    if (message.dependents !== undefined) {
      obj.dependents = Query_Expand_Dependents.toJSON(message.dependents);
    }
    return obj;
  },

  create(base?: DeepPartial<Query_Expand>): Query_Expand {
    return Query_Expand.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Query_Expand>): Query_Expand {
    const message = createBaseQuery_Expand() as any;
    message.dependencies = (object.dependencies !== undefined && object.dependencies !== null)
      ? Query_Expand_Dependencies.fromPartial(object.dependencies)
      : undefined;
    message.dependents = (object.dependents !== undefined && object.dependents !== null)
      ? Query_Expand_Dependents.fromPartial(object.dependents)
      : undefined;
    return message;
  },
};

function createBaseQuery_Expand_Dependencies(): Query_Expand_Dependencies {
  return { mode: undefined };
}

export const Query_Expand_Dependencies: MessageFns<Query_Expand_Dependencies> = {
  encode(message: Query_Expand_Dependencies, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.mode !== undefined) {
      writer.uint32(8).int32(message.mode);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Query_Expand_Dependencies {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuery_Expand_Dependencies() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.mode = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Query_Expand_Dependencies {
    return { mode: isSet(object.mode) ? queryExpandDepsModeFromJSON(object.mode) : undefined };
  },

  toJSON(message: Query_Expand_Dependencies): unknown {
    const obj: any = {};
    if (message.mode !== undefined) {
      obj.mode = queryExpandDepsModeToJSON(message.mode);
    }
    return obj;
  },

  create(base?: DeepPartial<Query_Expand_Dependencies>): Query_Expand_Dependencies {
    return Query_Expand_Dependencies.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Query_Expand_Dependencies>): Query_Expand_Dependencies {
    const message = createBaseQuery_Expand_Dependencies() as any;
    message.mode = object.mode ?? undefined;
    return message;
  },
};

function createBaseQuery_Expand_Dependents(): Query_Expand_Dependents {
  return { mode: undefined };
}

export const Query_Expand_Dependents: MessageFns<Query_Expand_Dependents> = {
  encode(message: Query_Expand_Dependents, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.mode !== undefined) {
      writer.uint32(8).int32(message.mode);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Query_Expand_Dependents {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuery_Expand_Dependents() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.mode = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Query_Expand_Dependents {
    return { mode: isSet(object.mode) ? queryExpandDepsModeFromJSON(object.mode) : undefined };
  },

  toJSON(message: Query_Expand_Dependents): unknown {
    const obj: any = {};
    if (message.mode !== undefined) {
      obj.mode = queryExpandDepsModeToJSON(message.mode);
    }
    return obj;
  },

  create(base?: DeepPartial<Query_Expand_Dependents>): Query_Expand_Dependents {
    return Query_Expand_Dependents.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Query_Expand_Dependents>): Query_Expand_Dependents {
    const message = createBaseQuery_Expand_Dependents() as any;
    message.mode = object.mode ?? undefined;
    return message;
  },
};

function createBaseQuery_Collect(): Query_Collect {
  return { check: undefined, stage: undefined };
}

export const Query_Collect: MessageFns<Query_Collect> = {
  encode(message: Query_Collect, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.check !== undefined) {
      Query_Collect_Check.encode(message.check, writer.uint32(10).fork()).join();
    }
    if (message.stage !== undefined) {
      Query_Collect_Stage.encode(message.stage, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Query_Collect {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuery_Collect() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.check = Query_Collect_Check.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.stage = Query_Collect_Stage.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Query_Collect {
    return {
      check: isSet(object.check) ? Query_Collect_Check.fromJSON(object.check) : undefined,
      stage: isSet(object.stage) ? Query_Collect_Stage.fromJSON(object.stage) : undefined,
    };
  },

  toJSON(message: Query_Collect): unknown {
    const obj: any = {};
    if (message.check !== undefined) {
      obj.check = Query_Collect_Check.toJSON(message.check);
    }
    if (message.stage !== undefined) {
      obj.stage = Query_Collect_Stage.toJSON(message.stage);
    }
    return obj;
  },

  create(base?: DeepPartial<Query_Collect>): Query_Collect {
    return Query_Collect.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Query_Collect>): Query_Collect {
    const message = createBaseQuery_Collect() as any;
    message.check = (object.check !== undefined && object.check !== null)
      ? Query_Collect_Check.fromPartial(object.check)
      : undefined;
    message.stage = (object.stage !== undefined && object.stage !== null)
      ? Query_Collect_Stage.fromPartial(object.stage)
      : undefined;
    return message;
  },
};

function createBaseQuery_Collect_Check(): Query_Collect_Check {
  return { options: undefined, resultData: undefined, edits: undefined };
}

export const Query_Collect_Check: MessageFns<Query_Collect_Check> = {
  encode(message: Query_Collect_Check, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.options !== undefined) {
      writer.uint32(8).bool(message.options);
    }
    if (message.resultData !== undefined) {
      writer.uint32(16).bool(message.resultData);
    }
    if (message.edits !== undefined) {
      RevisionRange.encode(message.edits, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Query_Collect_Check {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuery_Collect_Check() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.options = reader.bool();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.resultData = reader.bool();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.edits = RevisionRange.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Query_Collect_Check {
    return {
      options: isSet(object.options) ? globalThis.Boolean(object.options) : undefined,
      resultData: isSet(object.resultData) ? globalThis.Boolean(object.resultData) : undefined,
      edits: isSet(object.edits) ? RevisionRange.fromJSON(object.edits) : undefined,
    };
  },

  toJSON(message: Query_Collect_Check): unknown {
    const obj: any = {};
    if (message.options !== undefined) {
      obj.options = message.options;
    }
    if (message.resultData !== undefined) {
      obj.resultData = message.resultData;
    }
    if (message.edits !== undefined) {
      obj.edits = RevisionRange.toJSON(message.edits);
    }
    return obj;
  },

  create(base?: DeepPartial<Query_Collect_Check>): Query_Collect_Check {
    return Query_Collect_Check.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Query_Collect_Check>): Query_Collect_Check {
    const message = createBaseQuery_Collect_Check() as any;
    message.options = object.options ?? undefined;
    message.resultData = object.resultData ?? undefined;
    message.edits = (object.edits !== undefined && object.edits !== null)
      ? RevisionRange.fromPartial(object.edits)
      : undefined;
    return message;
  },
};

function createBaseQuery_Collect_Stage(): Query_Collect_Stage {
  return { edits: undefined };
}

export const Query_Collect_Stage: MessageFns<Query_Collect_Stage> = {
  encode(message: Query_Collect_Stage, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.edits !== undefined) {
      RevisionRange.encode(message.edits, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Query_Collect_Stage {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseQuery_Collect_Stage() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.edits = RevisionRange.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Query_Collect_Stage {
    return { edits: isSet(object.edits) ? RevisionRange.fromJSON(object.edits) : undefined };
  },

  toJSON(message: Query_Collect_Stage): unknown {
    const obj: any = {};
    if (message.edits !== undefined) {
      obj.edits = RevisionRange.toJSON(message.edits);
    }
    return obj;
  },

  create(base?: DeepPartial<Query_Collect_Stage>): Query_Collect_Stage {
    return Query_Collect_Stage.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Query_Collect_Stage>): Query_Collect_Stage {
    const message = createBaseQuery_Collect_Stage() as any;
    message.edits = (object.edits !== undefined && object.edits !== null)
      ? RevisionRange.fromPartial(object.edits)
      : undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
