// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.8.1
//   protoc               v6.32.0
// source: turboci/graph/orchestrator/v1/write_nodes_request.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import { Timestamp } from "../../../../google/protobuf/timestamp.pb";
import { Check, Identifier, Stage } from "../../ids/v1/identifier.pb";
import { CheckKind, checkKindFromJSON, checkKindToJSON } from "./check_kind.pb";
import { CheckState, checkStateFromJSON, checkStateToJSON } from "./check_state.pb";
import { Edge } from "./edge.pb";
import { Revision } from "./revision.pb";
import { Stage_Assignment } from "./stage.pb";
import { StageAttemptExecutionPolicy } from "./stage_attempt_execution_policy.pb";
import { StageExecutionPolicy } from "./stage_execution_policy.pb";
import { Value } from "./value.pb";

export const protobufPackage = "turboci.graph.orchestrator.v1";

/**
 * Request message for TurboCIOrchestrator.WriteNodes.
 *
 * Allows atomically writing to multiple nodes (Checks, Stages) in a single
 * transaction.
 */
export interface WriteNodesRequest {
  /**
   * The token which constrains this write to a specific Workplan (and possibly
   * to a Stage Attempt in that Workplan).
   *
   * A suitable token is provided to the Executor of a Stage or to the creator
   * of an empty Workplan.
   *
   * This is in addition to regular RPC authorization.
   *
   * If missing, this RPC will check that the caller additionally has the
   * 'turboci.workplans.writeExternal' permission on Workplan(s) in the
   * CheckWrites/StageWrites.
   */
  readonly token?:
    | string
    | undefined;
  /**
   * The reason for this write operation, as supplied by the entity performing
   * the write.
   *
   * This should be used to detail any information about WHY this write is
   * happening, or details about what changes are being made.
   *
   * This will be reflected in the CheckEdit or StageEdit logs for all
   * Checks and/or Stages affected by this write.
   *
   * This is repeated to allow reasons in multiple security domains; By
   * convention, these should be ordered from most to least specific, so if
   * a client only wants to display one Reason, it should be the first in this
   * list which they have access to.
   */
  readonly reasons: readonly WriteNodesRequest_Reason[];
  /**
   * Set if the caller wants to make this write transactional with a subset of
   * the graph at a particular snapshot.
   *
   * If this is unset, then this is an 'oblivious write' and any valid writes
   * will apply/overwrite the current database state, assuming they are
   * semantically valid (i.e. it will still not be possible to change a Check's
   * realm, or roll a Check's state backwards, etc.).
   *
   * There are common cases where this will be left unset, for example when a
   * Stage Attempt updates its own progress based on its own internal state, or
   * when a Stage Attempt records results for a Check off of some internal
   * computation. It's allowed for a Stage Attempt to tie this progress update
   * to the state of the graph, but it's not expected or required.
   */
  readonly txn?:
    | WriteNodesRequest_TransactionDetails
    | undefined;
  /** Write to zero or more Checks. */
  readonly checks: readonly WriteNodesRequest_CheckWrite[];
  /** Write to zero or more Stages. */
  readonly stages: readonly WriteNodesRequest_StageWrite[];
  /**
   * State for the current Stage Attempt as indicated by `token`.
   *
   * It is invalid to set this without also setting `token`.
   *
   * A WriteNodes call with `current_attempt` set (even when it is empty) acts
   * as a heartbeat for the current Stage Attempt indicated by the token. If
   * you need to implement the 'simplest heartbeat', you can make a WriteNodes
   * call with just the token and an empty `current_attempt {}`.
   *
   * WriteNodes calls that don't have `current_attempt` set do not affect the
   * heartbeat timer. This makes such calls less likely to hit transaction
   * collisions (since they don't try to concurrently modify the heartbeat
   * timer). This may be useful if you want to make concurrent WriteNodes calls
   * from the same Stage Attempt, or even closely-sequential WriteNodes calls
   * (to non-overlapping portions of the graph) from the same Stage Attempt.
   *
   * All else being equal, it's better to do fewer, larger, WriteNodes calls
   * than many small WriteNodes calls.
   */
  readonly currentAttempt?:
    | WriteNodesRequest_CurrentAttemptWrite
    | undefined;
  /**
   * State for the current Stage as indicated by `token`.
   *
   * It is invalid to set this without also setting `token`.
   *
   * This does not impact the heartbeat timer for the current attempt.
   */
  readonly currentStage?: WriteNodesRequest_CurrentStageWrite | undefined;
}

/**
 * RealmValue describes a Value which resides in a given security realm.
 *
 * This is used to write objects which appear in the graph as Datum messages.
 */
export interface WriteNodesRequest_RealmValue {
  /**
   * The realm to assign to this value (if the value is being created). If
   * it's unset/empty, it will inherit from the realm of the object containing
   * it (so, for Check options or result data, this would be the Check's
   * realm).
   *
   * If provided, must be the absolute form "<project>:<name>".
   *
   * If the value is being overwritten and `realm` is provided, it must match
   * the already-written value's realm.
   */
  readonly realm?:
    | string
    | undefined;
  /** The value to set. */
  readonly value?: Value | undefined;
}

/**
 * An in-line representation of Dependencies.Group.
 *
 * The Orchestrator will deduplicate edges into Dependencies.edges in the
 * Check or Stage.
 *
 * Otherwise this has the same meaning as Dependencies.Group.
 */
export interface WriteNodesRequest_DependencyGroup {
  /** Singular edges in this group. */
  readonly edges: readonly Edge[];
  /**
   * Sub-groups in this group.
   *
   * May not contain empty groups.
   */
  readonly groups: readonly WriteNodesRequest_DependencyGroup[];
  /**
   * Number of edges and/or groups which need to be satisfied for this
   * DependencyGroup to be satisfied.
   *
   * See `Dependencies.Group.threshold`.
   */
  readonly threshold?: number | undefined;
}

/** A single Stage.Attempt.Progress write message. */
export interface WriteNodesRequest_StageAttemptProgress {
  /**
   * Low-effort/human-readable progress information.
   *
   * Better than nothing, but not good for machines to parse.
   */
  readonly message?:
    | string
    | undefined;
  /** Machine-readable details for this progress item. */
  readonly details: readonly Value[];
}

/**
 * Reason is the write-request analogue of Edit.Reason.
 *
 * NOTE: If this WriteNodes is a no-op because it's a retry of a previous
 * successful WriteNodes, these Reasons will not be recorded in the graph
 * because there will not be any applied writes. This means that if you
 * vary the Reasons from retry to retry, it's possible to see a successful
 * WriteNodes where the provided reasons are not retained.
 */
export interface WriteNodesRequest_Reason {
  /**
   * The security realm for this reason.
   *
   * If provided, must be the absolute form "<project>:<name>".
   *
   * If absent the written Stage will copy its realm from the implied realm
   * of the `token`. For Stage Attempt tokens, this will be the Stage's
   * realm, and for Creator tokens, this will be the WorkPlan's realm.
   */
  readonly realm?:
    | string
    | undefined;
  /**
   * A 'low effort' reason for this edit.
   *
   * This is 'low effort' because it's preferable for the writer to provide
   * detailed machine-readable data in the `details` field below.
   */
  readonly message?:
    | string
    | undefined;
  /**
   * Machine-readable reason(s) for this edit.
   *
   * This is repeated to allow for standardized reason message types in
   * conjunction with workflow-specific details as part of the same write
   * record.
   */
  readonly details: readonly Value[];
}

/**
 * TransactionDetails encapsulates the information necessary to make this
 * write safe by describing the snapshot of the graph which the writer
 * observed. TurboCI Orchestrator will transactionally ensure that these
 * nodes haven't changed since the writer observed them.
 *
 * TurboCI Orchestrator will implicitly include all nodes which are being
 * written to - this message can provide additional nodes to that set.
 *
 * It is valid to include nodes which were absent from the snapshot, if the
 * writer wants to make its write conditional on their absence.
 *
 * Transaction Procedure:
 *   retry {
 *     nodes, snapshot_version = QueryNodes(...)
 *     # computations
 *
 *     more_nodes, _ = QueryNodes(..., ensure_version=snapshot_version)
 *     # This will cause QueryNodes to fail if any returned nodes have
 *     # a version greater than `snapshot_version`. This will allow the
 *     # transaction loop to retry immediately, rather than waiting for the
 *     # WriteNodes call.
 *
 *     # computations
 *
 *     if WriteNodes(..., txn={nodes+more_nodes, snapshot_version}) {
 *       # Success!
 *
 *       # If you need to make another transaction, you CAN use the
 *       # written_version in the response as an input snapshot_version to
 *       # the subsequent transaction. However, it's important that if this
 *       # second transaction gets a conflict, it restart with
 *       # snapshot_version unset.
 *       break
 *     } else {
 *       # failure - retry from the top
 *     }
 *   }
 */
export interface WriteNodesRequest_TransactionDetails {
  /**
   * A list of all nodes observed which lead to this write.
   *
   * This SHOULD include all nodes which your computation used as inputs
   * for making a decision. If you locally filtered the GraphView before the
   * computation, it is OK to omit nodes which were filtered out, because you
   * would do the same write regardless of those filtered nodes' content.
   *
   * This MAY include nodes which were absent from the GraphView - this means
   * that the write is conditional on their absence (e.g. "I queried for X and
   * didn't find it, so I'm doing a write based on that information. If X DOES
   * exist at the time of the write, I want to abort and try again.").
   *
   * NOTE: If you are writing what you THINK are all new nodes, but haven't
   * done a query to verify this, just providing `txn` with `nodes_observed`
   * and `snapshot_version` left unset is sufficient to guard against the
   * nodes already being written. However, if you get
   * a TransactionConflictFailure because the nodes already exist, when you
   * recover make sure to do the query before you try the write again! You
   * may be conflicting with a previous incarnation of your own process!
   */
  readonly nodesObserved: readonly Identifier[];
  /**
   * The 'version' of the GraphView returned from QueryNodes.
   *
   * If multiple queries were made in this transaction, this revision MUST be
   * the first revision observed. Providing version.require to QueryNodes
   * will help enforce this.
   *
   * If `snapshot_version` is unset, it is treated as a 0 value (which means
   * that all `nodes_observed` plus all nodes being written in this request
   * must not already exist).
   */
  readonly snapshotVersion?: Revision | undefined;
}

/** A description of modifications to make to a single Check. */
export interface WriteNodesRequest_CheckWrite {
  /**
   * The check to write to.
   *
   * If the WorkPlan is left blank, will be populated with the WorkPlan in
   * `token`, if it's provided.
   *
   * Otherwise, the Check must belong to the token's WorkPlan, or the caller
   * must have the additional "turboci.workplans.writeExternal" permission in
   * the check's realm (or in the realm of the option/result data).
   */
  readonly identifier?:
    | Check
    | undefined;
  /**
   * Realm to assign to this check.
   *
   * If provided, must be the absolute form "<project>:<name>".
   *
   * If this is set, and the Check DOES already exist, this MUST match the
   * existing realm.
   *
   * If absent and this CheckWrite creates the Check, the written Check will
   * copy its realm from the implied realm of the `token`. For Stage Attempt
   * tokens, this will be the Stage's realm, and for Creator tokens, this
   * will be the WorkPlan's realm.
   *
   * If `token` is unset and this field is absent, the write will be rejected.
   */
  readonly realm?:
    | string
    | undefined;
  /**
   * Kind to assign to this check.
   *
   * If this is set, and the Check DOES already exist, this MUST match the
   * existing Check kind.
   */
  readonly kind?:
    | CheckKind
    | undefined;
  /**
   * The list of Options to write/overwrite.
   *
   * Must be unique on `RealmValue.value.type_url`.
   */
  readonly options: readonly WriteNodesRequest_RealmValue[];
  /**
   * Dependency predicate for this Check.
   *
   * If set, used to populate the dependencies.edges and
   * dependencies.predicate fields in the target Check.
   *
   * To clear dependencies, set this to an empty DependencyGroup.
   */
  readonly dependencies?:
    | WriteNodesRequest_DependencyGroup
    | undefined;
  /**
   * Write data to a Result for this Check.
   *
   * The Result to write in is keyed on:
   *   * The Stage Attempt (if `token` is provided)
   *   * The caller's identity (if `token` is absent)
   *
   * If the given keyed Result does not exist, it will be automatically
   * created. Multiple calls to WriteNodes from this same Stage Attempt or
   * service account will update the same Result, and the Result will be
   * automatically finalized when this Stage Attempt ends (if a WriteNodes
   * with `finalize_results` is not called before then).
   *
   * The data here will overwrite existing data of the same type in the
   * selected Result for this Stage Attempt.
   */
  readonly results: readonly WriteNodesRequest_RealmValue[];
  /**
   * If set, finalize the Check.Result.
   *
   * No more data may be written to the Result from the caller after this is
   * set.
   */
  readonly finalizeResults?:
    | boolean
    | undefined;
  /**
   * The new state of this Check.
   *
   * If set, must be equal to, or greater than, the current state of the
   * Check.
   */
  readonly state?: CheckState | undefined;
}

/**
 * A description of modifications to make to a single Stage.
 *
 * Note that the `state` of a Stage is managed entirely by the Orchestrator
 * itself. If you are a Stage implementation and need to manage the state of
 * your own Stage Attempt, see CurrentStageWrite.
 */
export interface WriteNodesRequest_StageWrite {
  /**
   * The stage to write to.
   *
   * If the WorkPlan is left blank, will be populated with the WorkPlan in
   * `token`, if it's provided.
   *
   * Otherwise, the Stage must belong to the token's WorkPlan, or the caller
   * must have the additional "turboci.workplans.writeExternal" permission in
   * the stage's realm.
   *
   * The `is_worknode` field should also be omitted - it will be filled in by
   * the server according to the type of `args`.
   */
  readonly identifier?:
    | Stage
    | undefined;
  /**
   * The arguments of the Stage.
   *
   * A Stage MUST have `args` - if this write would create the Stage and
   * `args` is omitted, the write will be rejected.
   *
   * TBD: Document executor registration/selection process.
   *
   * TBD: What to do on double-creation? Do we compare args (protobuf
   * serialization is not canonical/deterministic, but in practice if the
   * same process creates the same stage twice, it will likely have the same
   * args).
   *
   * We could just accept 'same type' == OK and ignore the value, but this
   * feels a bit wishy-washy.
   */
  readonly args?:
    | Value
    | undefined;
  /**
   * Realm to assign to this Stage.
   *
   * If provided, must be the absolute form "<project>:<name>".
   *
   * If the Stage already exists, this will only result in an error if it
   * doesn't match the existing realm.
   *
   * If absent the written Stage will copy its realm from the implied realm of
   * the `token`. For Stage Attempt tokens, this will be the Stage's realm,
   * and for Creator tokens, this will be the WorkPlan's realm.
   *
   * If `token` is unset and this field is absent, the write will be rejected.
   */
  readonly realm?:
    | string
    | undefined;
  /**
   * Dependency predicate for this Stage.
   *
   * If set, used to populate the dependencies.edges and
   * dependencies.predicate fields in the target Check.
   *
   * If the Stage already exists, this will only result in an error if it
   * doesn't match the existing dependencies identically.
   *
   * NOTE: Currently Stages in this group must only point to Stages created by
   * the Stage performing this write. In theory, this should help prevent
   * excessive coupling between different, unrelated, stage implementations.
   *
   * If arbitrary stage dependencies are allowed, it could cause errors when
   * an upstream stage changes it's implementation and no longer produces the
   * stages the downstream one expects. Instead, the upstream stage should
   * create a Check which can remain stable across the implementation
   * versions, and the downstream stages should depend on that.
   *
   * However, if the current writer is the one creating the stages, then there
   * is no implementation risk.
   */
  readonly dependencies?:
    | WriteNodesRequest_DependencyGroup
    | undefined;
  /**
   * The requested execution policy of the Stage.
   *
   * If the Stage already exists, this will only result in an error if this
   * requested policy doesn't match doesn't match the existing requested
   * policy.
   *
   * If this write creates the stage and the requested_stage_execution_policy
   * is omitted, the stage will get the default StageExecutionPolicy from the
   * Executor.
   */
  readonly requestedStageExecutionPolicy?:
    | StageExecutionPolicy
    | undefined;
  /**
   * The Check assignments of the Stage.
   *
   * If the Stage already exists, this will only result in an error if it
   * doesn't match the existing assignments.
   */
  readonly assignments: readonly Stage_Assignment[];
  /**
   * If true, ensures that this Stage is marked for cancellation.
   *
   * If the Stage is in the ATTEMPTING state, and the current Attempt is
   * RUNNING, the Attempt will transition to CANCELLING - Otherwise the
   * current Attempt will be marked INCOMPLETE.
   *
   * If the Stage is already marked for cancellation, setting this is a no-op.
   *
   * A value of `false` is the same as `unset` (no-op).
   *
   * Use the top-level `reason` field to provide the cancellation reason.
   */
  readonly cancelled?: boolean | undefined;
}

/**
 * Internal writes for the Stage Attempt indicated by the token.
 *
 * These aspects come from either the Executor which owns this Stage Attempt,
 * or the running Stage Attempt process.
 */
export interface WriteNodesRequest_CurrentAttemptWrite {
  /**
   * Adds details to the Stage Attempt.details field.
   *
   * If a data type here is already present in the database, the data here
   * must exactly equal the existing data; Otherwise the write is rejected.
   */
  readonly details: readonly Value[];
  /**
   * Progress messages to add to the current Stage Attempt.
   *
   * It is a good idea to do these progress updates transactionally,
   * otherwise it's possible to double-append them.
   */
  readonly progress: readonly WriteNodesRequest_StageAttemptProgress[];
  /** A state transition to make in this write. */
  readonly stateTransition?: WriteNodesRequest_CurrentAttemptWrite_StateTransition | undefined;
}

/** Indicate how the Orchestrator should transition to a given state. */
export interface WriteNodesRequest_CurrentAttemptWrite_StateTransition {
  /**
   * Move to the THROTTLED state.
   *
   * Current state must be PENDING.
   */
  readonly throttled?:
    | WriteNodesRequest_CurrentAttemptWrite_StateTransition_Throttled
    | undefined;
  /**
   * Move to the SCHEDULED state.
   *
   * Current state must be PENDING.
   */
  readonly scheduled?:
    | WriteNodesRequest_CurrentAttemptWrite_StateTransition_Scheduled
    | undefined;
  /**
   * Move to the RUNNING state.
   *
   * Current state must be PENDING or SCHEDULED.
   */
  readonly running?:
    | WriteNodesRequest_CurrentAttemptWrite_StateTransition_Running
    | undefined;
  /**
   * Move to the TEARING_DOWN state.
   *
   * Current state must be RUNNING or CANCELLING.
   */
  readonly tearingDown?:
    | WriteNodesRequest_CurrentAttemptWrite_StateTransition_TearingDown
    | undefined;
  /**
   * Move to the COMPLETE state.
   *
   * Current state must be PENDING, SCHEDULED, RUNNING or TEARING_DOWN.
   */
  readonly complete?:
    | WriteNodesRequest_CurrentAttemptWrite_StateTransition_Complete
    | undefined;
  /**
   * Move to the INCOMPLETE state.
   *
   * Current state must be PENDING, SCHEDULED, RUNNING or TEARING_DOWN.
   */
  readonly incomplete?: WriteNodesRequest_CurrentAttemptWrite_StateTransition_Incomplete | undefined;
}

/**
 * Throttled indicates that the Executor can run this Attempt, just not
 * right now.
 */
export interface WriteNodesRequest_CurrentAttemptWrite_StateTransition_Throttled {
  /**
   * Specifies that the Stage Attempt should not be made PENDING again
   * (and thus sent to the Executor via RunStage) until this time.
   *
   * Specifying a time in the past will cause the write to be a no-op
   * (which will leave the Attempt in the PENDING state).
   *
   * Required.
   */
  readonly until?: string | undefined;
}

/**
 * Scheduled indicates that the Executor has accepted the Attempt, and
 * will run it at a later time.
 */
export interface WriteNodesRequest_CurrentAttemptWrite_StateTransition_Scheduled {
  /**
   * The execution policy for this Stage Attempt.
   *
   * Optional.
   */
  readonly attemptExecutionPolicy?: StageAttemptExecutionPolicy | undefined;
}

/** Running indicates that the Executor is actively running this Attempt. */
export interface WriteNodesRequest_CurrentAttemptWrite_StateTransition_Running {
  /**
   * The execution policy for this Stage Attempt.
   *
   * This should only be used if it wasn't already set in SCHEDULED.
   * If it's set for both SCHEDULED and RUNNING, it must be the same
   * value.
   *
   * Optional.
   */
  readonly attemptExecutionPolicy?:
    | StageAttemptExecutionPolicy
    | undefined;
  /**
   * Sets the Stage.Attempt.process_uid field.
   *
   * If the field is already populated in the Stage Attempt, this value
   * must match - otherwise the write is rejected with an error detail
   * of StageAttemptClaimedFailure.
   *
   * Refer to Stage.Attempt.process_uid.
   *
   * Required.
   */
  readonly processUid?: string | undefined;
}

/**
 * TearingDown indicates that the Executor has either finished RUNNING
 * the Attempt, or the Stage was cancelled and the Executor is doing
 * its final cleanup for a previously-RUNNING Attempt.
 */
export interface WriteNodesRequest_CurrentAttemptWrite_StateTransition_TearingDown {
}

/**
 * Complete indicates that the Executor has finished all work on this
 * Attempt, and the Stage can now move into its next state.
 *
 * NOTE: See STAGE_ATTEMPT_COMPLETE. Completing a Stage does not imply
 * workflow-level success like "the code compiled successfully" or "the
 * tests all passed". It simply means that e.g. the requested build ran
 * to completion, or the test harness executed all the tests.
 * Workflow-level records like compilation success/failure or test
 * execution success/failure should be recorded in the Checks for those
 * things as specific Result data.
 */
export interface WriteNodesRequest_CurrentAttemptWrite_StateTransition_Complete {
}

/**
 * Incomplete indicates an Executor-level failure which prevented the
 * stage from running to completion.
 *
 * By convention, the reason for this should be reflected in the final
 * Progress message (which, unlike the write reasons, will not be
 * garbage collected after some amount of time).
 *
 * NOTE: See STAGE_ATTEMPT_INCOMPLETE. Similar to COMPLETE, INCOMPLETE
 * is used to indicate failure of the stage to complete it's desired
 * task (e.g. compiler segfaulted, test harness lost contact with a DUT
 * during test execution (and such a failure may not be due to the test
 * itself), etc.)
 */
export interface WriteNodesRequest_CurrentAttemptWrite_StateTransition_Incomplete {
  /**
   * Controls if this Stage should make another Attempt.
   *
   * If true, then no new Attempt is made, even if policy would permit one.
   *
   * Optional.
   */
  readonly blockNewAttempts?: boolean | undefined;
}

/** Internal writes for the Stage indicated by the token. */
export interface WriteNodesRequest_CurrentStageWrite {
  /**
   * Continuation Group predicate for this Stage.
   *
   * If set, used to populate the continuation_group.edges and
   * continuation_group.predicate fields in this Stage.
   *
   * Edges here must only point to Stages which were created_by this Stage.
   *
   * If continuation_group is already set, this will overwrite the existing
   * continuation_group.
   */
  readonly continuationGroup?: WriteNodesRequest_DependencyGroup | undefined;
}

function createBaseWriteNodesRequest(): WriteNodesRequest {
  return {
    token: undefined,
    reasons: [],
    txn: undefined,
    checks: [],
    stages: [],
    currentAttempt: undefined,
    currentStage: undefined,
  };
}

export const WriteNodesRequest: MessageFns<WriteNodesRequest> = {
  encode(message: WriteNodesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.token !== undefined) {
      writer.uint32(10).string(message.token);
    }
    for (const v of message.reasons) {
      WriteNodesRequest_Reason.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.txn !== undefined) {
      WriteNodesRequest_TransactionDetails.encode(message.txn, writer.uint32(26).fork()).join();
    }
    for (const v of message.checks) {
      WriteNodesRequest_CheckWrite.encode(v!, writer.uint32(34).fork()).join();
    }
    for (const v of message.stages) {
      WriteNodesRequest_StageWrite.encode(v!, writer.uint32(42).fork()).join();
    }
    if (message.currentAttempt !== undefined) {
      WriteNodesRequest_CurrentAttemptWrite.encode(message.currentAttempt, writer.uint32(50).fork()).join();
    }
    if (message.currentStage !== undefined) {
      WriteNodesRequest_CurrentStageWrite.encode(message.currentStage, writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteNodesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteNodesRequest() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.token = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.reasons.push(WriteNodesRequest_Reason.decode(reader, reader.uint32()));
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.txn = WriteNodesRequest_TransactionDetails.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.checks.push(WriteNodesRequest_CheckWrite.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.stages.push(WriteNodesRequest_StageWrite.decode(reader, reader.uint32()));
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.currentAttempt = WriteNodesRequest_CurrentAttemptWrite.decode(reader, reader.uint32());
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.currentStage = WriteNodesRequest_CurrentStageWrite.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteNodesRequest {
    return {
      token: isSet(object.token) ? globalThis.String(object.token) : undefined,
      reasons: globalThis.Array.isArray(object?.reasons)
        ? object.reasons.map((e: any) => WriteNodesRequest_Reason.fromJSON(e))
        : [],
      txn: isSet(object.txn) ? WriteNodesRequest_TransactionDetails.fromJSON(object.txn) : undefined,
      checks: globalThis.Array.isArray(object?.checks)
        ? object.checks.map((e: any) => WriteNodesRequest_CheckWrite.fromJSON(e))
        : [],
      stages: globalThis.Array.isArray(object?.stages)
        ? object.stages.map((e: any) => WriteNodesRequest_StageWrite.fromJSON(e))
        : [],
      currentAttempt: isSet(object.currentAttempt)
        ? WriteNodesRequest_CurrentAttemptWrite.fromJSON(object.currentAttempt)
        : undefined,
      currentStage: isSet(object.currentStage)
        ? WriteNodesRequest_CurrentStageWrite.fromJSON(object.currentStage)
        : undefined,
    };
  },

  toJSON(message: WriteNodesRequest): unknown {
    const obj: any = {};
    if (message.token !== undefined) {
      obj.token = message.token;
    }
    if (message.reasons?.length) {
      obj.reasons = message.reasons.map((e) => WriteNodesRequest_Reason.toJSON(e));
    }
    if (message.txn !== undefined) {
      obj.txn = WriteNodesRequest_TransactionDetails.toJSON(message.txn);
    }
    if (message.checks?.length) {
      obj.checks = message.checks.map((e) => WriteNodesRequest_CheckWrite.toJSON(e));
    }
    if (message.stages?.length) {
      obj.stages = message.stages.map((e) => WriteNodesRequest_StageWrite.toJSON(e));
    }
    if (message.currentAttempt !== undefined) {
      obj.currentAttempt = WriteNodesRequest_CurrentAttemptWrite.toJSON(message.currentAttempt);
    }
    if (message.currentStage !== undefined) {
      obj.currentStage = WriteNodesRequest_CurrentStageWrite.toJSON(message.currentStage);
    }
    return obj;
  },

  create(base?: DeepPartial<WriteNodesRequest>): WriteNodesRequest {
    return WriteNodesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WriteNodesRequest>): WriteNodesRequest {
    const message = createBaseWriteNodesRequest() as any;
    message.token = object.token ?? undefined;
    message.reasons = object.reasons?.map((e) => WriteNodesRequest_Reason.fromPartial(e)) || [];
    message.txn = (object.txn !== undefined && object.txn !== null)
      ? WriteNodesRequest_TransactionDetails.fromPartial(object.txn)
      : undefined;
    message.checks = object.checks?.map((e) => WriteNodesRequest_CheckWrite.fromPartial(e)) || [];
    message.stages = object.stages?.map((e) => WriteNodesRequest_StageWrite.fromPartial(e)) || [];
    message.currentAttempt = (object.currentAttempt !== undefined && object.currentAttempt !== null)
      ? WriteNodesRequest_CurrentAttemptWrite.fromPartial(object.currentAttempt)
      : undefined;
    message.currentStage = (object.currentStage !== undefined && object.currentStage !== null)
      ? WriteNodesRequest_CurrentStageWrite.fromPartial(object.currentStage)
      : undefined;
    return message;
  },
};

function createBaseWriteNodesRequest_RealmValue(): WriteNodesRequest_RealmValue {
  return { realm: undefined, value: undefined };
}

export const WriteNodesRequest_RealmValue: MessageFns<WriteNodesRequest_RealmValue> = {
  encode(message: WriteNodesRequest_RealmValue, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.realm !== undefined) {
      writer.uint32(10).string(message.realm);
    }
    if (message.value !== undefined) {
      Value.encode(message.value, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteNodesRequest_RealmValue {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteNodesRequest_RealmValue() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.realm = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = Value.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteNodesRequest_RealmValue {
    return {
      realm: isSet(object.realm) ? globalThis.String(object.realm) : undefined,
      value: isSet(object.value) ? Value.fromJSON(object.value) : undefined,
    };
  },

  toJSON(message: WriteNodesRequest_RealmValue): unknown {
    const obj: any = {};
    if (message.realm !== undefined) {
      obj.realm = message.realm;
    }
    if (message.value !== undefined) {
      obj.value = Value.toJSON(message.value);
    }
    return obj;
  },

  create(base?: DeepPartial<WriteNodesRequest_RealmValue>): WriteNodesRequest_RealmValue {
    return WriteNodesRequest_RealmValue.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WriteNodesRequest_RealmValue>): WriteNodesRequest_RealmValue {
    const message = createBaseWriteNodesRequest_RealmValue() as any;
    message.realm = object.realm ?? undefined;
    message.value = (object.value !== undefined && object.value !== null) ? Value.fromPartial(object.value) : undefined;
    return message;
  },
};

function createBaseWriteNodesRequest_DependencyGroup(): WriteNodesRequest_DependencyGroup {
  return { edges: [], groups: [], threshold: undefined };
}

export const WriteNodesRequest_DependencyGroup: MessageFns<WriteNodesRequest_DependencyGroup> = {
  encode(message: WriteNodesRequest_DependencyGroup, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.edges) {
      Edge.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.groups) {
      WriteNodesRequest_DependencyGroup.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.threshold !== undefined) {
      writer.uint32(24).int32(message.threshold);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteNodesRequest_DependencyGroup {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteNodesRequest_DependencyGroup() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.edges.push(Edge.decode(reader, reader.uint32()));
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.groups.push(WriteNodesRequest_DependencyGroup.decode(reader, reader.uint32()));
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.threshold = reader.int32();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteNodesRequest_DependencyGroup {
    return {
      edges: globalThis.Array.isArray(object?.edges) ? object.edges.map((e: any) => Edge.fromJSON(e)) : [],
      groups: globalThis.Array.isArray(object?.groups)
        ? object.groups.map((e: any) => WriteNodesRequest_DependencyGroup.fromJSON(e))
        : [],
      threshold: isSet(object.threshold) ? globalThis.Number(object.threshold) : undefined,
    };
  },

  toJSON(message: WriteNodesRequest_DependencyGroup): unknown {
    const obj: any = {};
    if (message.edges?.length) {
      obj.edges = message.edges.map((e) => Edge.toJSON(e));
    }
    if (message.groups?.length) {
      obj.groups = message.groups.map((e) => WriteNodesRequest_DependencyGroup.toJSON(e));
    }
    if (message.threshold !== undefined) {
      obj.threshold = Math.round(message.threshold);
    }
    return obj;
  },

  create(base?: DeepPartial<WriteNodesRequest_DependencyGroup>): WriteNodesRequest_DependencyGroup {
    return WriteNodesRequest_DependencyGroup.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WriteNodesRequest_DependencyGroup>): WriteNodesRequest_DependencyGroup {
    const message = createBaseWriteNodesRequest_DependencyGroup() as any;
    message.edges = object.edges?.map((e) => Edge.fromPartial(e)) || [];
    message.groups = object.groups?.map((e) => WriteNodesRequest_DependencyGroup.fromPartial(e)) || [];
    message.threshold = object.threshold ?? undefined;
    return message;
  },
};

function createBaseWriteNodesRequest_StageAttemptProgress(): WriteNodesRequest_StageAttemptProgress {
  return { message: undefined, details: [] };
}

export const WriteNodesRequest_StageAttemptProgress: MessageFns<WriteNodesRequest_StageAttemptProgress> = {
  encode(message: WriteNodesRequest_StageAttemptProgress, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.message !== undefined) {
      writer.uint32(10).string(message.message);
    }
    for (const v of message.details) {
      Value.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteNodesRequest_StageAttemptProgress {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteNodesRequest_StageAttemptProgress() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.message = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.details.push(Value.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteNodesRequest_StageAttemptProgress {
    return {
      message: isSet(object.message) ? globalThis.String(object.message) : undefined,
      details: globalThis.Array.isArray(object?.details) ? object.details.map((e: any) => Value.fromJSON(e)) : [],
    };
  },

  toJSON(message: WriteNodesRequest_StageAttemptProgress): unknown {
    const obj: any = {};
    if (message.message !== undefined) {
      obj.message = message.message;
    }
    if (message.details?.length) {
      obj.details = message.details.map((e) => Value.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<WriteNodesRequest_StageAttemptProgress>): WriteNodesRequest_StageAttemptProgress {
    return WriteNodesRequest_StageAttemptProgress.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WriteNodesRequest_StageAttemptProgress>): WriteNodesRequest_StageAttemptProgress {
    const message = createBaseWriteNodesRequest_StageAttemptProgress() as any;
    message.message = object.message ?? undefined;
    message.details = object.details?.map((e) => Value.fromPartial(e)) || [];
    return message;
  },
};

function createBaseWriteNodesRequest_Reason(): WriteNodesRequest_Reason {
  return { realm: undefined, message: undefined, details: [] };
}

export const WriteNodesRequest_Reason: MessageFns<WriteNodesRequest_Reason> = {
  encode(message: WriteNodesRequest_Reason, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.realm !== undefined) {
      writer.uint32(10).string(message.realm);
    }
    if (message.message !== undefined) {
      writer.uint32(18).string(message.message);
    }
    for (const v of message.details) {
      Value.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteNodesRequest_Reason {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteNodesRequest_Reason() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.realm = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.message = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.details.push(Value.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteNodesRequest_Reason {
    return {
      realm: isSet(object.realm) ? globalThis.String(object.realm) : undefined,
      message: isSet(object.message) ? globalThis.String(object.message) : undefined,
      details: globalThis.Array.isArray(object?.details) ? object.details.map((e: any) => Value.fromJSON(e)) : [],
    };
  },

  toJSON(message: WriteNodesRequest_Reason): unknown {
    const obj: any = {};
    if (message.realm !== undefined) {
      obj.realm = message.realm;
    }
    if (message.message !== undefined) {
      obj.message = message.message;
    }
    if (message.details?.length) {
      obj.details = message.details.map((e) => Value.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<WriteNodesRequest_Reason>): WriteNodesRequest_Reason {
    return WriteNodesRequest_Reason.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WriteNodesRequest_Reason>): WriteNodesRequest_Reason {
    const message = createBaseWriteNodesRequest_Reason() as any;
    message.realm = object.realm ?? undefined;
    message.message = object.message ?? undefined;
    message.details = object.details?.map((e) => Value.fromPartial(e)) || [];
    return message;
  },
};

function createBaseWriteNodesRequest_TransactionDetails(): WriteNodesRequest_TransactionDetails {
  return { nodesObserved: [], snapshotVersion: undefined };
}

export const WriteNodesRequest_TransactionDetails: MessageFns<WriteNodesRequest_TransactionDetails> = {
  encode(message: WriteNodesRequest_TransactionDetails, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.nodesObserved) {
      Identifier.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.snapshotVersion !== undefined) {
      Revision.encode(message.snapshotVersion, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteNodesRequest_TransactionDetails {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteNodesRequest_TransactionDetails() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.nodesObserved.push(Identifier.decode(reader, reader.uint32()));
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.snapshotVersion = Revision.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteNodesRequest_TransactionDetails {
    return {
      nodesObserved: globalThis.Array.isArray(object?.nodesObserved)
        ? object.nodesObserved.map((e: any) => Identifier.fromJSON(e))
        : [],
      snapshotVersion: isSet(object.snapshotVersion) ? Revision.fromJSON(object.snapshotVersion) : undefined,
    };
  },

  toJSON(message: WriteNodesRequest_TransactionDetails): unknown {
    const obj: any = {};
    if (message.nodesObserved?.length) {
      obj.nodesObserved = message.nodesObserved.map((e) => Identifier.toJSON(e));
    }
    if (message.snapshotVersion !== undefined) {
      obj.snapshotVersion = Revision.toJSON(message.snapshotVersion);
    }
    return obj;
  },

  create(base?: DeepPartial<WriteNodesRequest_TransactionDetails>): WriteNodesRequest_TransactionDetails {
    return WriteNodesRequest_TransactionDetails.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WriteNodesRequest_TransactionDetails>): WriteNodesRequest_TransactionDetails {
    const message = createBaseWriteNodesRequest_TransactionDetails() as any;
    message.nodesObserved = object.nodesObserved?.map((e) => Identifier.fromPartial(e)) || [];
    message.snapshotVersion = (object.snapshotVersion !== undefined && object.snapshotVersion !== null)
      ? Revision.fromPartial(object.snapshotVersion)
      : undefined;
    return message;
  },
};

function createBaseWriteNodesRequest_CheckWrite(): WriteNodesRequest_CheckWrite {
  return {
    identifier: undefined,
    realm: undefined,
    kind: undefined,
    options: [],
    dependencies: undefined,
    results: [],
    finalizeResults: undefined,
    state: undefined,
  };
}

export const WriteNodesRequest_CheckWrite: MessageFns<WriteNodesRequest_CheckWrite> = {
  encode(message: WriteNodesRequest_CheckWrite, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.identifier !== undefined) {
      Check.encode(message.identifier, writer.uint32(10).fork()).join();
    }
    if (message.realm !== undefined) {
      writer.uint32(18).string(message.realm);
    }
    if (message.kind !== undefined) {
      writer.uint32(24).int32(message.kind);
    }
    for (const v of message.options) {
      WriteNodesRequest_RealmValue.encode(v!, writer.uint32(34).fork()).join();
    }
    if (message.dependencies !== undefined) {
      WriteNodesRequest_DependencyGroup.encode(message.dependencies, writer.uint32(42).fork()).join();
    }
    for (const v of message.results) {
      WriteNodesRequest_RealmValue.encode(v!, writer.uint32(50).fork()).join();
    }
    if (message.finalizeResults !== undefined) {
      writer.uint32(56).bool(message.finalizeResults);
    }
    if (message.state !== undefined) {
      writer.uint32(64).int32(message.state);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteNodesRequest_CheckWrite {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteNodesRequest_CheckWrite() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.identifier = Check.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.realm = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.kind = reader.int32() as any;
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.options.push(WriteNodesRequest_RealmValue.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.dependencies = WriteNodesRequest_DependencyGroup.decode(reader, reader.uint32());
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.results.push(WriteNodesRequest_RealmValue.decode(reader, reader.uint32()));
          continue;
        }
        case 7: {
          if (tag !== 56) {
            break;
          }

          message.finalizeResults = reader.bool();
          continue;
        }
        case 8: {
          if (tag !== 64) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteNodesRequest_CheckWrite {
    return {
      identifier: isSet(object.identifier) ? Check.fromJSON(object.identifier) : undefined,
      realm: isSet(object.realm) ? globalThis.String(object.realm) : undefined,
      kind: isSet(object.kind) ? checkKindFromJSON(object.kind) : undefined,
      options: globalThis.Array.isArray(object?.options)
        ? object.options.map((e: any) => WriteNodesRequest_RealmValue.fromJSON(e))
        : [],
      dependencies: isSet(object.dependencies)
        ? WriteNodesRequest_DependencyGroup.fromJSON(object.dependencies)
        : undefined,
      results: globalThis.Array.isArray(object?.results)
        ? object.results.map((e: any) => WriteNodesRequest_RealmValue.fromJSON(e))
        : [],
      finalizeResults: isSet(object.finalizeResults) ? globalThis.Boolean(object.finalizeResults) : undefined,
      state: isSet(object.state) ? checkStateFromJSON(object.state) : undefined,
    };
  },

  toJSON(message: WriteNodesRequest_CheckWrite): unknown {
    const obj: any = {};
    if (message.identifier !== undefined) {
      obj.identifier = Check.toJSON(message.identifier);
    }
    if (message.realm !== undefined) {
      obj.realm = message.realm;
    }
    if (message.kind !== undefined) {
      obj.kind = checkKindToJSON(message.kind);
    }
    if (message.options?.length) {
      obj.options = message.options.map((e) => WriteNodesRequest_RealmValue.toJSON(e));
    }
    if (message.dependencies !== undefined) {
      obj.dependencies = WriteNodesRequest_DependencyGroup.toJSON(message.dependencies);
    }
    if (message.results?.length) {
      obj.results = message.results.map((e) => WriteNodesRequest_RealmValue.toJSON(e));
    }
    if (message.finalizeResults !== undefined) {
      obj.finalizeResults = message.finalizeResults;
    }
    if (message.state !== undefined) {
      obj.state = checkStateToJSON(message.state);
    }
    return obj;
  },

  create(base?: DeepPartial<WriteNodesRequest_CheckWrite>): WriteNodesRequest_CheckWrite {
    return WriteNodesRequest_CheckWrite.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WriteNodesRequest_CheckWrite>): WriteNodesRequest_CheckWrite {
    const message = createBaseWriteNodesRequest_CheckWrite() as any;
    message.identifier = (object.identifier !== undefined && object.identifier !== null)
      ? Check.fromPartial(object.identifier)
      : undefined;
    message.realm = object.realm ?? undefined;
    message.kind = object.kind ?? undefined;
    message.options = object.options?.map((e) => WriteNodesRequest_RealmValue.fromPartial(e)) || [];
    message.dependencies = (object.dependencies !== undefined && object.dependencies !== null)
      ? WriteNodesRequest_DependencyGroup.fromPartial(object.dependencies)
      : undefined;
    message.results = object.results?.map((e) => WriteNodesRequest_RealmValue.fromPartial(e)) || [];
    message.finalizeResults = object.finalizeResults ?? undefined;
    message.state = object.state ?? undefined;
    return message;
  },
};

function createBaseWriteNodesRequest_StageWrite(): WriteNodesRequest_StageWrite {
  return {
    identifier: undefined,
    args: undefined,
    realm: undefined,
    dependencies: undefined,
    requestedStageExecutionPolicy: undefined,
    assignments: [],
    cancelled: undefined,
  };
}

export const WriteNodesRequest_StageWrite: MessageFns<WriteNodesRequest_StageWrite> = {
  encode(message: WriteNodesRequest_StageWrite, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.identifier !== undefined) {
      Stage.encode(message.identifier, writer.uint32(10).fork()).join();
    }
    if (message.args !== undefined) {
      Value.encode(message.args, writer.uint32(18).fork()).join();
    }
    if (message.realm !== undefined) {
      writer.uint32(26).string(message.realm);
    }
    if (message.dependencies !== undefined) {
      WriteNodesRequest_DependencyGroup.encode(message.dependencies, writer.uint32(34).fork()).join();
    }
    if (message.requestedStageExecutionPolicy !== undefined) {
      StageExecutionPolicy.encode(message.requestedStageExecutionPolicy, writer.uint32(42).fork()).join();
    }
    for (const v of message.assignments) {
      Stage_Assignment.encode(v!, writer.uint32(50).fork()).join();
    }
    if (message.cancelled !== undefined) {
      writer.uint32(56).bool(message.cancelled);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteNodesRequest_StageWrite {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteNodesRequest_StageWrite() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.identifier = Stage.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.args = Value.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.realm = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.dependencies = WriteNodesRequest_DependencyGroup.decode(reader, reader.uint32());
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.requestedStageExecutionPolicy = StageExecutionPolicy.decode(reader, reader.uint32());
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.assignments.push(Stage_Assignment.decode(reader, reader.uint32()));
          continue;
        }
        case 7: {
          if (tag !== 56) {
            break;
          }

          message.cancelled = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteNodesRequest_StageWrite {
    return {
      identifier: isSet(object.identifier) ? Stage.fromJSON(object.identifier) : undefined,
      args: isSet(object.args) ? Value.fromJSON(object.args) : undefined,
      realm: isSet(object.realm) ? globalThis.String(object.realm) : undefined,
      dependencies: isSet(object.dependencies)
        ? WriteNodesRequest_DependencyGroup.fromJSON(object.dependencies)
        : undefined,
      requestedStageExecutionPolicy: isSet(object.requestedStageExecutionPolicy)
        ? StageExecutionPolicy.fromJSON(object.requestedStageExecutionPolicy)
        : undefined,
      assignments: globalThis.Array.isArray(object?.assignments)
        ? object.assignments.map((e: any) => Stage_Assignment.fromJSON(e))
        : [],
      cancelled: isSet(object.cancelled) ? globalThis.Boolean(object.cancelled) : undefined,
    };
  },

  toJSON(message: WriteNodesRequest_StageWrite): unknown {
    const obj: any = {};
    if (message.identifier !== undefined) {
      obj.identifier = Stage.toJSON(message.identifier);
    }
    if (message.args !== undefined) {
      obj.args = Value.toJSON(message.args);
    }
    if (message.realm !== undefined) {
      obj.realm = message.realm;
    }
    if (message.dependencies !== undefined) {
      obj.dependencies = WriteNodesRequest_DependencyGroup.toJSON(message.dependencies);
    }
    if (message.requestedStageExecutionPolicy !== undefined) {
      obj.requestedStageExecutionPolicy = StageExecutionPolicy.toJSON(message.requestedStageExecutionPolicy);
    }
    if (message.assignments?.length) {
      obj.assignments = message.assignments.map((e) => Stage_Assignment.toJSON(e));
    }
    if (message.cancelled !== undefined) {
      obj.cancelled = message.cancelled;
    }
    return obj;
  },

  create(base?: DeepPartial<WriteNodesRequest_StageWrite>): WriteNodesRequest_StageWrite {
    return WriteNodesRequest_StageWrite.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WriteNodesRequest_StageWrite>): WriteNodesRequest_StageWrite {
    const message = createBaseWriteNodesRequest_StageWrite() as any;
    message.identifier = (object.identifier !== undefined && object.identifier !== null)
      ? Stage.fromPartial(object.identifier)
      : undefined;
    message.args = (object.args !== undefined && object.args !== null) ? Value.fromPartial(object.args) : undefined;
    message.realm = object.realm ?? undefined;
    message.dependencies = (object.dependencies !== undefined && object.dependencies !== null)
      ? WriteNodesRequest_DependencyGroup.fromPartial(object.dependencies)
      : undefined;
    message.requestedStageExecutionPolicy =
      (object.requestedStageExecutionPolicy !== undefined && object.requestedStageExecutionPolicy !== null)
        ? StageExecutionPolicy.fromPartial(object.requestedStageExecutionPolicy)
        : undefined;
    message.assignments = object.assignments?.map((e) => Stage_Assignment.fromPartial(e)) || [];
    message.cancelled = object.cancelled ?? undefined;
    return message;
  },
};

function createBaseWriteNodesRequest_CurrentAttemptWrite(): WriteNodesRequest_CurrentAttemptWrite {
  return { details: [], progress: [], stateTransition: undefined };
}

export const WriteNodesRequest_CurrentAttemptWrite: MessageFns<WriteNodesRequest_CurrentAttemptWrite> = {
  encode(message: WriteNodesRequest_CurrentAttemptWrite, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.details) {
      Value.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.progress) {
      WriteNodesRequest_StageAttemptProgress.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.stateTransition !== undefined) {
      WriteNodesRequest_CurrentAttemptWrite_StateTransition.encode(message.stateTransition, writer.uint32(26).fork())
        .join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteNodesRequest_CurrentAttemptWrite {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteNodesRequest_CurrentAttemptWrite() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.details.push(Value.decode(reader, reader.uint32()));
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.progress.push(WriteNodesRequest_StageAttemptProgress.decode(reader, reader.uint32()));
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.stateTransition = WriteNodesRequest_CurrentAttemptWrite_StateTransition.decode(
            reader,
            reader.uint32(),
          );
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteNodesRequest_CurrentAttemptWrite {
    return {
      details: globalThis.Array.isArray(object?.details) ? object.details.map((e: any) => Value.fromJSON(e)) : [],
      progress: globalThis.Array.isArray(object?.progress)
        ? object.progress.map((e: any) => WriteNodesRequest_StageAttemptProgress.fromJSON(e))
        : [],
      stateTransition: isSet(object.stateTransition)
        ? WriteNodesRequest_CurrentAttemptWrite_StateTransition.fromJSON(object.stateTransition)
        : undefined,
    };
  },

  toJSON(message: WriteNodesRequest_CurrentAttemptWrite): unknown {
    const obj: any = {};
    if (message.details?.length) {
      obj.details = message.details.map((e) => Value.toJSON(e));
    }
    if (message.progress?.length) {
      obj.progress = message.progress.map((e) => WriteNodesRequest_StageAttemptProgress.toJSON(e));
    }
    if (message.stateTransition !== undefined) {
      obj.stateTransition = WriteNodesRequest_CurrentAttemptWrite_StateTransition.toJSON(message.stateTransition);
    }
    return obj;
  },

  create(base?: DeepPartial<WriteNodesRequest_CurrentAttemptWrite>): WriteNodesRequest_CurrentAttemptWrite {
    return WriteNodesRequest_CurrentAttemptWrite.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WriteNodesRequest_CurrentAttemptWrite>): WriteNodesRequest_CurrentAttemptWrite {
    const message = createBaseWriteNodesRequest_CurrentAttemptWrite() as any;
    message.details = object.details?.map((e) => Value.fromPartial(e)) || [];
    message.progress = object.progress?.map((e) => WriteNodesRequest_StageAttemptProgress.fromPartial(e)) || [];
    message.stateTransition = (object.stateTransition !== undefined && object.stateTransition !== null)
      ? WriteNodesRequest_CurrentAttemptWrite_StateTransition.fromPartial(object.stateTransition)
      : undefined;
    return message;
  },
};

function createBaseWriteNodesRequest_CurrentAttemptWrite_StateTransition(): WriteNodesRequest_CurrentAttemptWrite_StateTransition {
  return {
    throttled: undefined,
    scheduled: undefined,
    running: undefined,
    tearingDown: undefined,
    complete: undefined,
    incomplete: undefined,
  };
}

export const WriteNodesRequest_CurrentAttemptWrite_StateTransition: MessageFns<
  WriteNodesRequest_CurrentAttemptWrite_StateTransition
> = {
  encode(
    message: WriteNodesRequest_CurrentAttemptWrite_StateTransition,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.throttled !== undefined) {
      WriteNodesRequest_CurrentAttemptWrite_StateTransition_Throttled.encode(
        message.throttled,
        writer.uint32(10).fork(),
      ).join();
    }
    if (message.scheduled !== undefined) {
      WriteNodesRequest_CurrentAttemptWrite_StateTransition_Scheduled.encode(
        message.scheduled,
        writer.uint32(18).fork(),
      ).join();
    }
    if (message.running !== undefined) {
      WriteNodesRequest_CurrentAttemptWrite_StateTransition_Running.encode(message.running, writer.uint32(26).fork())
        .join();
    }
    if (message.tearingDown !== undefined) {
      WriteNodesRequest_CurrentAttemptWrite_StateTransition_TearingDown.encode(
        message.tearingDown,
        writer.uint32(34).fork(),
      ).join();
    }
    if (message.complete !== undefined) {
      WriteNodesRequest_CurrentAttemptWrite_StateTransition_Complete.encode(message.complete, writer.uint32(42).fork())
        .join();
    }
    if (message.incomplete !== undefined) {
      WriteNodesRequest_CurrentAttemptWrite_StateTransition_Incomplete.encode(
        message.incomplete,
        writer.uint32(50).fork(),
      ).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteNodesRequest_CurrentAttemptWrite_StateTransition {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteNodesRequest_CurrentAttemptWrite_StateTransition() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.throttled = WriteNodesRequest_CurrentAttemptWrite_StateTransition_Throttled.decode(
            reader,
            reader.uint32(),
          );
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.scheduled = WriteNodesRequest_CurrentAttemptWrite_StateTransition_Scheduled.decode(
            reader,
            reader.uint32(),
          );
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.running = WriteNodesRequest_CurrentAttemptWrite_StateTransition_Running.decode(
            reader,
            reader.uint32(),
          );
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.tearingDown = WriteNodesRequest_CurrentAttemptWrite_StateTransition_TearingDown.decode(
            reader,
            reader.uint32(),
          );
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.complete = WriteNodesRequest_CurrentAttemptWrite_StateTransition_Complete.decode(
            reader,
            reader.uint32(),
          );
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.incomplete = WriteNodesRequest_CurrentAttemptWrite_StateTransition_Incomplete.decode(
            reader,
            reader.uint32(),
          );
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteNodesRequest_CurrentAttemptWrite_StateTransition {
    return {
      throttled: isSet(object.throttled)
        ? WriteNodesRequest_CurrentAttemptWrite_StateTransition_Throttled.fromJSON(object.throttled)
        : undefined,
      scheduled: isSet(object.scheduled)
        ? WriteNodesRequest_CurrentAttemptWrite_StateTransition_Scheduled.fromJSON(object.scheduled)
        : undefined,
      running: isSet(object.running)
        ? WriteNodesRequest_CurrentAttemptWrite_StateTransition_Running.fromJSON(object.running)
        : undefined,
      tearingDown: isSet(object.tearingDown)
        ? WriteNodesRequest_CurrentAttemptWrite_StateTransition_TearingDown.fromJSON(object.tearingDown)
        : undefined,
      complete: isSet(object.complete)
        ? WriteNodesRequest_CurrentAttemptWrite_StateTransition_Complete.fromJSON(object.complete)
        : undefined,
      incomplete: isSet(object.incomplete)
        ? WriteNodesRequest_CurrentAttemptWrite_StateTransition_Incomplete.fromJSON(object.incomplete)
        : undefined,
    };
  },

  toJSON(message: WriteNodesRequest_CurrentAttemptWrite_StateTransition): unknown {
    const obj: any = {};
    if (message.throttled !== undefined) {
      obj.throttled = WriteNodesRequest_CurrentAttemptWrite_StateTransition_Throttled.toJSON(message.throttled);
    }
    if (message.scheduled !== undefined) {
      obj.scheduled = WriteNodesRequest_CurrentAttemptWrite_StateTransition_Scheduled.toJSON(message.scheduled);
    }
    if (message.running !== undefined) {
      obj.running = WriteNodesRequest_CurrentAttemptWrite_StateTransition_Running.toJSON(message.running);
    }
    if (message.tearingDown !== undefined) {
      obj.tearingDown = WriteNodesRequest_CurrentAttemptWrite_StateTransition_TearingDown.toJSON(message.tearingDown);
    }
    if (message.complete !== undefined) {
      obj.complete = WriteNodesRequest_CurrentAttemptWrite_StateTransition_Complete.toJSON(message.complete);
    }
    if (message.incomplete !== undefined) {
      obj.incomplete = WriteNodesRequest_CurrentAttemptWrite_StateTransition_Incomplete.toJSON(message.incomplete);
    }
    return obj;
  },

  create(
    base?: DeepPartial<WriteNodesRequest_CurrentAttemptWrite_StateTransition>,
  ): WriteNodesRequest_CurrentAttemptWrite_StateTransition {
    return WriteNodesRequest_CurrentAttemptWrite_StateTransition.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<WriteNodesRequest_CurrentAttemptWrite_StateTransition>,
  ): WriteNodesRequest_CurrentAttemptWrite_StateTransition {
    const message = createBaseWriteNodesRequest_CurrentAttemptWrite_StateTransition() as any;
    message.throttled = (object.throttled !== undefined && object.throttled !== null)
      ? WriteNodesRequest_CurrentAttemptWrite_StateTransition_Throttled.fromPartial(object.throttled)
      : undefined;
    message.scheduled = (object.scheduled !== undefined && object.scheduled !== null)
      ? WriteNodesRequest_CurrentAttemptWrite_StateTransition_Scheduled.fromPartial(object.scheduled)
      : undefined;
    message.running = (object.running !== undefined && object.running !== null)
      ? WriteNodesRequest_CurrentAttemptWrite_StateTransition_Running.fromPartial(object.running)
      : undefined;
    message.tearingDown = (object.tearingDown !== undefined && object.tearingDown !== null)
      ? WriteNodesRequest_CurrentAttemptWrite_StateTransition_TearingDown.fromPartial(object.tearingDown)
      : undefined;
    message.complete = (object.complete !== undefined && object.complete !== null)
      ? WriteNodesRequest_CurrentAttemptWrite_StateTransition_Complete.fromPartial(object.complete)
      : undefined;
    message.incomplete = (object.incomplete !== undefined && object.incomplete !== null)
      ? WriteNodesRequest_CurrentAttemptWrite_StateTransition_Incomplete.fromPartial(object.incomplete)
      : undefined;
    return message;
  },
};

function createBaseWriteNodesRequest_CurrentAttemptWrite_StateTransition_Throttled(): WriteNodesRequest_CurrentAttemptWrite_StateTransition_Throttled {
  return { until: undefined };
}

export const WriteNodesRequest_CurrentAttemptWrite_StateTransition_Throttled: MessageFns<
  WriteNodesRequest_CurrentAttemptWrite_StateTransition_Throttled
> = {
  encode(
    message: WriteNodesRequest_CurrentAttemptWrite_StateTransition_Throttled,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.until !== undefined) {
      Timestamp.encode(toTimestamp(message.until), writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): WriteNodesRequest_CurrentAttemptWrite_StateTransition_Throttled {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteNodesRequest_CurrentAttemptWrite_StateTransition_Throttled() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.until = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteNodesRequest_CurrentAttemptWrite_StateTransition_Throttled {
    return { until: isSet(object.until) ? globalThis.String(object.until) : undefined };
  },

  toJSON(message: WriteNodesRequest_CurrentAttemptWrite_StateTransition_Throttled): unknown {
    const obj: any = {};
    if (message.until !== undefined) {
      obj.until = message.until;
    }
    return obj;
  },

  create(
    base?: DeepPartial<WriteNodesRequest_CurrentAttemptWrite_StateTransition_Throttled>,
  ): WriteNodesRequest_CurrentAttemptWrite_StateTransition_Throttled {
    return WriteNodesRequest_CurrentAttemptWrite_StateTransition_Throttled.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<WriteNodesRequest_CurrentAttemptWrite_StateTransition_Throttled>,
  ): WriteNodesRequest_CurrentAttemptWrite_StateTransition_Throttled {
    const message = createBaseWriteNodesRequest_CurrentAttemptWrite_StateTransition_Throttled() as any;
    message.until = object.until ?? undefined;
    return message;
  },
};

function createBaseWriteNodesRequest_CurrentAttemptWrite_StateTransition_Scheduled(): WriteNodesRequest_CurrentAttemptWrite_StateTransition_Scheduled {
  return { attemptExecutionPolicy: undefined };
}

export const WriteNodesRequest_CurrentAttemptWrite_StateTransition_Scheduled: MessageFns<
  WriteNodesRequest_CurrentAttemptWrite_StateTransition_Scheduled
> = {
  encode(
    message: WriteNodesRequest_CurrentAttemptWrite_StateTransition_Scheduled,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.attemptExecutionPolicy !== undefined) {
      StageAttemptExecutionPolicy.encode(message.attemptExecutionPolicy, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): WriteNodesRequest_CurrentAttemptWrite_StateTransition_Scheduled {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteNodesRequest_CurrentAttemptWrite_StateTransition_Scheduled() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.attemptExecutionPolicy = StageAttemptExecutionPolicy.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteNodesRequest_CurrentAttemptWrite_StateTransition_Scheduled {
    return {
      attemptExecutionPolicy: isSet(object.attemptExecutionPolicy)
        ? StageAttemptExecutionPolicy.fromJSON(object.attemptExecutionPolicy)
        : undefined,
    };
  },

  toJSON(message: WriteNodesRequest_CurrentAttemptWrite_StateTransition_Scheduled): unknown {
    const obj: any = {};
    if (message.attemptExecutionPolicy !== undefined) {
      obj.attemptExecutionPolicy = StageAttemptExecutionPolicy.toJSON(message.attemptExecutionPolicy);
    }
    return obj;
  },

  create(
    base?: DeepPartial<WriteNodesRequest_CurrentAttemptWrite_StateTransition_Scheduled>,
  ): WriteNodesRequest_CurrentAttemptWrite_StateTransition_Scheduled {
    return WriteNodesRequest_CurrentAttemptWrite_StateTransition_Scheduled.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<WriteNodesRequest_CurrentAttemptWrite_StateTransition_Scheduled>,
  ): WriteNodesRequest_CurrentAttemptWrite_StateTransition_Scheduled {
    const message = createBaseWriteNodesRequest_CurrentAttemptWrite_StateTransition_Scheduled() as any;
    message.attemptExecutionPolicy =
      (object.attemptExecutionPolicy !== undefined && object.attemptExecutionPolicy !== null)
        ? StageAttemptExecutionPolicy.fromPartial(object.attemptExecutionPolicy)
        : undefined;
    return message;
  },
};

function createBaseWriteNodesRequest_CurrentAttemptWrite_StateTransition_Running(): WriteNodesRequest_CurrentAttemptWrite_StateTransition_Running {
  return { attemptExecutionPolicy: undefined, processUid: undefined };
}

export const WriteNodesRequest_CurrentAttemptWrite_StateTransition_Running: MessageFns<
  WriteNodesRequest_CurrentAttemptWrite_StateTransition_Running
> = {
  encode(
    message: WriteNodesRequest_CurrentAttemptWrite_StateTransition_Running,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.attemptExecutionPolicy !== undefined) {
      StageAttemptExecutionPolicy.encode(message.attemptExecutionPolicy, writer.uint32(10).fork()).join();
    }
    if (message.processUid !== undefined) {
      writer.uint32(18).string(message.processUid);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): WriteNodesRequest_CurrentAttemptWrite_StateTransition_Running {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteNodesRequest_CurrentAttemptWrite_StateTransition_Running() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.attemptExecutionPolicy = StageAttemptExecutionPolicy.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.processUid = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteNodesRequest_CurrentAttemptWrite_StateTransition_Running {
    return {
      attemptExecutionPolicy: isSet(object.attemptExecutionPolicy)
        ? StageAttemptExecutionPolicy.fromJSON(object.attemptExecutionPolicy)
        : undefined,
      processUid: isSet(object.processUid) ? globalThis.String(object.processUid) : undefined,
    };
  },

  toJSON(message: WriteNodesRequest_CurrentAttemptWrite_StateTransition_Running): unknown {
    const obj: any = {};
    if (message.attemptExecutionPolicy !== undefined) {
      obj.attemptExecutionPolicy = StageAttemptExecutionPolicy.toJSON(message.attemptExecutionPolicy);
    }
    if (message.processUid !== undefined) {
      obj.processUid = message.processUid;
    }
    return obj;
  },

  create(
    base?: DeepPartial<WriteNodesRequest_CurrentAttemptWrite_StateTransition_Running>,
  ): WriteNodesRequest_CurrentAttemptWrite_StateTransition_Running {
    return WriteNodesRequest_CurrentAttemptWrite_StateTransition_Running.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<WriteNodesRequest_CurrentAttemptWrite_StateTransition_Running>,
  ): WriteNodesRequest_CurrentAttemptWrite_StateTransition_Running {
    const message = createBaseWriteNodesRequest_CurrentAttemptWrite_StateTransition_Running() as any;
    message.attemptExecutionPolicy =
      (object.attemptExecutionPolicy !== undefined && object.attemptExecutionPolicy !== null)
        ? StageAttemptExecutionPolicy.fromPartial(object.attemptExecutionPolicy)
        : undefined;
    message.processUid = object.processUid ?? undefined;
    return message;
  },
};

function createBaseWriteNodesRequest_CurrentAttemptWrite_StateTransition_TearingDown(): WriteNodesRequest_CurrentAttemptWrite_StateTransition_TearingDown {
  return {};
}

export const WriteNodesRequest_CurrentAttemptWrite_StateTransition_TearingDown: MessageFns<
  WriteNodesRequest_CurrentAttemptWrite_StateTransition_TearingDown
> = {
  encode(
    _: WriteNodesRequest_CurrentAttemptWrite_StateTransition_TearingDown,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): WriteNodesRequest_CurrentAttemptWrite_StateTransition_TearingDown {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteNodesRequest_CurrentAttemptWrite_StateTransition_TearingDown() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): WriteNodesRequest_CurrentAttemptWrite_StateTransition_TearingDown {
    return {};
  },

  toJSON(_: WriteNodesRequest_CurrentAttemptWrite_StateTransition_TearingDown): unknown {
    const obj: any = {};
    return obj;
  },

  create(
    base?: DeepPartial<WriteNodesRequest_CurrentAttemptWrite_StateTransition_TearingDown>,
  ): WriteNodesRequest_CurrentAttemptWrite_StateTransition_TearingDown {
    return WriteNodesRequest_CurrentAttemptWrite_StateTransition_TearingDown.fromPartial(base ?? {});
  },
  fromPartial(
    _: DeepPartial<WriteNodesRequest_CurrentAttemptWrite_StateTransition_TearingDown>,
  ): WriteNodesRequest_CurrentAttemptWrite_StateTransition_TearingDown {
    const message = createBaseWriteNodesRequest_CurrentAttemptWrite_StateTransition_TearingDown() as any;
    return message;
  },
};

function createBaseWriteNodesRequest_CurrentAttemptWrite_StateTransition_Complete(): WriteNodesRequest_CurrentAttemptWrite_StateTransition_Complete {
  return {};
}

export const WriteNodesRequest_CurrentAttemptWrite_StateTransition_Complete: MessageFns<
  WriteNodesRequest_CurrentAttemptWrite_StateTransition_Complete
> = {
  encode(
    _: WriteNodesRequest_CurrentAttemptWrite_StateTransition_Complete,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): WriteNodesRequest_CurrentAttemptWrite_StateTransition_Complete {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteNodesRequest_CurrentAttemptWrite_StateTransition_Complete() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): WriteNodesRequest_CurrentAttemptWrite_StateTransition_Complete {
    return {};
  },

  toJSON(_: WriteNodesRequest_CurrentAttemptWrite_StateTransition_Complete): unknown {
    const obj: any = {};
    return obj;
  },

  create(
    base?: DeepPartial<WriteNodesRequest_CurrentAttemptWrite_StateTransition_Complete>,
  ): WriteNodesRequest_CurrentAttemptWrite_StateTransition_Complete {
    return WriteNodesRequest_CurrentAttemptWrite_StateTransition_Complete.fromPartial(base ?? {});
  },
  fromPartial(
    _: DeepPartial<WriteNodesRequest_CurrentAttemptWrite_StateTransition_Complete>,
  ): WriteNodesRequest_CurrentAttemptWrite_StateTransition_Complete {
    const message = createBaseWriteNodesRequest_CurrentAttemptWrite_StateTransition_Complete() as any;
    return message;
  },
};

function createBaseWriteNodesRequest_CurrentAttemptWrite_StateTransition_Incomplete(): WriteNodesRequest_CurrentAttemptWrite_StateTransition_Incomplete {
  return { blockNewAttempts: undefined };
}

export const WriteNodesRequest_CurrentAttemptWrite_StateTransition_Incomplete: MessageFns<
  WriteNodesRequest_CurrentAttemptWrite_StateTransition_Incomplete
> = {
  encode(
    message: WriteNodesRequest_CurrentAttemptWrite_StateTransition_Incomplete,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.blockNewAttempts !== undefined) {
      writer.uint32(8).bool(message.blockNewAttempts);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): WriteNodesRequest_CurrentAttemptWrite_StateTransition_Incomplete {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteNodesRequest_CurrentAttemptWrite_StateTransition_Incomplete() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.blockNewAttempts = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteNodesRequest_CurrentAttemptWrite_StateTransition_Incomplete {
    return {
      blockNewAttempts: isSet(object.blockNewAttempts) ? globalThis.Boolean(object.blockNewAttempts) : undefined,
    };
  },

  toJSON(message: WriteNodesRequest_CurrentAttemptWrite_StateTransition_Incomplete): unknown {
    const obj: any = {};
    if (message.blockNewAttempts !== undefined) {
      obj.blockNewAttempts = message.blockNewAttempts;
    }
    return obj;
  },

  create(
    base?: DeepPartial<WriteNodesRequest_CurrentAttemptWrite_StateTransition_Incomplete>,
  ): WriteNodesRequest_CurrentAttemptWrite_StateTransition_Incomplete {
    return WriteNodesRequest_CurrentAttemptWrite_StateTransition_Incomplete.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<WriteNodesRequest_CurrentAttemptWrite_StateTransition_Incomplete>,
  ): WriteNodesRequest_CurrentAttemptWrite_StateTransition_Incomplete {
    const message = createBaseWriteNodesRequest_CurrentAttemptWrite_StateTransition_Incomplete() as any;
    message.blockNewAttempts = object.blockNewAttempts ?? undefined;
    return message;
  },
};

function createBaseWriteNodesRequest_CurrentStageWrite(): WriteNodesRequest_CurrentStageWrite {
  return { continuationGroup: undefined };
}

export const WriteNodesRequest_CurrentStageWrite: MessageFns<WriteNodesRequest_CurrentStageWrite> = {
  encode(message: WriteNodesRequest_CurrentStageWrite, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.continuationGroup !== undefined) {
      WriteNodesRequest_DependencyGroup.encode(message.continuationGroup, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteNodesRequest_CurrentStageWrite {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteNodesRequest_CurrentStageWrite() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.continuationGroup = WriteNodesRequest_DependencyGroup.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteNodesRequest_CurrentStageWrite {
    return {
      continuationGroup: isSet(object.continuationGroup)
        ? WriteNodesRequest_DependencyGroup.fromJSON(object.continuationGroup)
        : undefined,
    };
  },

  toJSON(message: WriteNodesRequest_CurrentStageWrite): unknown {
    const obj: any = {};
    if (message.continuationGroup !== undefined) {
      obj.continuationGroup = WriteNodesRequest_DependencyGroup.toJSON(message.continuationGroup);
    }
    return obj;
  },

  create(base?: DeepPartial<WriteNodesRequest_CurrentStageWrite>): WriteNodesRequest_CurrentStageWrite {
    return WriteNodesRequest_CurrentStageWrite.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WriteNodesRequest_CurrentStageWrite>): WriteNodesRequest_CurrentStageWrite {
    const message = createBaseWriteNodesRequest_CurrentStageWrite() as any;
    message.continuationGroup = (object.continuationGroup !== undefined && object.continuationGroup !== null)
      ? WriteNodesRequest_DependencyGroup.fromPartial(object.continuationGroup)
      : undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function toTimestamp(dateStr: string): Timestamp {
  const date = new globalThis.Date(dateStr);
  const seconds = Math.trunc(date.getTime() / 1_000).toString();
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): string {
  let millis = (globalThis.Number(t.seconds) || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis).toISOString();
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
