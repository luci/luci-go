// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.7.5
//   protoc               v6.32.1
// source: turboci/graph/orchestrator/v1/write_nodes_request.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import { Any } from "../../../../google/protobuf/any.pb";
import { Check, Identifier, Stage } from "../../ids/v1/identifier.pb";
import { CheckKind, checkKindFromJSON, checkKindToJSON } from "./check_kind.pb";
import { CheckState, checkStateFromJSON, checkStateToJSON } from "./check_state.pb";
import { Edge } from "./edge.pb";
import { EdgeGroup } from "./edge_group.pb";
import { Edit_Reason } from "./edit.pb";
import { ExecutionPolicy } from "./execution_policy.pb";
import { Revision } from "./revision.pb";
import { Stage_Assignment } from "./stage.pb";
import { StageAttemptState, stageAttemptStateFromJSON, stageAttemptStateToJSON } from "./stage_attempt_state.pb";

export const protobufPackage = "turboci.graph.orchestrator.v1";

/**
 * Request message for TurboCIOrchestrator.WriteNodes.
 *
 * Allows atomically writing to multiple nodes (Checks, Stages) in a single
 * transaction.
 */
export interface WriteNodesRequest {
  /**
   * The token of the Stage Attempt which is performing this write.
   *
   * This is in addition to regular RPC authorization.
   *
   * If missing, this RPC will check that the caller additionally has the
   * 'turboci.workplans.writeExternal' permission on Workplan(s) in the
   * CheckWrites/StageWrites.
   */
  readonly stageAttemptToken?:
    | string
    | undefined;
  /**
   * The reason for this write operation, as supplied by the entity performing
   * the write.
   *
   * This should be used to detail any information about WHY this write is
   * happening, or details about what changes are being made.
   *
   * This will be reflected in the CheckEdit or StageEdit logs for all
   * Checks and/or Stages affected by this write.
   *
   * This is repeated to allow reasons in multiple security domains; By
   * convention, these should be ordered from most to least specific, so if
   * a client only wants to display one Reason, it should be the first in this
   * list which they have access to.
   */
  readonly reasons: readonly Edit_Reason[];
  /**
   * Set if the caller wants to make this write transactional with a subset of
   * the graph at a particular snapshot.
   *
   * If this is unset, then this is an 'oblivious write' and any valid writes
   * will apply/overwrite the current database state, assuming they are
   * semantically valid (i.e. it will still not be possible to change a Check's
   * realm, or roll a Check's state backwards, etc.).
   *
   * There are common cases where this will be left unset, for example when a
   * Stage Attempt updates its own progress based on its own internal state, or
   * when a Stage Attempt records results for a Check off of some internal
   * computation. It's allowed for a Stage Attempt to tie this progress update
   * to the state of the graph, but it's not expected or required.
   */
  readonly txn?:
    | WriteNodesRequest_TransactionDetails
    | undefined;
  /** Write to zero or more Checks. */
  readonly checks: readonly WriteNodesRequest_CheckWrite[];
  /** Write to zero or more Stages. */
  readonly stages: readonly WriteNodesRequest_StageWrite[];
  /**
   * State for the current Stage as indicated by `stage_attempt_token`.
   *
   * It is invalid to set this without also setting `stage_attempt_token`.
   *
   * All WriteNodes calls with a token act as a heartbeat for the current Stage
   * Attempt indicated by the token. If you need to implement the 'simplest
   * heartbeat', you can make a WriteNodes call with the token set and nothing
   * else.
   *
   * TBD: Document the SCHEDULED -> RUNNING state transition requirements (i.e.
   * setting a unique worker_id and handling multiple logicall processes all
   * trying to transition to RUNNING at the same time).
   */
  readonly currentStage?: WriteNodesRequest_CurrentStageWrite | undefined;
}

/**
 * RealmValue describes a standard Any which resides in a given security
 * realm.
 */
export interface WriteNodesRequest_RealmValue {
  /**
   * The realm to assign to this value (if the value is being created).
   * If it's unset/empty, it will inherit from the realm of the Stage
   * indicated by stage_attempt_token. If it's unset/empty and there is no
   * stage_attempt_token, the update will be rejected.
   *
   * If the value is being overwritten and `realm` is provided, it must match
   * the already-written value's realm.
   */
  readonly realm?:
    | string
    | undefined;
  /** The value to set. */
  readonly value?: Any | undefined;
}

/**
 * TransactionDetails encapsulates the information necessary to make this
 * write safe by describing the snapshot of the graph which the writer
 * observed. TurboCI Orchestrator will transactionally ensure that these nodes
 * haven't changed since the writer observed them.
 *
 * TurboCI Orchestrator will implicitly include all nodes which are being
 * written to - this message can provide additional nodes to that set.
 *
 * It is valid to include nodes which were absent from the snapshot, if the
 * writer wants to make its write conditional on their absence.
 *
 * Transaction Procedure:
 *   retry {
 *     nodes, snapshot_version = QueryNodes(...)
 *     # computations
 *
 *     more_nodes, _ = QueryNodes(..., ensure_version=snapshot_version)
 *     # This will cause QueryNodes to fail if any returned nodes have
 *     # a version greater than `snapshot_version`. This will allow the
 *     # transaction loop to retry.
 *
 *     # computations
 *
 *     if WriteNodes(..., txn={nodes+more_nodes, snapshot_version}) {
 *       # Success!
 *
 *       # It would be technically possible to use the written_version field from the
 *       # response to do another WriteNodes call, assuming you supply a subset of
 *       # the `nodes_observed` to the new write. However, if this second write fails,
 *       # you must restart the second write process from after the first Write.
 *       #
 *       # It is simplest to just start a second transaction loop, including potentially
 *       # re-reading the nodes_observed.
 *       break
 *     } else {
 *       # failure - retry from the top
 *     }
 *   }
 */
export interface WriteNodesRequest_TransactionDetails {
  /**
   * A list of all nodes observed which lead to this write.
   *
   * This SHOULD include all nodes which your computation used as inputs
   * for making a decision. If you locally filtered the GraphView before the
   * computation, it is OK to omit nodes which were filtered out, because you
   * would do the same write regardless of those filtered nodes' content.
   *
   * This MAY include nodes which were absent from the GraphView - this means
   * that the write is conditional on their absence (e.g. "I queried for X and
   * didn't find it, so I'm doing a write based on that information. If X DOES
   * exist at the time of the write, I want to abort and try again.").
   *
   * NOTE: If you are writing what you THINK is a new node, the safe thing to
   * do is to query for that node before doing the write (to confirm it
   * doesn't exist) and then also include that node ID in this list (to
   * confirm it didn't start existing before your write).
   */
  readonly nodesObserved: readonly Identifier[];
  /**
   * The 'version' of the GraphView returned from QueryNodes.
   *
   * If multiple queries were made in this transaction, this revision MUST be
   * the first revision observed. Providing version.require to QueryNodes will
   * help enforce this.
   */
  readonly snapshotVersion?: Revision | undefined;
}

/** A description of modifications to make to a single Check. */
export interface WriteNodesRequest_CheckWrite {
  /**
   * The check to write to.
   *
   * If the WorkPlan is left blank, will be populated with the WorkPlan in
   * `stage_attempt_token`, if it's provided.
   *
   * Otherwise, the Check must belong to the stage_attempt_token's WorkPlan,
   * or the caller must have the additional "turboci.workplans.writeExternal"
   * permission in the check's realm (or in the realm of the option/result
   * data).
   */
  readonly check?:
    | Check
    | undefined;
  /**
   * Realm to assign to this check.
   *
   * If this is set, and the Check DOES already exist, this MUST match the
   * existing realm.
   *
   * If absent and this CheckWrite creates the Check, the written Check will
   * copy its realm from the Stage doing the write (assuming
   * `stage_attempt_token` is set). If `stage_attempt_token` is unset and this
   * field is absent, the write will be rejected.
   */
  readonly realm?:
    | string
    | undefined;
  /**
   * Kind to assign to this check.
   *
   * If this is set, and the Check DOES already exist, this MUST match the
   * existing Check kind.
   */
  readonly kind?:
    | CheckKind
    | undefined;
  /**
   * The list of Options to write/overwrite.
   *
   * Must be unique on `RealmValue.value.type_url`.
   */
  readonly options: readonly WriteNodesRequest_RealmValue[];
  /**
   * Dependencies for this Check.
   *
   * If set, fully overwrites the dependencies field in the target Check.
   *
   * Empty groups will be pruned from this. You can remove all dependencies by
   * providing a single, empty, EdgeGroup.
   *
   * If this Write transitions the Check to PLANNED and also provides
   * dependencies, these must match identically to the already-written
   * dependencies.
   */
  readonly dependencies: readonly EdgeGroup[];
  /**
   * Write data to a Result for this Check.
   *
   * The Result to write in is keyed on:
   *   * The Stage Attempt (if stage_attempt_token is provided)
   *   * The caller's identity (if stage_attempt_token is absent)
   *
   * If the given keyed Result does not exist, it will be automatically
   * created. Multiple calls to WriteNodes from this same StageAttempt or
   * service account will update the same Result, and the Result will be
   * automatically finalized when this StageAttempt ends (if a WriteNodes with
   * `finalize_results` is not called before then).
   *
   * The data here will overwrite existing data of the same type in the
   * selected Result for this StageAttempt.
   */
  readonly results: readonly WriteNodesRequest_RealmValue[];
  /**
   * If set, finalize the Check.Result.
   *
   * No more data may be written to the Result from the caller after this is
   * set.
   */
  readonly finalizeResults?:
    | boolean
    | undefined;
  /**
   * The new state of this Check.
   *
   * If set, must be equal to, or greater than, the current state of the
   * Check.
   */
  readonly state?: CheckState | undefined;
}

/**
 * A description of modifications to make to a single Stage.
 *
 * Note that the `state` of a Stage is managed entirely by the Orchestrator
 * itself. If you are a Stage implementation and need to manage the state of
 * your own StageAttempt, see CurrentStageWrite.
 */
export interface WriteNodesRequest_StageWrite {
  /**
   * The stage to write to.
   *
   * If the WorkPlan is left blank, will be populated with the WorkPlan in
   * `stage_attempt_token`, if it's provided.
   *
   * Otherwise, the Stage must belong to the stage_attempt_token's WorkPlan,
   * or the caller must have the additional "turboci.workplans.writeExternal"
   * permission in the stage's realm.
   */
  readonly stage?:
    | Stage
    | undefined;
  /**
   * The arguments of the Stage.
   *
   * A Stage MUST have `args` - if this write would create the Stage and
   * `args` is omitted, the write will be rejected.
   *
   * TBD: Document executor registration/selection process.
   *
   * TBD: What to do on double-creation? Do we compare args (protobuf
   * serialization is not canonical/deterministic, but in practice if the
   * same process creates the same stage twice, it will likely have the same
   * args).
   *
   * We could just accept 'same type' == OK and ignore the value, but this
   * feels a bit wishy-washy.
   */
  readonly args?:
    | Any
    | undefined;
  /**
   * Realm to assign to this Stage.
   *
   * If the Stage already exists, this will only result in an error if it
   * doesn't match the existing realm.
   *
   * If absent, the written Stage will copy its realm from the Stage doing
   * the write (assuming `stage_attempt_token` is set). If
   * `stage_attempt_token` is unset and this field is absent, the write will
   * be rejected.
   */
  readonly realm?:
    | string
    | undefined;
  /**
   * Dependencies for this Stage.
   *
   * If the Stage already exists, this will only result in an error if it
   * doesn't match the existing dependencies identically.
   */
  readonly dependencies: readonly EdgeGroup[];
  /**
   * The requested retry policy of the Stage.
   *
   * If the Stage already exists, this will only result in an error if this
   * requested policy doesn't match doesn't match the existing requested policy.
   *
   * If this write creates the stage and the requested_execution_policy is
   * omitted, the stage will get the default ExecutionPolicy from the
   * Executor.
   */
  readonly requestedExecutionPolicy?:
    | ExecutionPolicy
    | undefined;
  /**
   * The Check assignments of the Stage.
   *
   * If the Stage already exists, this will only result in an error if it
   * doesn't match the existing assignments.
   */
  readonly assignments: readonly Stage_Assignment[];
  /**
   * If true, ensures that this Stage is marked for cancellation.
   *
   * If the Stage is in the ATTEMPTING state, and the current Attempt is
   * RUNNING, the Attempt will transition to CANCELLING - Otherwise the
   * current Attempt will be marked INCOMPLETE.
   *
   * If the Stage is already marked for cancellation, setting this is a no-op.
   *
   * A value of `false` is the same as `unset` (no-op).
   *
   * Use the top-level `reason` field to provide the cancellation reason.
   */
  readonly cancelled?: boolean | undefined;
}

/**
 * Internal writes for the Stage indicated by the token.
 *
 * These aspects come from either the Executor which owns this Stage Attempt,
 * or the running Stage Attempt process.
 */
export interface WriteNodesRequest_CurrentStageWrite {
  /**
   * Report the attempt's current state. This can only make the following
   * transitions (since all other transitions are handled by the Orchestrator
   * itself):
   *
   *   * SCHEDULED -> RUNNING
   *   * SCHEDULED -> COMPLETE
   *   * SCHEDULED -> INCOMPLETE
   *   * RUNNING -> TEARING_DOWN
   *   * RUNNING -> COMPLETE
   *   * RUNNING -> INCOMPLETE
   */
  readonly state?:
    | StageAttemptState
    | undefined;
  /**
   * Ensure all provided edges are included in `Stage.continuation_group`.
   *
   * Edges are deduplicated with `Stage.continuation_group` if they have the
   * same `target`.
   *
   * TBD: When edges have conditions, will want to coalesce the conditions
   * with `and` instead? Or just reject multiple conditional Edges with the
   * same target? Or replace the condition in the existing Edge?
   */
  readonly ensureInContinuationGroup: readonly Edge[];
}

function createBaseWriteNodesRequest(): WriteNodesRequest {
  return { stageAttemptToken: undefined, reasons: [], txn: undefined, checks: [], stages: [], currentStage: undefined };
}

export const WriteNodesRequest: MessageFns<WriteNodesRequest> = {
  encode(message: WriteNodesRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.stageAttemptToken !== undefined) {
      writer.uint32(10).string(message.stageAttemptToken);
    }
    for (const v of message.reasons) {
      Edit_Reason.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.txn !== undefined) {
      WriteNodesRequest_TransactionDetails.encode(message.txn, writer.uint32(26).fork()).join();
    }
    for (const v of message.checks) {
      WriteNodesRequest_CheckWrite.encode(v!, writer.uint32(34).fork()).join();
    }
    for (const v of message.stages) {
      WriteNodesRequest_StageWrite.encode(v!, writer.uint32(42).fork()).join();
    }
    if (message.currentStage !== undefined) {
      WriteNodesRequest_CurrentStageWrite.encode(message.currentStage, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteNodesRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteNodesRequest() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.stageAttemptToken = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.reasons.push(Edit_Reason.decode(reader, reader.uint32()));
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.txn = WriteNodesRequest_TransactionDetails.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.checks.push(WriteNodesRequest_CheckWrite.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.stages.push(WriteNodesRequest_StageWrite.decode(reader, reader.uint32()));
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.currentStage = WriteNodesRequest_CurrentStageWrite.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteNodesRequest {
    return {
      stageAttemptToken: isSet(object.stageAttemptToken) ? globalThis.String(object.stageAttemptToken) : undefined,
      reasons: globalThis.Array.isArray(object?.reasons) ? object.reasons.map((e: any) => Edit_Reason.fromJSON(e)) : [],
      txn: isSet(object.txn) ? WriteNodesRequest_TransactionDetails.fromJSON(object.txn) : undefined,
      checks: globalThis.Array.isArray(object?.checks)
        ? object.checks.map((e: any) => WriteNodesRequest_CheckWrite.fromJSON(e))
        : [],
      stages: globalThis.Array.isArray(object?.stages)
        ? object.stages.map((e: any) => WriteNodesRequest_StageWrite.fromJSON(e))
        : [],
      currentStage: isSet(object.currentStage)
        ? WriteNodesRequest_CurrentStageWrite.fromJSON(object.currentStage)
        : undefined,
    };
  },

  toJSON(message: WriteNodesRequest): unknown {
    const obj: any = {};
    if (message.stageAttemptToken !== undefined) {
      obj.stageAttemptToken = message.stageAttemptToken;
    }
    if (message.reasons?.length) {
      obj.reasons = message.reasons.map((e) => Edit_Reason.toJSON(e));
    }
    if (message.txn !== undefined) {
      obj.txn = WriteNodesRequest_TransactionDetails.toJSON(message.txn);
    }
    if (message.checks?.length) {
      obj.checks = message.checks.map((e) => WriteNodesRequest_CheckWrite.toJSON(e));
    }
    if (message.stages?.length) {
      obj.stages = message.stages.map((e) => WriteNodesRequest_StageWrite.toJSON(e));
    }
    if (message.currentStage !== undefined) {
      obj.currentStage = WriteNodesRequest_CurrentStageWrite.toJSON(message.currentStage);
    }
    return obj;
  },

  create(base?: DeepPartial<WriteNodesRequest>): WriteNodesRequest {
    return WriteNodesRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WriteNodesRequest>): WriteNodesRequest {
    const message = createBaseWriteNodesRequest() as any;
    message.stageAttemptToken = object.stageAttemptToken ?? undefined;
    message.reasons = object.reasons?.map((e) => Edit_Reason.fromPartial(e)) || [];
    message.txn = (object.txn !== undefined && object.txn !== null)
      ? WriteNodesRequest_TransactionDetails.fromPartial(object.txn)
      : undefined;
    message.checks = object.checks?.map((e) => WriteNodesRequest_CheckWrite.fromPartial(e)) || [];
    message.stages = object.stages?.map((e) => WriteNodesRequest_StageWrite.fromPartial(e)) || [];
    message.currentStage = (object.currentStage !== undefined && object.currentStage !== null)
      ? WriteNodesRequest_CurrentStageWrite.fromPartial(object.currentStage)
      : undefined;
    return message;
  },
};

function createBaseWriteNodesRequest_RealmValue(): WriteNodesRequest_RealmValue {
  return { realm: undefined, value: undefined };
}

export const WriteNodesRequest_RealmValue: MessageFns<WriteNodesRequest_RealmValue> = {
  encode(message: WriteNodesRequest_RealmValue, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.realm !== undefined) {
      writer.uint32(10).string(message.realm);
    }
    if (message.value !== undefined) {
      Any.encode(message.value, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteNodesRequest_RealmValue {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteNodesRequest_RealmValue() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.realm = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = Any.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteNodesRequest_RealmValue {
    return {
      realm: isSet(object.realm) ? globalThis.String(object.realm) : undefined,
      value: isSet(object.value) ? Any.fromJSON(object.value) : undefined,
    };
  },

  toJSON(message: WriteNodesRequest_RealmValue): unknown {
    const obj: any = {};
    if (message.realm !== undefined) {
      obj.realm = message.realm;
    }
    if (message.value !== undefined) {
      obj.value = Any.toJSON(message.value);
    }
    return obj;
  },

  create(base?: DeepPartial<WriteNodesRequest_RealmValue>): WriteNodesRequest_RealmValue {
    return WriteNodesRequest_RealmValue.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WriteNodesRequest_RealmValue>): WriteNodesRequest_RealmValue {
    const message = createBaseWriteNodesRequest_RealmValue() as any;
    message.realm = object.realm ?? undefined;
    message.value = (object.value !== undefined && object.value !== null) ? Any.fromPartial(object.value) : undefined;
    return message;
  },
};

function createBaseWriteNodesRequest_TransactionDetails(): WriteNodesRequest_TransactionDetails {
  return { nodesObserved: [], snapshotVersion: undefined };
}

export const WriteNodesRequest_TransactionDetails: MessageFns<WriteNodesRequest_TransactionDetails> = {
  encode(message: WriteNodesRequest_TransactionDetails, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.nodesObserved) {
      Identifier.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.snapshotVersion !== undefined) {
      Revision.encode(message.snapshotVersion, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteNodesRequest_TransactionDetails {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteNodesRequest_TransactionDetails() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.nodesObserved.push(Identifier.decode(reader, reader.uint32()));
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.snapshotVersion = Revision.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteNodesRequest_TransactionDetails {
    return {
      nodesObserved: globalThis.Array.isArray(object?.nodesObserved)
        ? object.nodesObserved.map((e: any) => Identifier.fromJSON(e))
        : [],
      snapshotVersion: isSet(object.snapshotVersion) ? Revision.fromJSON(object.snapshotVersion) : undefined,
    };
  },

  toJSON(message: WriteNodesRequest_TransactionDetails): unknown {
    const obj: any = {};
    if (message.nodesObserved?.length) {
      obj.nodesObserved = message.nodesObserved.map((e) => Identifier.toJSON(e));
    }
    if (message.snapshotVersion !== undefined) {
      obj.snapshotVersion = Revision.toJSON(message.snapshotVersion);
    }
    return obj;
  },

  create(base?: DeepPartial<WriteNodesRequest_TransactionDetails>): WriteNodesRequest_TransactionDetails {
    return WriteNodesRequest_TransactionDetails.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WriteNodesRequest_TransactionDetails>): WriteNodesRequest_TransactionDetails {
    const message = createBaseWriteNodesRequest_TransactionDetails() as any;
    message.nodesObserved = object.nodesObserved?.map((e) => Identifier.fromPartial(e)) || [];
    message.snapshotVersion = (object.snapshotVersion !== undefined && object.snapshotVersion !== null)
      ? Revision.fromPartial(object.snapshotVersion)
      : undefined;
    return message;
  },
};

function createBaseWriteNodesRequest_CheckWrite(): WriteNodesRequest_CheckWrite {
  return {
    check: undefined,
    realm: undefined,
    kind: undefined,
    options: [],
    dependencies: [],
    results: [],
    finalizeResults: undefined,
    state: undefined,
  };
}

export const WriteNodesRequest_CheckWrite: MessageFns<WriteNodesRequest_CheckWrite> = {
  encode(message: WriteNodesRequest_CheckWrite, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.check !== undefined) {
      Check.encode(message.check, writer.uint32(10).fork()).join();
    }
    if (message.realm !== undefined) {
      writer.uint32(18).string(message.realm);
    }
    if (message.kind !== undefined) {
      writer.uint32(24).int32(message.kind);
    }
    for (const v of message.options) {
      WriteNodesRequest_RealmValue.encode(v!, writer.uint32(34).fork()).join();
    }
    for (const v of message.dependencies) {
      EdgeGroup.encode(v!, writer.uint32(42).fork()).join();
    }
    for (const v of message.results) {
      WriteNodesRequest_RealmValue.encode(v!, writer.uint32(50).fork()).join();
    }
    if (message.finalizeResults !== undefined) {
      writer.uint32(56).bool(message.finalizeResults);
    }
    if (message.state !== undefined) {
      writer.uint32(64).int32(message.state);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteNodesRequest_CheckWrite {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteNodesRequest_CheckWrite() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.check = Check.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.realm = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.kind = reader.int32() as any;
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.options.push(WriteNodesRequest_RealmValue.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.dependencies.push(EdgeGroup.decode(reader, reader.uint32()));
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.results.push(WriteNodesRequest_RealmValue.decode(reader, reader.uint32()));
          continue;
        }
        case 7: {
          if (tag !== 56) {
            break;
          }

          message.finalizeResults = reader.bool();
          continue;
        }
        case 8: {
          if (tag !== 64) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteNodesRequest_CheckWrite {
    return {
      check: isSet(object.check) ? Check.fromJSON(object.check) : undefined,
      realm: isSet(object.realm) ? globalThis.String(object.realm) : undefined,
      kind: isSet(object.kind) ? checkKindFromJSON(object.kind) : undefined,
      options: globalThis.Array.isArray(object?.options)
        ? object.options.map((e: any) => WriteNodesRequest_RealmValue.fromJSON(e))
        : [],
      dependencies: globalThis.Array.isArray(object?.dependencies)
        ? object.dependencies.map((e: any) => EdgeGroup.fromJSON(e))
        : [],
      results: globalThis.Array.isArray(object?.results)
        ? object.results.map((e: any) => WriteNodesRequest_RealmValue.fromJSON(e))
        : [],
      finalizeResults: isSet(object.finalizeResults) ? globalThis.Boolean(object.finalizeResults) : undefined,
      state: isSet(object.state) ? checkStateFromJSON(object.state) : undefined,
    };
  },

  toJSON(message: WriteNodesRequest_CheckWrite): unknown {
    const obj: any = {};
    if (message.check !== undefined) {
      obj.check = Check.toJSON(message.check);
    }
    if (message.realm !== undefined) {
      obj.realm = message.realm;
    }
    if (message.kind !== undefined) {
      obj.kind = checkKindToJSON(message.kind);
    }
    if (message.options?.length) {
      obj.options = message.options.map((e) => WriteNodesRequest_RealmValue.toJSON(e));
    }
    if (message.dependencies?.length) {
      obj.dependencies = message.dependencies.map((e) => EdgeGroup.toJSON(e));
    }
    if (message.results?.length) {
      obj.results = message.results.map((e) => WriteNodesRequest_RealmValue.toJSON(e));
    }
    if (message.finalizeResults !== undefined) {
      obj.finalizeResults = message.finalizeResults;
    }
    if (message.state !== undefined) {
      obj.state = checkStateToJSON(message.state);
    }
    return obj;
  },

  create(base?: DeepPartial<WriteNodesRequest_CheckWrite>): WriteNodesRequest_CheckWrite {
    return WriteNodesRequest_CheckWrite.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WriteNodesRequest_CheckWrite>): WriteNodesRequest_CheckWrite {
    const message = createBaseWriteNodesRequest_CheckWrite() as any;
    message.check = (object.check !== undefined && object.check !== null) ? Check.fromPartial(object.check) : undefined;
    message.realm = object.realm ?? undefined;
    message.kind = object.kind ?? undefined;
    message.options = object.options?.map((e) => WriteNodesRequest_RealmValue.fromPartial(e)) || [];
    message.dependencies = object.dependencies?.map((e) => EdgeGroup.fromPartial(e)) || [];
    message.results = object.results?.map((e) => WriteNodesRequest_RealmValue.fromPartial(e)) || [];
    message.finalizeResults = object.finalizeResults ?? undefined;
    message.state = object.state ?? undefined;
    return message;
  },
};

function createBaseWriteNodesRequest_StageWrite(): WriteNodesRequest_StageWrite {
  return {
    stage: undefined,
    args: undefined,
    realm: undefined,
    dependencies: [],
    requestedExecutionPolicy: undefined,
    assignments: [],
    cancelled: undefined,
  };
}

export const WriteNodesRequest_StageWrite: MessageFns<WriteNodesRequest_StageWrite> = {
  encode(message: WriteNodesRequest_StageWrite, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.stage !== undefined) {
      Stage.encode(message.stage, writer.uint32(10).fork()).join();
    }
    if (message.args !== undefined) {
      Any.encode(message.args, writer.uint32(18).fork()).join();
    }
    if (message.realm !== undefined) {
      writer.uint32(26).string(message.realm);
    }
    for (const v of message.dependencies) {
      EdgeGroup.encode(v!, writer.uint32(34).fork()).join();
    }
    if (message.requestedExecutionPolicy !== undefined) {
      ExecutionPolicy.encode(message.requestedExecutionPolicy, writer.uint32(42).fork()).join();
    }
    for (const v of message.assignments) {
      Stage_Assignment.encode(v!, writer.uint32(50).fork()).join();
    }
    if (message.cancelled !== undefined) {
      writer.uint32(56).bool(message.cancelled);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteNodesRequest_StageWrite {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteNodesRequest_StageWrite() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.stage = Stage.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.args = Any.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.realm = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.dependencies.push(EdgeGroup.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.requestedExecutionPolicy = ExecutionPolicy.decode(reader, reader.uint32());
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.assignments.push(Stage_Assignment.decode(reader, reader.uint32()));
          continue;
        }
        case 7: {
          if (tag !== 56) {
            break;
          }

          message.cancelled = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteNodesRequest_StageWrite {
    return {
      stage: isSet(object.stage) ? Stage.fromJSON(object.stage) : undefined,
      args: isSet(object.args) ? Any.fromJSON(object.args) : undefined,
      realm: isSet(object.realm) ? globalThis.String(object.realm) : undefined,
      dependencies: globalThis.Array.isArray(object?.dependencies)
        ? object.dependencies.map((e: any) => EdgeGroup.fromJSON(e))
        : [],
      requestedExecutionPolicy: isSet(object.requestedExecutionPolicy)
        ? ExecutionPolicy.fromJSON(object.requestedExecutionPolicy)
        : undefined,
      assignments: globalThis.Array.isArray(object?.assignments)
        ? object.assignments.map((e: any) => Stage_Assignment.fromJSON(e))
        : [],
      cancelled: isSet(object.cancelled) ? globalThis.Boolean(object.cancelled) : undefined,
    };
  },

  toJSON(message: WriteNodesRequest_StageWrite): unknown {
    const obj: any = {};
    if (message.stage !== undefined) {
      obj.stage = Stage.toJSON(message.stage);
    }
    if (message.args !== undefined) {
      obj.args = Any.toJSON(message.args);
    }
    if (message.realm !== undefined) {
      obj.realm = message.realm;
    }
    if (message.dependencies?.length) {
      obj.dependencies = message.dependencies.map((e) => EdgeGroup.toJSON(e));
    }
    if (message.requestedExecutionPolicy !== undefined) {
      obj.requestedExecutionPolicy = ExecutionPolicy.toJSON(message.requestedExecutionPolicy);
    }
    if (message.assignments?.length) {
      obj.assignments = message.assignments.map((e) => Stage_Assignment.toJSON(e));
    }
    if (message.cancelled !== undefined) {
      obj.cancelled = message.cancelled;
    }
    return obj;
  },

  create(base?: DeepPartial<WriteNodesRequest_StageWrite>): WriteNodesRequest_StageWrite {
    return WriteNodesRequest_StageWrite.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WriteNodesRequest_StageWrite>): WriteNodesRequest_StageWrite {
    const message = createBaseWriteNodesRequest_StageWrite() as any;
    message.stage = (object.stage !== undefined && object.stage !== null) ? Stage.fromPartial(object.stage) : undefined;
    message.args = (object.args !== undefined && object.args !== null) ? Any.fromPartial(object.args) : undefined;
    message.realm = object.realm ?? undefined;
    message.dependencies = object.dependencies?.map((e) => EdgeGroup.fromPartial(e)) || [];
    message.requestedExecutionPolicy =
      (object.requestedExecutionPolicy !== undefined && object.requestedExecutionPolicy !== null)
        ? ExecutionPolicy.fromPartial(object.requestedExecutionPolicy)
        : undefined;
    message.assignments = object.assignments?.map((e) => Stage_Assignment.fromPartial(e)) || [];
    message.cancelled = object.cancelled ?? undefined;
    return message;
  },
};

function createBaseWriteNodesRequest_CurrentStageWrite(): WriteNodesRequest_CurrentStageWrite {
  return { state: undefined, ensureInContinuationGroup: [] };
}

export const WriteNodesRequest_CurrentStageWrite: MessageFns<WriteNodesRequest_CurrentStageWrite> = {
  encode(message: WriteNodesRequest_CurrentStageWrite, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.state !== undefined) {
      writer.uint32(8).int32(message.state);
    }
    for (const v of message.ensureInContinuationGroup) {
      Edge.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): WriteNodesRequest_CurrentStageWrite {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseWriteNodesRequest_CurrentStageWrite() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.ensureInContinuationGroup.push(Edge.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): WriteNodesRequest_CurrentStageWrite {
    return {
      state: isSet(object.state) ? stageAttemptStateFromJSON(object.state) : undefined,
      ensureInContinuationGroup: globalThis.Array.isArray(object?.ensureInContinuationGroup)
        ? object.ensureInContinuationGroup.map((e: any) => Edge.fromJSON(e))
        : [],
    };
  },

  toJSON(message: WriteNodesRequest_CurrentStageWrite): unknown {
    const obj: any = {};
    if (message.state !== undefined) {
      obj.state = stageAttemptStateToJSON(message.state);
    }
    if (message.ensureInContinuationGroup?.length) {
      obj.ensureInContinuationGroup = message.ensureInContinuationGroup.map((e) => Edge.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<WriteNodesRequest_CurrentStageWrite>): WriteNodesRequest_CurrentStageWrite {
    return WriteNodesRequest_CurrentStageWrite.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<WriteNodesRequest_CurrentStageWrite>): WriteNodesRequest_CurrentStageWrite {
    const message = createBaseWriteNodesRequest_CurrentStageWrite() as any;
    message.state = object.state ?? undefined;
    message.ensureInContinuationGroup = object.ensureInContinuationGroup?.map((e) => Edge.fromPartial(e)) || [];
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
