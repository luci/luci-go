// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.7.5
//   protoc               v6.32.1
// source: turboci/graph/orchestrator/v1/stage.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import { Check, Stage as Stage1 } from "../../ids/v1/identifier.pb";
import { CheckState, checkStateFromJSON, checkStateToJSON } from "./check_state.pb";
import { Edge } from "./edge.pb";
import { EdgeGroup } from "./edge_group.pb";
import { ExecutionPolicy } from "./execution_policy.pb";
import { Revision } from "./revision.pb";
import { StageAttemptState, stageAttemptStateFromJSON, stageAttemptStateToJSON } from "./stage_attempt_state.pb";
import { StageState, stageStateFromJSON, stageStateToJSON } from "./stage_state.pb";
import { Value } from "./value.pb";

export const protobufPackage = "turboci.graph.orchestrator.v1";

/**
 * A Stage is an executable node in the workflow.
 *
 * The Orchestrator will coordinate with the Executor which is registered to
 * match `args.type_url` to actually run the Stage.
 *
 * See also:
 *   * StageView (graph view object for a Stage and contained messages)
 *   * StageEditView (graph view object for Edits of a Stage)
 */
export interface Stage {
  /** The Stage's identifier. */
  readonly identifier?:
    | Stage1
    | undefined;
  /**
   * The security realm for this Stage.
   *
   * When a Stage inserts another, the inserted Stage will inherit the realm of
   * the inserting Stage, unless this is explicitly set.
   */
  readonly realm?:
    | string
    | undefined;
  /** The database revision (commit timestamp) when this Stage was created. */
  readonly createTs?:
    | Revision
    | undefined;
  /**
   * The arguments of the Stage.
   *
   * `identifier` is always empty.
   *
   * The type of this Datum must be pre-registered with the Orchestrator, and
   * that registration will indicate which Executor should handle this Stage.
   *
   * NOTE: It's assumed that args.type_url will be a sufficient routing key to
   * the various registered Executors, but it's POSSIBLE that we may need to
   * have multiple Executors handle exactly the same Stage type, at which point
   * we would need to either:
   *   * Add a secondary type to distinguish them; this would have the
   *     additional benefit of allowing us to clearly delineate the differences
   *     via documentation, but if we have this situation a lot, it could be
   *     confusing.
   *   * Add another field to Stage to allow registration on (newfield,
   *     type_url) instead of just type_url.
   *
   * Looking at WorkNode, there are definitely multiple executor types which
   * accept the same arguments in WorkParameters, but these could be represented
   * by adding a new field to WorkParameters. There is also the PARTIAL_RERUN
   * executor type which is used when duplicating WorkNodes, but this seems like
   * it will be handled differently with Checks (i.e. Checks of the same options
   * would be added, and new Results of the cached results would be added. There
   * wouldn't be a need to add placeholder Stages into such a graph). There
   * are also some executor types which serve as a way to separate ACLs, but
   * we expect this to be handled by realms.
   */
  readonly args?:
    | Value
    | undefined;
  /**
   * The version of this Stage.
   *
   * Updated any time fields in this Stage change, which includes all changes to
   * the active Stage Attempt (if state is ATTEMPTING).
   */
  readonly version?:
    | Revision
    | undefined;
  /** The current state of the Stage. */
  readonly state?:
    | StageState
    | undefined;
  /**
   * Stages are allowed to depend on other Checks and Stages, and will not be
   * sent to an Executor until these dependencies are resolved.
   */
  readonly dependencies: readonly EdgeGroup[];
  /** Execution policy for this Stage. */
  readonly executionPolicy?:
    | Stage_ExecutionPolicyState
    | undefined;
  /**
   * Current retry/attempts state of this Stage, stored in ascending order by
   * created time.
   *
   * Only the most recent attempt (the last in the list) is potentially 'live'.
   */
  readonly attempts: readonly Stage_Attempt[];
  /** The workflow's intent for this Stage. */
  readonly assignments: readonly Stage_Assignment[];
  /**
   * A set of other Stages, created by this Stage, which should be treated as a
   * logical part of this Stage.
   *
   * Any other Stages in the graph waiting for this one to be FINAL will
   * additionally wait for the continuation_group stages to be FINAL as well,
   * allowing this Stage to transition to WAITING_FOR_GROUP without unblocking
   * dependent Stages.
   *
   * This allows for encapsulation of work where one Stage may spawn a group of
   * Stages which should be treated as a single unit - otherwise all waiters for
   * this Stage would need to be informed of, and wait for, these new Stages
   * which introduces a leaky abstraction.
   */
  readonly continuationGroup: readonly Edge[];
}

/**
 * ExecutionPolicyState is the set of execution policies which define the
 * overall execution policy for this Stage.
 *
 * `requested` is set by the stage creator. This is validated and augmented by
 * the Executor to become the `validated` policy.
 *
 * It is expected that a requested ExecutionPolicy which is over-broad will be
 * rejected by the Executor (rather than silently capped), but this is not
 * enforced by TurboCI.
 *
 * In the future, this may also include a `dynamic` policy which could allow
 * additional restrictions to be added after the Stage is created.
 */
export interface Stage_ExecutionPolicyState {
  /**
   * Requested execution policy is the policy which is set by the creator of
   * this Stage.
   *
   * This will be validated by the Executor prior to the Stage being committed
   * to the graph.
   *
   * If omitted, the Executor will provide a full ExecutionPolicy according to
   * its own logic/configuration.
   */
  readonly requested?:
    | ExecutionPolicy
    | undefined;
  /**
   * Actual execution policy is the policy validated and returned by the
   * Executor when it accepts the Stage for insertion to the graph.
   *
   * This is the policy that TurboCI will use to drive Attempts for this
   * Stage.
   */
  readonly validated?: ExecutionPolicy | undefined;
}

/**
 * Attempt represents a single attempt to execute a Stage.
 *
 * Stages in the AWAITING state ALWAYS have an active Attempt, even before
 * the Orchestrator sends the first RPC to the Executor for this Stage.
 *
 * TBD: Pull this into its own top-level StageAttempt entity because it will
 * need to have its own state and lifecycle/transactions.
 */
export interface Stage_Attempt {
  /** The current state of this Attempt. */
  readonly state?:
    | StageAttemptState
    | undefined;
  /** The database revision of when the current state was set. */
  readonly version?:
    | Revision
    | undefined;
  /**
   * An opaque value provided by a Stage Attempt process (i.e. a single thread
   * of execution which is servicing this Stage Attempt) which is used to
   * ensure that a StageAttempt is idempotently assigned to at most one single
   * thread of execution globally.
   *
   * Consider the case where a task with a StageAttemptToken is dispatched to
   * a worker fleet and due to bugs/netsplits/solar flares/etc. the task ends
   * up on two different machines in the fleet, or in two different pubsub
   * handlers. Basically, two logical processes now have a StageAttemptToken,
   * and this Stage Attempt is in the SCHEDULED state.
   *
   * The first thing all of these copycat processes should do is a WriteNodes
   * RPC where they attempt to set `process_uid` to a value *unique to that
   * worker thread*, and transition the state to RUNNING.
   *
   * The Orchestrator service will only permit this field to be set while the
   * Stage Attempt is SCHEDULED. In the case of network failure, multiple
   * calls of `WriteNodes(token, current={RUNNING, <process_uid>})` with the
   * same process_uid will all succeed. However, the other worker threads will
   * produce different process_uid values, and the server will reject their
   * attempt to transition to the RUNNING state, and they should drop the
   * task.
   *
   * There is no specific form for process_uid, but it must be unique per
   * thread consuming this Stage Attempt. Examples:
   *   * A UUID
   *   * hostname:process_id:thread_id
   *   * servicename:unique_assigned_process_name
   *
   * In the event that this accepting thread crashes, it is expected that this
   * Stage Attempt will become INCOMPLETE on heartbeat timeout, and, retries
   * permitting, a new Stage Attempt will be generated.
   */
  readonly processUid?:
    | string
    | undefined;
  /**
   * Details provided by the Executor about this Stage Attempt.
   *
   * This information is always updated in-whole from the Executor or
   * StageAttempt and is meant to house critical data like links to the
   * underlying Executor, build/task ids, etc.
   *
   * It can be set by the Executor or Stage Attempt as long as the Stage
   * Attempt is not final (i.e. COMPLETE or INCOMPLETE).
   */
  readonly details: readonly Value[];
  /** Append-only Executor-specefic progress messages. */
  readonly progress: readonly Stage_Attempt_Progress[];
}

/**
 * Attempt-specific progress information.
 *
 * Note that the Edit log also has a Reason for every graph write - this
 * Progress message should be used when the Executor wants e.g. the UI to be
 * able to load just the current state of a Stage and display this
 * information in a time-oriented way.
 */
export interface Stage_Attempt_Progress {
  /** Low-effort/human-readable progress information. */
  readonly msg?:
    | string
    | undefined;
  /** The version of this Stage which added this Progress message. */
  readonly version?:
    | Revision
    | undefined;
  /** Machine-readable details for this progress item. */
  readonly details: readonly Value[];
}

/**
 * Assignment describes the workflow's intent that this Stage will handle one
 * or more Checks in some fashion.
 */
export interface Stage_Assignment {
  /** The Check that this Stage should handle. */
  readonly target?:
    | Check
    | undefined;
  /**
   * The expected state of the Check when this Stage is FINAL.
   *
   * NOTE: The Stage may, during its execution, create additional Stages with
   * this same Assignment as a way of propagating the responsibility of
   * handling the Check to those Stages.
   *
   * The Orchestrator will automatically advance the state of this Check to
   * the goal state when no more Stages are assigned to handle it with this
   * goal state.
   *
   * Ex. If some stage S is assigned a Check C with goal state PLANNED, it
   * indicates that S is responsible for ensuring that C is fully PLANNED. S
   * could spawn some helpers (S' and S'') with this same Assignment. Assuming
   * that S' and S'' don't further propagate the responsibility of handling C,
   * when all of S, S', and S'' are FINAL, the Orchestrator will advance C to
   * the PLANNED state.
   *
   * If a stage manually advances a Check to a state equal to or beyond the
   * goal state, then the Orchestrator will stop monitoring Assignments for
   * this Check at this goal state.
   *
   * Manual advancement can dangerous if done when other Stages are still
   * operating on the Check at the earlier state (for example, if one Stage
   * moves a Check to PLANNED while another Stage is still trying to write to
   * the Check options, the writing Stage will fail to write out the options).
   */
  readonly goalState?: CheckState | undefined;
}

function createBaseStage(): Stage {
  return {
    identifier: undefined,
    realm: undefined,
    createTs: undefined,
    args: undefined,
    version: undefined,
    state: undefined,
    dependencies: [],
    executionPolicy: undefined,
    attempts: [],
    assignments: [],
    continuationGroup: [],
  };
}

export const Stage: MessageFns<Stage> = {
  encode(message: Stage, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.identifier !== undefined) {
      Stage1.encode(message.identifier, writer.uint32(10).fork()).join();
    }
    if (message.realm !== undefined) {
      writer.uint32(18).string(message.realm);
    }
    if (message.createTs !== undefined) {
      Revision.encode(message.createTs, writer.uint32(26).fork()).join();
    }
    if (message.args !== undefined) {
      Value.encode(message.args, writer.uint32(34).fork()).join();
    }
    if (message.version !== undefined) {
      Revision.encode(message.version, writer.uint32(42).fork()).join();
    }
    if (message.state !== undefined) {
      writer.uint32(48).int32(message.state);
    }
    for (const v of message.dependencies) {
      EdgeGroup.encode(v!, writer.uint32(58).fork()).join();
    }
    if (message.executionPolicy !== undefined) {
      Stage_ExecutionPolicyState.encode(message.executionPolicy, writer.uint32(66).fork()).join();
    }
    for (const v of message.attempts) {
      Stage_Attempt.encode(v!, writer.uint32(74).fork()).join();
    }
    for (const v of message.assignments) {
      Stage_Assignment.encode(v!, writer.uint32(82).fork()).join();
    }
    for (const v of message.continuationGroup) {
      Edge.encode(v!, writer.uint32(90).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Stage {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStage() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.identifier = Stage1.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.realm = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.createTs = Revision.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.args = Value.decode(reader, reader.uint32());
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.version = Revision.decode(reader, reader.uint32());
          continue;
        }
        case 6: {
          if (tag !== 48) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.dependencies.push(EdgeGroup.decode(reader, reader.uint32()));
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.executionPolicy = Stage_ExecutionPolicyState.decode(reader, reader.uint32());
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.attempts.push(Stage_Attempt.decode(reader, reader.uint32()));
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.assignments.push(Stage_Assignment.decode(reader, reader.uint32()));
          continue;
        }
        case 11: {
          if (tag !== 90) {
            break;
          }

          message.continuationGroup.push(Edge.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Stage {
    return {
      identifier: isSet(object.identifier) ? Stage1.fromJSON(object.identifier) : undefined,
      realm: isSet(object.realm) ? globalThis.String(object.realm) : undefined,
      createTs: isSet(object.createTs) ? Revision.fromJSON(object.createTs) : undefined,
      args: isSet(object.args) ? Value.fromJSON(object.args) : undefined,
      version: isSet(object.version) ? Revision.fromJSON(object.version) : undefined,
      state: isSet(object.state) ? stageStateFromJSON(object.state) : undefined,
      dependencies: globalThis.Array.isArray(object?.dependencies)
        ? object.dependencies.map((e: any) => EdgeGroup.fromJSON(e))
        : [],
      executionPolicy: isSet(object.executionPolicy)
        ? Stage_ExecutionPolicyState.fromJSON(object.executionPolicy)
        : undefined,
      attempts: globalThis.Array.isArray(object?.attempts)
        ? object.attempts.map((e: any) => Stage_Attempt.fromJSON(e))
        : [],
      assignments: globalThis.Array.isArray(object?.assignments)
        ? object.assignments.map((e: any) => Stage_Assignment.fromJSON(e))
        : [],
      continuationGroup: globalThis.Array.isArray(object?.continuationGroup)
        ? object.continuationGroup.map((e: any) => Edge.fromJSON(e))
        : [],
    };
  },

  toJSON(message: Stage): unknown {
    const obj: any = {};
    if (message.identifier !== undefined) {
      obj.identifier = Stage1.toJSON(message.identifier);
    }
    if (message.realm !== undefined) {
      obj.realm = message.realm;
    }
    if (message.createTs !== undefined) {
      obj.createTs = Revision.toJSON(message.createTs);
    }
    if (message.args !== undefined) {
      obj.args = Value.toJSON(message.args);
    }
    if (message.version !== undefined) {
      obj.version = Revision.toJSON(message.version);
    }
    if (message.state !== undefined) {
      obj.state = stageStateToJSON(message.state);
    }
    if (message.dependencies?.length) {
      obj.dependencies = message.dependencies.map((e) => EdgeGroup.toJSON(e));
    }
    if (message.executionPolicy !== undefined) {
      obj.executionPolicy = Stage_ExecutionPolicyState.toJSON(message.executionPolicy);
    }
    if (message.attempts?.length) {
      obj.attempts = message.attempts.map((e) => Stage_Attempt.toJSON(e));
    }
    if (message.assignments?.length) {
      obj.assignments = message.assignments.map((e) => Stage_Assignment.toJSON(e));
    }
    if (message.continuationGroup?.length) {
      obj.continuationGroup = message.continuationGroup.map((e) => Edge.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<Stage>): Stage {
    return Stage.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Stage>): Stage {
    const message = createBaseStage() as any;
    message.identifier = (object.identifier !== undefined && object.identifier !== null)
      ? Stage1.fromPartial(object.identifier)
      : undefined;
    message.realm = object.realm ?? undefined;
    message.createTs = (object.createTs !== undefined && object.createTs !== null)
      ? Revision.fromPartial(object.createTs)
      : undefined;
    message.args = (object.args !== undefined && object.args !== null) ? Value.fromPartial(object.args) : undefined;
    message.version = (object.version !== undefined && object.version !== null)
      ? Revision.fromPartial(object.version)
      : undefined;
    message.state = object.state ?? undefined;
    message.dependencies = object.dependencies?.map((e) => EdgeGroup.fromPartial(e)) || [];
    message.executionPolicy = (object.executionPolicy !== undefined && object.executionPolicy !== null)
      ? Stage_ExecutionPolicyState.fromPartial(object.executionPolicy)
      : undefined;
    message.attempts = object.attempts?.map((e) => Stage_Attempt.fromPartial(e)) || [];
    message.assignments = object.assignments?.map((e) => Stage_Assignment.fromPartial(e)) || [];
    message.continuationGroup = object.continuationGroup?.map((e) => Edge.fromPartial(e)) || [];
    return message;
  },
};

function createBaseStage_ExecutionPolicyState(): Stage_ExecutionPolicyState {
  return { requested: undefined, validated: undefined };
}

export const Stage_ExecutionPolicyState: MessageFns<Stage_ExecutionPolicyState> = {
  encode(message: Stage_ExecutionPolicyState, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.requested !== undefined) {
      ExecutionPolicy.encode(message.requested, writer.uint32(10).fork()).join();
    }
    if (message.validated !== undefined) {
      ExecutionPolicy.encode(message.validated, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Stage_ExecutionPolicyState {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStage_ExecutionPolicyState() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.requested = ExecutionPolicy.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.validated = ExecutionPolicy.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Stage_ExecutionPolicyState {
    return {
      requested: isSet(object.requested) ? ExecutionPolicy.fromJSON(object.requested) : undefined,
      validated: isSet(object.validated) ? ExecutionPolicy.fromJSON(object.validated) : undefined,
    };
  },

  toJSON(message: Stage_ExecutionPolicyState): unknown {
    const obj: any = {};
    if (message.requested !== undefined) {
      obj.requested = ExecutionPolicy.toJSON(message.requested);
    }
    if (message.validated !== undefined) {
      obj.validated = ExecutionPolicy.toJSON(message.validated);
    }
    return obj;
  },

  create(base?: DeepPartial<Stage_ExecutionPolicyState>): Stage_ExecutionPolicyState {
    return Stage_ExecutionPolicyState.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Stage_ExecutionPolicyState>): Stage_ExecutionPolicyState {
    const message = createBaseStage_ExecutionPolicyState() as any;
    message.requested = (object.requested !== undefined && object.requested !== null)
      ? ExecutionPolicy.fromPartial(object.requested)
      : undefined;
    message.validated = (object.validated !== undefined && object.validated !== null)
      ? ExecutionPolicy.fromPartial(object.validated)
      : undefined;
    return message;
  },
};

function createBaseStage_Attempt(): Stage_Attempt {
  return { state: undefined, version: undefined, processUid: undefined, details: [], progress: [] };
}

export const Stage_Attempt: MessageFns<Stage_Attempt> = {
  encode(message: Stage_Attempt, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.state !== undefined) {
      writer.uint32(8).int32(message.state);
    }
    if (message.version !== undefined) {
      Revision.encode(message.version, writer.uint32(18).fork()).join();
    }
    if (message.processUid !== undefined) {
      writer.uint32(26).string(message.processUid);
    }
    for (const v of message.details) {
      Value.encode(v!, writer.uint32(34).fork()).join();
    }
    for (const v of message.progress) {
      Stage_Attempt_Progress.encode(v!, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Stage_Attempt {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStage_Attempt() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.version = Revision.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.processUid = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.details.push(Value.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.progress.push(Stage_Attempt_Progress.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Stage_Attempt {
    return {
      state: isSet(object.state) ? stageAttemptStateFromJSON(object.state) : undefined,
      version: isSet(object.version) ? Revision.fromJSON(object.version) : undefined,
      processUid: isSet(object.processUid) ? globalThis.String(object.processUid) : undefined,
      details: globalThis.Array.isArray(object?.details) ? object.details.map((e: any) => Value.fromJSON(e)) : [],
      progress: globalThis.Array.isArray(object?.progress)
        ? object.progress.map((e: any) => Stage_Attempt_Progress.fromJSON(e))
        : [],
    };
  },

  toJSON(message: Stage_Attempt): unknown {
    const obj: any = {};
    if (message.state !== undefined) {
      obj.state = stageAttemptStateToJSON(message.state);
    }
    if (message.version !== undefined) {
      obj.version = Revision.toJSON(message.version);
    }
    if (message.processUid !== undefined) {
      obj.processUid = message.processUid;
    }
    if (message.details?.length) {
      obj.details = message.details.map((e) => Value.toJSON(e));
    }
    if (message.progress?.length) {
      obj.progress = message.progress.map((e) => Stage_Attempt_Progress.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<Stage_Attempt>): Stage_Attempt {
    return Stage_Attempt.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Stage_Attempt>): Stage_Attempt {
    const message = createBaseStage_Attempt() as any;
    message.state = object.state ?? undefined;
    message.version = (object.version !== undefined && object.version !== null)
      ? Revision.fromPartial(object.version)
      : undefined;
    message.processUid = object.processUid ?? undefined;
    message.details = object.details?.map((e) => Value.fromPartial(e)) || [];
    message.progress = object.progress?.map((e) => Stage_Attempt_Progress.fromPartial(e)) || [];
    return message;
  },
};

function createBaseStage_Attempt_Progress(): Stage_Attempt_Progress {
  return { msg: undefined, version: undefined, details: [] };
}

export const Stage_Attempt_Progress: MessageFns<Stage_Attempt_Progress> = {
  encode(message: Stage_Attempt_Progress, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.msg !== undefined) {
      writer.uint32(10).string(message.msg);
    }
    if (message.version !== undefined) {
      Revision.encode(message.version, writer.uint32(18).fork()).join();
    }
    for (const v of message.details) {
      Value.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Stage_Attempt_Progress {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStage_Attempt_Progress() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.msg = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.version = Revision.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.details.push(Value.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Stage_Attempt_Progress {
    return {
      msg: isSet(object.msg) ? globalThis.String(object.msg) : undefined,
      version: isSet(object.version) ? Revision.fromJSON(object.version) : undefined,
      details: globalThis.Array.isArray(object?.details) ? object.details.map((e: any) => Value.fromJSON(e)) : [],
    };
  },

  toJSON(message: Stage_Attempt_Progress): unknown {
    const obj: any = {};
    if (message.msg !== undefined) {
      obj.msg = message.msg;
    }
    if (message.version !== undefined) {
      obj.version = Revision.toJSON(message.version);
    }
    if (message.details?.length) {
      obj.details = message.details.map((e) => Value.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<Stage_Attempt_Progress>): Stage_Attempt_Progress {
    return Stage_Attempt_Progress.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Stage_Attempt_Progress>): Stage_Attempt_Progress {
    const message = createBaseStage_Attempt_Progress() as any;
    message.msg = object.msg ?? undefined;
    message.version = (object.version !== undefined && object.version !== null)
      ? Revision.fromPartial(object.version)
      : undefined;
    message.details = object.details?.map((e) => Value.fromPartial(e)) || [];
    return message;
  },
};

function createBaseStage_Assignment(): Stage_Assignment {
  return { target: undefined, goalState: undefined };
}

export const Stage_Assignment: MessageFns<Stage_Assignment> = {
  encode(message: Stage_Assignment, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.target !== undefined) {
      Check.encode(message.target, writer.uint32(10).fork()).join();
    }
    if (message.goalState !== undefined) {
      writer.uint32(16).int32(message.goalState);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Stage_Assignment {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStage_Assignment() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.target = Check.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.goalState = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Stage_Assignment {
    return {
      target: isSet(object.target) ? Check.fromJSON(object.target) : undefined,
      goalState: isSet(object.goalState) ? checkStateFromJSON(object.goalState) : undefined,
    };
  },

  toJSON(message: Stage_Assignment): unknown {
    const obj: any = {};
    if (message.target !== undefined) {
      obj.target = Check.toJSON(message.target);
    }
    if (message.goalState !== undefined) {
      obj.goalState = checkStateToJSON(message.goalState);
    }
    return obj;
  },

  create(base?: DeepPartial<Stage_Assignment>): Stage_Assignment {
    return Stage_Assignment.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Stage_Assignment>): Stage_Assignment {
    const message = createBaseStage_Assignment() as any;
    message.target = (object.target !== undefined && object.target !== null)
      ? Check.fromPartial(object.target)
      : undefined;
    message.goalState = object.goalState ?? undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
