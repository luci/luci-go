// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.7.5
//   protoc               v6.32.1
// source: turboci/graph/orchestrator/v1/stage.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import { Check, Stage as Stage1, StageAttempt } from "../../ids/v1/identifier.pb";
import { Actor } from "./actor.pb";
import { CheckState, checkStateFromJSON, checkStateToJSON } from "./check_state.pb";
import { Dependencies } from "./dependencies.pb";
import { Failure } from "./failure.pb";
import { Revision } from "./revision.pb";
import { StageAttemptExecutionPolicy } from "./stage_attempt_execution_policy.pb";
import { StageAttemptState, stageAttemptStateFromJSON, stageAttemptStateToJSON } from "./stage_attempt_state.pb";
import { StageExecutionPolicy } from "./stage_execution_policy.pb";
import { StageState, stageStateFromJSON, stageStateToJSON } from "./stage_state.pb";
import { Value } from "./value.pb";

export const protobufPackage = "turboci.graph.orchestrator.v1";

/**
 * A Stage is an executable node in the workflow.
 *
 * The Orchestrator will coordinate with the Executor which is registered to
 * match `args.type_url` to actually run the Stage.
 *
 * See also:
 *   * StageView (graph view object for a Stage and contained messages)
 *   * StageEditView (graph view object for Edits of a Stage)
 */
export interface Stage {
  /** The Stage's identifier. */
  readonly identifier?:
    | Stage1
    | undefined;
  /** Actor which created the Stage. */
  readonly createdBy?:
    | Actor
    | undefined;
  /**
   * The security realm for this Stage.
   *
   * When a Stage inserts another, the inserted Stage will inherit the realm of
   * the inserting Stage, unless this is explicitly set.
   */
  readonly realm?:
    | string
    | undefined;
  /**
   * The arguments of the Stage.
   *
   * `identifier` is always empty.
   *
   * The type of this Datum must be pre-registered with the Orchestrator, and
   * that registration will indicate which Executor should handle this Stage.
   *
   * NOTE: It's assumed that args.type_url will be a sufficient routing key to
   * the various registered Executors, but it's POSSIBLE that we may need to
   * have multiple Executors handle exactly the same Stage type, at which point
   * we would need to either:
   *   * Add a secondary type to distinguish them; this would have the
   *     additional benefit of allowing us to clearly delineate the differences
   *     via documentation, but if we have this situation a lot, it could be
   *     confusing.
   *   * Add another field to Stage to allow registration on (newfield,
   *     type_url) instead of just type_url.
   *
   * Looking at WorkNode, there are definitely multiple executor types which
   * accept the same arguments in WorkParameters, but these could be represented
   * by adding a new field to WorkParameters. There is also the PARTIAL_RERUN
   * executor type which is used when duplicating WorkNodes, but this seems like
   * it will be handled differently with Checks (i.e. Checks of the same options
   * would be added, and new Results of the cached results would be added. There
   * wouldn't be a need to add placeholder Stages into such a graph). There
   * are also some executor types which serve as a way to separate ACLs, but
   * we expect this to be handled by realms.
   */
  readonly args?:
    | Value
    | undefined;
  /**
   * The version of this Stage.
   *
   * Updated any time fields in this Stage change, which includes all changes to
   * the active Stage Attempt (if state is ATTEMPTING).
   */
  readonly version?:
    | Revision
    | undefined;
  /** The current state of the Stage. */
  readonly state?:
    | StageState
    | undefined;
  /**
   * Append-only list of StateHistoryEntry to record the database revision
   * (commit timestamp) when each time this Stage's state changes.
   */
  readonly stateHistory: readonly Stage_StateHistoryEntry[];
  /**
   * Dependencies on other objects in the graph.
   *
   * Stages are allowed to depend on other Checks and Stages, and will not be
   * sent to an Executor until dependencies is resolved.
   *
   * Once the Stage is ATTEMPTING, this field is immutable.
   */
  readonly dependencies?:
    | Dependencies
    | undefined;
  /** Execution policy for this Stage. */
  readonly executionPolicy?:
    | Stage_ExecutionPolicyState
    | undefined;
  /**
   * Current retry/attempts state of this Stage, stored in ascending order by
   * created time.
   *
   * Only the most recent attempt (the last in the list) is potentially 'live'.
   *
   * Note that the revision of the attempts are unrelated to the revision of the
   * Stage. While the Stage is ATTEMPTING, the Stage's revision only changes
   * when:
   *   * A new Attempt is created
   *   * The Stage is canceled
   */
  readonly attempts: readonly Stage_Attempt[];
  /** The workflow's intent for this Stage. */
  readonly assignments: readonly Stage_Assignment[];
  /**
   * A set of dependencies edges o Stages whose resolution should be treated as
   * a logical part of this Stage.
   *
   * Stages included in this continuation_group MUST be created BY THIS STAGE.
   *
   * If non-empty, this Stage will enter the state AWAITING_GROUP after the
   * final attempt. The orchestrator will move this Stage to the FINAL state
   * once these Dependencies are resolved. If this is empty, the Stage will move
   * directly from ATTEMPTING to FINAL.
   *
   * This allows for encapsulation of work where one Stage may spawn a group of
   * Stages which should be treated as a single unit - otherwise all waiters for
   * this Stage would need to be directly informed of, and wait for, these new
   * Stages, which introduces a leaky abstraction.
   *
   * If needed, this could be expanded to allow Checks later.
   */
  readonly continuationGroup?: Dependencies | undefined;
}

/**
 * StateHistoryEntry records the database revision (commit timestamp) when
 * each time this Stage's state changes.
 */
export interface Stage_StateHistoryEntry {
  /** The changed state. */
  readonly state?:
    | StageState
    | undefined;
  /** The revision when the state change happens. */
  readonly version?: Revision | undefined;
}

/**
 * ExecutionPolicyState is the set of execution policies which define the
 * overall execution policy for this Stage.
 *
 * `requested` is set by the stage creator. This is validated and augmented by
 * the Executor to become the `validated` policy.
 *
 * In the future, this may also include a `dynamic` policy which could allow
 * additional restrictions to be added after the Stage is created.
 */
export interface Stage_ExecutionPolicyState {
  /**
   * Requested execution policy is the policy which is set by the creator of
   * this Stage.
   *
   * This will be validated by the Executor prior to the Stage being committed
   * to the graph.
   *
   * If omitted, the Executor will provide a full StageExecutionPolicy according to
   * its own logic/configuration.
   */
  readonly requested?:
    | StageExecutionPolicy
    | undefined;
  /**
   * Actual execution policy is the policy validated and returned by the
   * Executor when it accepts the Stage for insertion to the graph.
   *
   * This is the policy that TurboCI will use to drive Attempts for this
   * Stage.
   */
  readonly validated?: StageExecutionPolicy | undefined;
}

/**
 * Attempt represents a single attempt to execute a Stage.
 *
 * Stages in the AWAITING state ALWAYS have an active Attempt, even before
 * the Orchestrator sends the first RPC to the Executor for this Stage.
 *
 * TBD: Pull this into its own top-level StageAttempt entity because it will
 * need to have its own state and lifecycle/transactions.
 *
 * Next ID: 9
 */
export interface Stage_Attempt {
  /** The Stage Attempt's identifier. */
  readonly identifier?:
    | StageAttempt
    | undefined;
  /**
   * The version of this Attempt.
   *
   * Updated any time fields in this Attempt change.
   */
  readonly version?:
    | Revision
    | undefined;
  /** The current state of this Attempt. */
  readonly state?:
    | StageAttemptState
    | undefined;
  /**
   * Append-only list of StateHistoryEntry to record the database revision
   * (commit timestamp) when each time this Attempt's state changes.
   */
  readonly stateHistory: readonly Stage_Attempt_StateHistoryEntry[];
  /**
   * An opaque value provided by a Stage Attempt process (i.e. a single thread
   * of execution which is servicing this Stage Attempt) which is used to
   * ensure that a StageAttempt is idempotently assigned to at most one single
   * thread of execution globally.
   *
   * Consider the case where a task with a StageAttemptToken is dispatched to
   * a worker fleet and due to bugs/netsplits/solar flares/etc. the task ends
   * up on two different machines in the fleet, or in two different pubsub
   * handlers. Basically, two logical processes now have a StageAttemptToken,
   * and this Stage Attempt is in the SCHEDULED state.
   *
   * The first thing all of these copycat processes should do is a WriteNodes
   * RPC where they attempt to set `process_uid` to a value *unique to that
   * worker thread*, and transition the state to RUNNING. One of these
   * processes will succeed, and the Stage Attempt will transition to RUNNING.
   * All the other processes will fail, and the returned error will have
   * a gRPC Status detail of StageAttemptClaimedFailure.
   *
   * The Orchestrator service will only permit this field to be set while the
   * Stage Attempt is PENDING or SCHEDULED. In the case of network failure,
   * multiple calls of `WriteNodes(token, current={RUNNING, <process_uid>})`
   * with the same process_uid will all succeed. However, the other worker
   * threads will produce different process_uid values, and the server will
   * reject their attempt to transition to the RUNNING state, and they should
   * drop the task.
   *
   * There is no specific form for process_uid, but it must be unique per
   * thread consuming this Stage Attempt. Examples:
   *   * A UUID
   *   * hostname:process_id:thread_id
   *   * servicename:unique_assigned_process_name
   *
   * In the event that this accepting thread crashes, it is expected that this
   * Stage Attempt will become INCOMPLETE on heartbeat timeout, and, retries
   * permitting, a new Stage Attempt will be generated.
   */
  readonly processUid?:
    | string
    | undefined;
  /**
   * Details provided by the Executor about this Stage Attempt.
   *
   * This field is effectively an append-only map. The Executor and/or Stage
   * Attempt can only write data *of a given type* ONCE to this field, and
   * that data type must be unique within this field. If you need to add data
   * here multiple times during the lifecycle of the attempt, use different
   * types for each stage of that lifecycle.
   *
   * It can be updated by the Executor or Stage Attempt as long as the Stage
   * Attempt is not final (i.e. a state prior to COMPLETE or INCOMPLETE).
   *
   * Kept sorted by, and unique on, type_url.
   */
  readonly details: readonly Value[];
  /** Append-only Executor-specefic progress messages. */
  readonly progress: readonly Stage_Attempt_Progress[];
  /**
   * Actual execution policy for this StageAttempt.
   *
   * When the orchestrator sends this attempt to the executor to run, the
   * executor will reevaluate the previous validated attempt execution
   * template in stage execution policy and make adjustments when necessary.
   * The validated execution policy is sent to the Orchestrator as part of
   * CurrentStageWrite when the executor advances the StageAttempt state
   * PENDING -> (SCHEDULED|RUNNING).
   */
  readonly executionPolicy?:
    | StageAttemptExecutionPolicy
    | undefined;
  /** Execution failure information for the StageAttempt. */
  readonly failure?: Failure | undefined;
}

/**
 * StateHistoryEntry records the database revision (commit timestamp) when
 * each time this Attempt's state changes.
 */
export interface Stage_Attempt_StateHistoryEntry {
  /** The changed state. */
  readonly state?:
    | StageAttemptState
    | undefined;
  /** The revision when the state change happens. */
  readonly version?: Revision | undefined;
}

/**
 * Attempt-specific progress information.
 *
 * Note that the Edit log also has a Reason for every graph write - this
 * Progress message should be used when the Executor wants e.g. the UI to be
 * able to load just the current state of a Stage and display this
 * information in a time-oriented way.
 */
export interface Stage_Attempt_Progress {
  /** Low-effort/human-readable progress information. */
  readonly msg?:
    | string
    | undefined;
  /** The version of this Stage which added this Progress message. */
  readonly version?:
    | Revision
    | undefined;
  /**
   * Machine-readable details for this progress item.
   *
   * Kept sorted by, and unique on, type_url.
   */
  readonly details: readonly Value[];
}

/**
 * Assignment describes the workflow's intent that this Stage will handle one
 * or more Checks in some fashion.
 */
export interface Stage_Assignment {
  /** The Check that this Stage should handle. */
  readonly target?:
    | Check
    | undefined;
  /**
   * The expected state of the Check when this Stage is FINAL.
   *
   * NOTE: The Stage may, during its execution, create additional Stages with
   * this same Assignment as a way of propagating the responsibility of
   * handling the Check to those Stages.
   *
   * The Orchestrator will automatically advance the state of this Check to
   * the goal state when no more Stages are assigned to handle it with this
   * goal state.
   *
   * Ex. If some stage S is assigned a Check C with goal state PLANNED, it
   * indicates that S is responsible for ensuring that C is fully PLANNED. S
   * could spawn some helpers (S' and S'') with this same Assignment. Assuming
   * that S' and S'' don't further propagate the responsibility of handling C,
   * when all of S, S', and S'' are FINAL, the Orchestrator will advance C to
   * the PLANNED state.
   *
   * If a stage manually advances a Check to a state equal to or beyond the
   * goal state, then the Orchestrator will stop monitoring Assignments for
   * this Check at this goal state.
   *
   * Manual advancement can be dangerous if done when other Stages are still
   * operating on the Check at the earlier state (for example, if one Stage
   * moves a Check to PLANNED while another Stage is still trying to write to
   * the Check options, the writing Stage will fail to write out the options).
   */
  readonly goalState?: CheckState | undefined;
}

/**
 * StageAttemptClaimedFailure is a gRPC error detail message returned by
 * WriteNodes when attempting to transition a Stage Attempt from
 * PENDING/SCHEDULED to RUNNING with a mismatched process_uid.
 *
 * If your client receives an rpc status with this message in it, it means that
 * another process already claimed this Stage Attempt, and you should stop
 * attempting to execute this Stage Attempt.
 */
export interface StageAttemptClaimedFailure {
  /**
   * The recorded Stage Attempt process_uid - this should only be used for
   * logging/reporting purposes (typically to help wayward developers see which
   * other process is *actually* working on this Stage Attempt).
   */
  readonly claimedByProcessUid?: string | undefined;
}

function createBaseStage(): Stage {
  return {
    identifier: undefined,
    createdBy: undefined,
    realm: undefined,
    args: undefined,
    version: undefined,
    state: undefined,
    stateHistory: [],
    dependencies: undefined,
    executionPolicy: undefined,
    attempts: [],
    assignments: [],
    continuationGroup: undefined,
  };
}

export const Stage: MessageFns<Stage> = {
  encode(message: Stage, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.identifier !== undefined) {
      Stage1.encode(message.identifier, writer.uint32(10).fork()).join();
    }
    if (message.createdBy !== undefined) {
      Actor.encode(message.createdBy, writer.uint32(18).fork()).join();
    }
    if (message.realm !== undefined) {
      writer.uint32(26).string(message.realm);
    }
    if (message.args !== undefined) {
      Value.encode(message.args, writer.uint32(34).fork()).join();
    }
    if (message.version !== undefined) {
      Revision.encode(message.version, writer.uint32(42).fork()).join();
    }
    if (message.state !== undefined) {
      writer.uint32(48).int32(message.state);
    }
    for (const v of message.stateHistory) {
      Stage_StateHistoryEntry.encode(v!, writer.uint32(58).fork()).join();
    }
    if (message.dependencies !== undefined) {
      Dependencies.encode(message.dependencies, writer.uint32(66).fork()).join();
    }
    if (message.executionPolicy !== undefined) {
      Stage_ExecutionPolicyState.encode(message.executionPolicy, writer.uint32(74).fork()).join();
    }
    for (const v of message.attempts) {
      Stage_Attempt.encode(v!, writer.uint32(82).fork()).join();
    }
    for (const v of message.assignments) {
      Stage_Assignment.encode(v!, writer.uint32(90).fork()).join();
    }
    if (message.continuationGroup !== undefined) {
      Dependencies.encode(message.continuationGroup, writer.uint32(98).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Stage {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStage() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.identifier = Stage1.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.createdBy = Actor.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.realm = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.args = Value.decode(reader, reader.uint32());
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.version = Revision.decode(reader, reader.uint32());
          continue;
        }
        case 6: {
          if (tag !== 48) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.stateHistory.push(Stage_StateHistoryEntry.decode(reader, reader.uint32()));
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.dependencies = Dependencies.decode(reader, reader.uint32());
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.executionPolicy = Stage_ExecutionPolicyState.decode(reader, reader.uint32());
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.attempts.push(Stage_Attempt.decode(reader, reader.uint32()));
          continue;
        }
        case 11: {
          if (tag !== 90) {
            break;
          }

          message.assignments.push(Stage_Assignment.decode(reader, reader.uint32()));
          continue;
        }
        case 12: {
          if (tag !== 98) {
            break;
          }

          message.continuationGroup = Dependencies.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Stage {
    return {
      identifier: isSet(object.identifier) ? Stage1.fromJSON(object.identifier) : undefined,
      createdBy: isSet(object.createdBy) ? Actor.fromJSON(object.createdBy) : undefined,
      realm: isSet(object.realm) ? globalThis.String(object.realm) : undefined,
      args: isSet(object.args) ? Value.fromJSON(object.args) : undefined,
      version: isSet(object.version) ? Revision.fromJSON(object.version) : undefined,
      state: isSet(object.state) ? stageStateFromJSON(object.state) : undefined,
      stateHistory: globalThis.Array.isArray(object?.stateHistory)
        ? object.stateHistory.map((e: any) => Stage_StateHistoryEntry.fromJSON(e))
        : [],
      dependencies: isSet(object.dependencies) ? Dependencies.fromJSON(object.dependencies) : undefined,
      executionPolicy: isSet(object.executionPolicy)
        ? Stage_ExecutionPolicyState.fromJSON(object.executionPolicy)
        : undefined,
      attempts: globalThis.Array.isArray(object?.attempts)
        ? object.attempts.map((e: any) => Stage_Attempt.fromJSON(e))
        : [],
      assignments: globalThis.Array.isArray(object?.assignments)
        ? object.assignments.map((e: any) => Stage_Assignment.fromJSON(e))
        : [],
      continuationGroup: isSet(object.continuationGroup) ? Dependencies.fromJSON(object.continuationGroup) : undefined,
    };
  },

  toJSON(message: Stage): unknown {
    const obj: any = {};
    if (message.identifier !== undefined) {
      obj.identifier = Stage1.toJSON(message.identifier);
    }
    if (message.createdBy !== undefined) {
      obj.createdBy = Actor.toJSON(message.createdBy);
    }
    if (message.realm !== undefined) {
      obj.realm = message.realm;
    }
    if (message.args !== undefined) {
      obj.args = Value.toJSON(message.args);
    }
    if (message.version !== undefined) {
      obj.version = Revision.toJSON(message.version);
    }
    if (message.state !== undefined) {
      obj.state = stageStateToJSON(message.state);
    }
    if (message.stateHistory?.length) {
      obj.stateHistory = message.stateHistory.map((e) => Stage_StateHistoryEntry.toJSON(e));
    }
    if (message.dependencies !== undefined) {
      obj.dependencies = Dependencies.toJSON(message.dependencies);
    }
    if (message.executionPolicy !== undefined) {
      obj.executionPolicy = Stage_ExecutionPolicyState.toJSON(message.executionPolicy);
    }
    if (message.attempts?.length) {
      obj.attempts = message.attempts.map((e) => Stage_Attempt.toJSON(e));
    }
    if (message.assignments?.length) {
      obj.assignments = message.assignments.map((e) => Stage_Assignment.toJSON(e));
    }
    if (message.continuationGroup !== undefined) {
      obj.continuationGroup = Dependencies.toJSON(message.continuationGroup);
    }
    return obj;
  },

  create(base?: DeepPartial<Stage>): Stage {
    return Stage.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Stage>): Stage {
    const message = createBaseStage() as any;
    message.identifier = (object.identifier !== undefined && object.identifier !== null)
      ? Stage1.fromPartial(object.identifier)
      : undefined;
    message.createdBy = (object.createdBy !== undefined && object.createdBy !== null)
      ? Actor.fromPartial(object.createdBy)
      : undefined;
    message.realm = object.realm ?? undefined;
    message.args = (object.args !== undefined && object.args !== null) ? Value.fromPartial(object.args) : undefined;
    message.version = (object.version !== undefined && object.version !== null)
      ? Revision.fromPartial(object.version)
      : undefined;
    message.state = object.state ?? undefined;
    message.stateHistory = object.stateHistory?.map((e) => Stage_StateHistoryEntry.fromPartial(e)) || [];
    message.dependencies = (object.dependencies !== undefined && object.dependencies !== null)
      ? Dependencies.fromPartial(object.dependencies)
      : undefined;
    message.executionPolicy = (object.executionPolicy !== undefined && object.executionPolicy !== null)
      ? Stage_ExecutionPolicyState.fromPartial(object.executionPolicy)
      : undefined;
    message.attempts = object.attempts?.map((e) => Stage_Attempt.fromPartial(e)) || [];
    message.assignments = object.assignments?.map((e) => Stage_Assignment.fromPartial(e)) || [];
    message.continuationGroup = (object.continuationGroup !== undefined && object.continuationGroup !== null)
      ? Dependencies.fromPartial(object.continuationGroup)
      : undefined;
    return message;
  },
};

function createBaseStage_StateHistoryEntry(): Stage_StateHistoryEntry {
  return { state: undefined, version: undefined };
}

export const Stage_StateHistoryEntry: MessageFns<Stage_StateHistoryEntry> = {
  encode(message: Stage_StateHistoryEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.state !== undefined) {
      writer.uint32(8).int32(message.state);
    }
    if (message.version !== undefined) {
      Revision.encode(message.version, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Stage_StateHistoryEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStage_StateHistoryEntry() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.version = Revision.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Stage_StateHistoryEntry {
    return {
      state: isSet(object.state) ? stageStateFromJSON(object.state) : undefined,
      version: isSet(object.version) ? Revision.fromJSON(object.version) : undefined,
    };
  },

  toJSON(message: Stage_StateHistoryEntry): unknown {
    const obj: any = {};
    if (message.state !== undefined) {
      obj.state = stageStateToJSON(message.state);
    }
    if (message.version !== undefined) {
      obj.version = Revision.toJSON(message.version);
    }
    return obj;
  },

  create(base?: DeepPartial<Stage_StateHistoryEntry>): Stage_StateHistoryEntry {
    return Stage_StateHistoryEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Stage_StateHistoryEntry>): Stage_StateHistoryEntry {
    const message = createBaseStage_StateHistoryEntry() as any;
    message.state = object.state ?? undefined;
    message.version = (object.version !== undefined && object.version !== null)
      ? Revision.fromPartial(object.version)
      : undefined;
    return message;
  },
};

function createBaseStage_ExecutionPolicyState(): Stage_ExecutionPolicyState {
  return { requested: undefined, validated: undefined };
}

export const Stage_ExecutionPolicyState: MessageFns<Stage_ExecutionPolicyState> = {
  encode(message: Stage_ExecutionPolicyState, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.requested !== undefined) {
      StageExecutionPolicy.encode(message.requested, writer.uint32(10).fork()).join();
    }
    if (message.validated !== undefined) {
      StageExecutionPolicy.encode(message.validated, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Stage_ExecutionPolicyState {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStage_ExecutionPolicyState() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.requested = StageExecutionPolicy.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.validated = StageExecutionPolicy.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Stage_ExecutionPolicyState {
    return {
      requested: isSet(object.requested) ? StageExecutionPolicy.fromJSON(object.requested) : undefined,
      validated: isSet(object.validated) ? StageExecutionPolicy.fromJSON(object.validated) : undefined,
    };
  },

  toJSON(message: Stage_ExecutionPolicyState): unknown {
    const obj: any = {};
    if (message.requested !== undefined) {
      obj.requested = StageExecutionPolicy.toJSON(message.requested);
    }
    if (message.validated !== undefined) {
      obj.validated = StageExecutionPolicy.toJSON(message.validated);
    }
    return obj;
  },

  create(base?: DeepPartial<Stage_ExecutionPolicyState>): Stage_ExecutionPolicyState {
    return Stage_ExecutionPolicyState.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Stage_ExecutionPolicyState>): Stage_ExecutionPolicyState {
    const message = createBaseStage_ExecutionPolicyState() as any;
    message.requested = (object.requested !== undefined && object.requested !== null)
      ? StageExecutionPolicy.fromPartial(object.requested)
      : undefined;
    message.validated = (object.validated !== undefined && object.validated !== null)
      ? StageExecutionPolicy.fromPartial(object.validated)
      : undefined;
    return message;
  },
};

function createBaseStage_Attempt(): Stage_Attempt {
  return {
    identifier: undefined,
    version: undefined,
    state: undefined,
    stateHistory: [],
    processUid: undefined,
    details: [],
    progress: [],
    executionPolicy: undefined,
    failure: undefined,
  };
}

export const Stage_Attempt: MessageFns<Stage_Attempt> = {
  encode(message: Stage_Attempt, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.identifier !== undefined) {
      StageAttempt.encode(message.identifier, writer.uint32(10).fork()).join();
    }
    if (message.version !== undefined) {
      Revision.encode(message.version, writer.uint32(18).fork()).join();
    }
    if (message.state !== undefined) {
      writer.uint32(24).int32(message.state);
    }
    for (const v of message.stateHistory) {
      Stage_Attempt_StateHistoryEntry.encode(v!, writer.uint32(34).fork()).join();
    }
    if (message.processUid !== undefined) {
      writer.uint32(42).string(message.processUid);
    }
    for (const v of message.details) {
      Value.encode(v!, writer.uint32(50).fork()).join();
    }
    for (const v of message.progress) {
      Stage_Attempt_Progress.encode(v!, writer.uint32(58).fork()).join();
    }
    if (message.executionPolicy !== undefined) {
      StageAttemptExecutionPolicy.encode(message.executionPolicy, writer.uint32(66).fork()).join();
    }
    if (message.failure !== undefined) {
      Failure.encode(message.failure, writer.uint32(74).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Stage_Attempt {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStage_Attempt() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.identifier = StageAttempt.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.version = Revision.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.stateHistory.push(Stage_Attempt_StateHistoryEntry.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.processUid = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.details.push(Value.decode(reader, reader.uint32()));
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.progress.push(Stage_Attempt_Progress.decode(reader, reader.uint32()));
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.executionPolicy = StageAttemptExecutionPolicy.decode(reader, reader.uint32());
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.failure = Failure.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Stage_Attempt {
    return {
      identifier: isSet(object.identifier) ? StageAttempt.fromJSON(object.identifier) : undefined,
      version: isSet(object.version) ? Revision.fromJSON(object.version) : undefined,
      state: isSet(object.state) ? stageAttemptStateFromJSON(object.state) : undefined,
      stateHistory: globalThis.Array.isArray(object?.stateHistory)
        ? object.stateHistory.map((e: any) => Stage_Attempt_StateHistoryEntry.fromJSON(e))
        : [],
      processUid: isSet(object.processUid) ? globalThis.String(object.processUid) : undefined,
      details: globalThis.Array.isArray(object?.details) ? object.details.map((e: any) => Value.fromJSON(e)) : [],
      progress: globalThis.Array.isArray(object?.progress)
        ? object.progress.map((e: any) => Stage_Attempt_Progress.fromJSON(e))
        : [],
      executionPolicy: isSet(object.executionPolicy)
        ? StageAttemptExecutionPolicy.fromJSON(object.executionPolicy)
        : undefined,
      failure: isSet(object.failure) ? Failure.fromJSON(object.failure) : undefined,
    };
  },

  toJSON(message: Stage_Attempt): unknown {
    const obj: any = {};
    if (message.identifier !== undefined) {
      obj.identifier = StageAttempt.toJSON(message.identifier);
    }
    if (message.version !== undefined) {
      obj.version = Revision.toJSON(message.version);
    }
    if (message.state !== undefined) {
      obj.state = stageAttemptStateToJSON(message.state);
    }
    if (message.stateHistory?.length) {
      obj.stateHistory = message.stateHistory.map((e) => Stage_Attempt_StateHistoryEntry.toJSON(e));
    }
    if (message.processUid !== undefined) {
      obj.processUid = message.processUid;
    }
    if (message.details?.length) {
      obj.details = message.details.map((e) => Value.toJSON(e));
    }
    if (message.progress?.length) {
      obj.progress = message.progress.map((e) => Stage_Attempt_Progress.toJSON(e));
    }
    if (message.executionPolicy !== undefined) {
      obj.executionPolicy = StageAttemptExecutionPolicy.toJSON(message.executionPolicy);
    }
    if (message.failure !== undefined) {
      obj.failure = Failure.toJSON(message.failure);
    }
    return obj;
  },

  create(base?: DeepPartial<Stage_Attempt>): Stage_Attempt {
    return Stage_Attempt.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Stage_Attempt>): Stage_Attempt {
    const message = createBaseStage_Attempt() as any;
    message.identifier = (object.identifier !== undefined && object.identifier !== null)
      ? StageAttempt.fromPartial(object.identifier)
      : undefined;
    message.version = (object.version !== undefined && object.version !== null)
      ? Revision.fromPartial(object.version)
      : undefined;
    message.state = object.state ?? undefined;
    message.stateHistory = object.stateHistory?.map((e) => Stage_Attempt_StateHistoryEntry.fromPartial(e)) || [];
    message.processUid = object.processUid ?? undefined;
    message.details = object.details?.map((e) => Value.fromPartial(e)) || [];
    message.progress = object.progress?.map((e) => Stage_Attempt_Progress.fromPartial(e)) || [];
    message.executionPolicy = (object.executionPolicy !== undefined && object.executionPolicy !== null)
      ? StageAttemptExecutionPolicy.fromPartial(object.executionPolicy)
      : undefined;
    message.failure = (object.failure !== undefined && object.failure !== null)
      ? Failure.fromPartial(object.failure)
      : undefined;
    return message;
  },
};

function createBaseStage_Attempt_StateHistoryEntry(): Stage_Attempt_StateHistoryEntry {
  return { state: undefined, version: undefined };
}

export const Stage_Attempt_StateHistoryEntry: MessageFns<Stage_Attempt_StateHistoryEntry> = {
  encode(message: Stage_Attempt_StateHistoryEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.state !== undefined) {
      writer.uint32(8).int32(message.state);
    }
    if (message.version !== undefined) {
      Revision.encode(message.version, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Stage_Attempt_StateHistoryEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStage_Attempt_StateHistoryEntry() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.version = Revision.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Stage_Attempt_StateHistoryEntry {
    return {
      state: isSet(object.state) ? stageAttemptStateFromJSON(object.state) : undefined,
      version: isSet(object.version) ? Revision.fromJSON(object.version) : undefined,
    };
  },

  toJSON(message: Stage_Attempt_StateHistoryEntry): unknown {
    const obj: any = {};
    if (message.state !== undefined) {
      obj.state = stageAttemptStateToJSON(message.state);
    }
    if (message.version !== undefined) {
      obj.version = Revision.toJSON(message.version);
    }
    return obj;
  },

  create(base?: DeepPartial<Stage_Attempt_StateHistoryEntry>): Stage_Attempt_StateHistoryEntry {
    return Stage_Attempt_StateHistoryEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Stage_Attempt_StateHistoryEntry>): Stage_Attempt_StateHistoryEntry {
    const message = createBaseStage_Attempt_StateHistoryEntry() as any;
    message.state = object.state ?? undefined;
    message.version = (object.version !== undefined && object.version !== null)
      ? Revision.fromPartial(object.version)
      : undefined;
    return message;
  },
};

function createBaseStage_Attempt_Progress(): Stage_Attempt_Progress {
  return { msg: undefined, version: undefined, details: [] };
}

export const Stage_Attempt_Progress: MessageFns<Stage_Attempt_Progress> = {
  encode(message: Stage_Attempt_Progress, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.msg !== undefined) {
      writer.uint32(10).string(message.msg);
    }
    if (message.version !== undefined) {
      Revision.encode(message.version, writer.uint32(18).fork()).join();
    }
    for (const v of message.details) {
      Value.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Stage_Attempt_Progress {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStage_Attempt_Progress() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.msg = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.version = Revision.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.details.push(Value.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Stage_Attempt_Progress {
    return {
      msg: isSet(object.msg) ? globalThis.String(object.msg) : undefined,
      version: isSet(object.version) ? Revision.fromJSON(object.version) : undefined,
      details: globalThis.Array.isArray(object?.details) ? object.details.map((e: any) => Value.fromJSON(e)) : [],
    };
  },

  toJSON(message: Stage_Attempt_Progress): unknown {
    const obj: any = {};
    if (message.msg !== undefined) {
      obj.msg = message.msg;
    }
    if (message.version !== undefined) {
      obj.version = Revision.toJSON(message.version);
    }
    if (message.details?.length) {
      obj.details = message.details.map((e) => Value.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<Stage_Attempt_Progress>): Stage_Attempt_Progress {
    return Stage_Attempt_Progress.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Stage_Attempt_Progress>): Stage_Attempt_Progress {
    const message = createBaseStage_Attempt_Progress() as any;
    message.msg = object.msg ?? undefined;
    message.version = (object.version !== undefined && object.version !== null)
      ? Revision.fromPartial(object.version)
      : undefined;
    message.details = object.details?.map((e) => Value.fromPartial(e)) || [];
    return message;
  },
};

function createBaseStage_Assignment(): Stage_Assignment {
  return { target: undefined, goalState: undefined };
}

export const Stage_Assignment: MessageFns<Stage_Assignment> = {
  encode(message: Stage_Assignment, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.target !== undefined) {
      Check.encode(message.target, writer.uint32(10).fork()).join();
    }
    if (message.goalState !== undefined) {
      writer.uint32(16).int32(message.goalState);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Stage_Assignment {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStage_Assignment() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.target = Check.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.goalState = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Stage_Assignment {
    return {
      target: isSet(object.target) ? Check.fromJSON(object.target) : undefined,
      goalState: isSet(object.goalState) ? checkStateFromJSON(object.goalState) : undefined,
    };
  },

  toJSON(message: Stage_Assignment): unknown {
    const obj: any = {};
    if (message.target !== undefined) {
      obj.target = Check.toJSON(message.target);
    }
    if (message.goalState !== undefined) {
      obj.goalState = checkStateToJSON(message.goalState);
    }
    return obj;
  },

  create(base?: DeepPartial<Stage_Assignment>): Stage_Assignment {
    return Stage_Assignment.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Stage_Assignment>): Stage_Assignment {
    const message = createBaseStage_Assignment() as any;
    message.target = (object.target !== undefined && object.target !== null)
      ? Check.fromPartial(object.target)
      : undefined;
    message.goalState = object.goalState ?? undefined;
    return message;
  },
};

function createBaseStageAttemptClaimedFailure(): StageAttemptClaimedFailure {
  return { claimedByProcessUid: undefined };
}

export const StageAttemptClaimedFailure: MessageFns<StageAttemptClaimedFailure> = {
  encode(message: StageAttemptClaimedFailure, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.claimedByProcessUid !== undefined) {
      writer.uint32(10).string(message.claimedByProcessUid);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StageAttemptClaimedFailure {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStageAttemptClaimedFailure() as any;
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.claimedByProcessUid = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StageAttemptClaimedFailure {
    return {
      claimedByProcessUid: isSet(object.claimedByProcessUid)
        ? globalThis.String(object.claimedByProcessUid)
        : undefined,
    };
  },

  toJSON(message: StageAttemptClaimedFailure): unknown {
    const obj: any = {};
    if (message.claimedByProcessUid !== undefined) {
      obj.claimedByProcessUid = message.claimedByProcessUid;
    }
    return obj;
  },

  create(base?: DeepPartial<StageAttemptClaimedFailure>): StageAttemptClaimedFailure {
    return StageAttemptClaimedFailure.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<StageAttemptClaimedFailure>): StageAttemptClaimedFailure {
    const message = createBaseStageAttemptClaimedFailure() as any;
    message.claimedByProcessUid = object.claimedByProcessUid ?? undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
